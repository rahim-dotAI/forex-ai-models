name: Smart Forex Brain Pipeline (Trade Beacon v17.1)

on:
  workflow_dispatch:
  push:
    paths:
      - 'colab_trigger.txt'
    branches:
      - main
  schedule:
    # Weekdays (Mon-Fri): Every 2 hours - Full notebook execution
    - cron: '0 */2 * * 1-5'
    # Weekends (Sat-Sun): Every 30 minutes - Tagged cells only
    - cron: '*/30 * * * 0,6'

jobs:
  run-forex-brain:
    runs-on: ubuntu-latest
    timeout-minutes: 55

    env:
      FOREX_PAT: ${{ secrets.FOREX_PAT }}
      BROWSERLESS_TOKEN: ${{ secrets.BROWSERLESS_TOKEN }}
      ALPHA_VANTAGE_KEY: ${{ secrets.ALPHA_VANTAGE_KEY }}
      GMAIL_USER: ${{ secrets.GMAIL_USER }}
      GMAIL_APP_PASSWORD: ${{ secrets.GMAIL_APP_PASSWORD }}
      GIT_USER_NAME: "Forex AI Bot"
      GIT_USER_EMAIL: "nakatonabira3@gmail.com"
      GITHUB_USERNAME: "rahim-dotAI"
      GITHUB_REPO: "forex-ai-models"
      PYTHONIOENCODING: utf-8
      PYTHONUNBUFFERED: 1
      GITHUB_ACTIONS: "true"
      SINGLE_RUN_MODE: "true"

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          persist-credentials: false
          fetch-depth: 0
          lfs: true
          token: ${{ secrets.FOREX_PAT }}

      - name: Fix submodule issue
        run: |
          echo "=========================================="
          echo "üîß FIXING SUBMODULE CONFIGURATION"
          echo "=========================================="
          
          if [ -f ".gitmodules" ]; then
            echo "‚ö†Ô∏è Found .gitmodules file - removing it"
            rm -f .gitmodules
            git rm --cached -r forex-alpha-models 2>/dev/null || true
            rm -rf forex-alpha-models
            git add .gitmodules 2>/dev/null || true
            echo "‚úÖ Submodule configuration removed"
          else
            echo "‚úÖ No .gitmodules file found"
          fi
          
          find . -mindepth 2 -name ".git" -type d -exec rm -rf {} + 2>/dev/null || true
          echo "=========================================="

      - name: Detect Execution Mode
        id: detect_mode
        run: |
          DAY_OF_WEEK=$(date +%u)
          HOUR=$(date +%H)
          
          echo "=========================================="
          echo "üóìÔ∏è  EXECUTION MODE DETECTION"
          echo "=========================================="
          echo "Current day: $DAY_OF_WEEK (1=Mon, 5=Fri, 6=Sat, 7=Sun)"
          echo "Current hour: $HOUR UTC"
          echo "Date: $(date +'%A, %B %d, %Y %H:%M UTC')"
          echo ""
          
          # Weekend = Saturday (6) or Sunday (7)
          if [ $DAY_OF_WEEK -eq 6 ] || [ $DAY_OF_WEEK -eq 7 ]; then
            echo "execution_mode=weekend_tagged_cells" >> $GITHUB_OUTPUT
            echo "schedule_type=30min_tagged" >> $GITHUB_OUTPUT
            echo "üèñÔ∏è MODE: WEEKEND (Saturday/Sunday)"
            echo "   ‚Ä¢ Execution: Tagged cells only"
            echo "   ‚Ä¢ Schedule: Every 30 minutes"
            echo "   ‚Ä¢ Trading: LEARNING MODE"
          else
            echo "execution_mode=weekday_full_notebook" >> $GITHUB_OUTPUT
            echo "schedule_type=2hourly" >> $GITHUB_OUTPUT
            echo "üíº MODE: WEEKDAY (Monday-Friday)"
            echo "   ‚Ä¢ Execution: Full notebook"
            echo "   ‚Ä¢ Schedule: Every 2 hours"
            echo "   ‚Ä¢ Trading: LIVE MODE"
          fi
          echo "=========================================="

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip

      - name: Install dependencies
        run: |
          echo "üì¶ Installing Python dependencies..."
          python -m pip install --upgrade pip wheel setuptools
          pip install --no-cache-dir \
            pandas numpy requests beautifulsoup4 scikit-learn \
            jupyter nbconvert nbformat ta yfinance \
            mplfinance firebase-admin dropbox \
            pyppeteer nest_asyncio lightgbm joblib matplotlib \
            alpha_vantage tqdm river scipy
          echo "‚úÖ Dependencies installed"

      - name: Configure Git
        run: |
          git config --global user.name "${GIT_USER_NAME}"
          git config --global user.email "${GIT_USER_EMAIL}"
          git config --global credential.helper store
          echo "https://${GITHUB_USERNAME}:${FOREX_PAT}@github.com" > ~/.git-credentials
          echo "‚úÖ Git configured"

      - name: Load Run History
        id: load_history
        run: |
          echo "=========================================="
          echo "üìä LOADING RUN HISTORY"
          echo "=========================================="
          
          # Create run history directory if it doesn't exist
          mkdir -p .github/run_history
          
          # Initialize or load run counter
          if [ -f ".github/run_history/run_counter.txt" ]; then
            CURRENT_RUN=$(cat .github/run_history/run_counter.txt)
          else
            CURRENT_RUN=0
          fi
          
          CURRENT_RUN=$((CURRENT_RUN + 1))
          echo $CURRENT_RUN > .github/run_history/run_counter.txt
          
          echo "run_number=$CURRENT_RUN" >> $GITHUB_OUTPUT
          
          # Check if we need to send email report (every 10 runs)
          if [ $((CURRENT_RUN % 10)) -eq 0 ]; then
            echo "send_report=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Run #$CURRENT_RUN - EMAIL REPORT SCHEDULED"
          else
            echo "send_report=false" >> $GITHUB_OUTPUT
            echo "‚úÖ Run #$CURRENT_RUN - Normal execution"
          fi
          
          echo "=========================================="

      - name: Check for Required Data Files
        id: check_data
        run: |
          echo "=========================================="
          echo "üîç CHECKING FOR REQUIRED DATA FILES"
          echo "=========================================="
          
          PICKLE_COUNT=$(find data/processed -name "*.pkl" -type f 2>/dev/null | \
            grep -v "_sgd_model\|_rf_model\|indicator_cache\|ultra_\|alpha_\|_model.pkl\|\.bak" | wc -l)
          
          PIPELINE_DB_EXISTS=false
          if [ -f "database/memory_v85.db" ]; then
            PIPELINE_DB_EXISTS=true
          fi
          
          RL_STATE_EXISTS=false
          if [ -d "rl_memory" ] && [ -f "rl_memory/experience_replay.pkl" ]; then
            RL_STATE_EXISTS=true
          fi
          
          echo "üìä Data Status:"
          echo "   Processed pickles: $PICKLE_COUNT"
          echo "   Pipeline DB: $PIPELINE_DB_EXISTS"
          echo "   RL State: $RL_STATE_EXISTS"
          
          if [ $PICKLE_COUNT -ge 4 ]; then
            echo "has_data=true" >> $GITHUB_OUTPUT
            echo "‚úÖ SUFFICIENT DATA FOUND"
          else
            echo "has_data=false" >> $GITHUB_OUTPUT
            echo "‚ö†Ô∏è  INSUFFICIENT DATA - Will run full notebook"
          fi
          
          echo "=========================================="

      - name: Create Python Executors
        run: |
          # Create the tagged cells executor with error handling
          cat > run_tagged_cells.py << 'EOFPYTHON'
          import nbformat
          from nbconvert.preprocessors import ExecutePreprocessor
          import sys, os, time, re, traceback, json
          from datetime import datetime
          
          class TaggedCellExecutor(ExecutePreprocessor):
              def __init__(self, *args, **kwargs):
                  super().__init__(*args, **kwargs)
                  self.tagged_cells = []
                  self.current_cell = 0
                  self.start_time = None
                  self.cell_summaries = []
                  
              def preprocess(self, nb, resources=None, km=None):
                  for idx, cell in enumerate(nb.cells):
                      if cell.cell_type == 'code' and '#TAG: pipeline_main' in cell.source:
                          self.tagged_cells.append(idx)
                  
                  print(f"üìä Found {len(self.tagged_cells)} tagged cells")
                  self.start_time = time.time()
                  return super().preprocess(nb, resources, km)
              
              def preprocess_cell(self, cell, resources, cell_index):
                  if cell.cell_type != 'code' or cell_index not in self.tagged_cells:
                      return cell, resources
                  
                  self.current_cell += 1
                  print(f"\n{'='*70}")
                  print(f"üîÑ TAGGED CELL {self.current_cell}/{len(self.tagged_cells)}")
                  print(f"{'='*70}")
                  
                  cell_start = time.time()
                  
                  try:
                      cell, resources = super().preprocess_cell(cell, resources, cell_index)
                      cell_time = time.time() - cell_start
                      
                      # Extract key output lines
                      output_lines = []
                      if cell.outputs:
                          for output in cell.outputs:
                              if output.output_type == 'stream':
                                  text = re.sub(r'\x1b\[[0-9;]*m', '', output.text)
                                  lines = text.strip().split('\n')
                                  for line in lines:
                                      if any(marker in line for marker in ['‚úÖ', '‚ö†Ô∏è', '‚ùå', 'üí∞', 'üß†', 'üíæ', 'üìä', 'Iteration', 'Mode:', 'COMPLETE', 'Win Rate', 'Total P&L']):
                                          output_lines.append(line)
                              elif output.output_type == 'error':
                                  error_name = output.get('ename', 'Error')
                                  error_value = output.get('evalue', 'Unknown error')
                                  output_lines.append(f"‚ùå {error_name}: {error_value}")
                      
                      if output_lines:
                          print("\nüìã Key Output:")
                          for line in output_lines[:30]:
                              print(f"   {line}")
                          if len(output_lines) > 30:
                              print(f"   ... ({len(output_lines) - 30} more lines)")
                      
                      print(f"\n‚úÖ Cell {self.current_cell} completed in {cell_time:.1f}s")
                      
                      self.cell_summaries.append({
                          'cell': self.current_cell,
                          'duration': cell_time,
                          'status': 'success',
                          'key_outputs': len(output_lines),
                          'outputs': output_lines[:10]
                      })
                      
                  except Exception as e:
                      cell_time = time.time() - cell_start
                      error_name = type(e).__name__
                      error_msg = str(e)
                      
                      if 'CellExecutionError' in error_name:
                          if hasattr(e, 'ename') and hasattr(e, 'evalue'):
                              error_name = e.ename
                              error_msg = e.evalue
                      
                      print(f"\n‚ùå Cell {self.current_cell} FAILED after {cell_time:.1f}s")
                      print(f"   Error Type: {error_name}")
                      print(f"   Error Message: {error_msg[:200]}")
                      
                      self.cell_summaries.append({
                          'cell': self.current_cell,
                          'duration': cell_time,
                          'status': 'failed',
                          'error': f"{error_name}: {error_msg[:100]}"
                      })
                      
                      raise RuntimeError(f"Cell {self.current_cell} execution failed: {error_name}")
                  
                  return cell, resources
          
          def run_tagged_cells(notebook_path):
              with open(notebook_path, 'r', encoding='utf-8') as f:
                  nb = nbformat.read(f, as_version=4)
              
              ep = TaggedCellExecutor(timeout=2400, kernel_name='python3', allow_errors=False)
              
              print("="*70)
              print("üöÄ STARTING TAGGED CELLS EXECUTION")
              print("="*70)
              
              start = time.time()
              
              try:
                  ep.preprocess(nb, {'metadata': {'path': '.'}})
              except Exception as e:
                  pass
              
              duration = time.time() - start
              
              print("\n" + "="*70)
              print("üìä EXECUTION SUMMARY")
              print("="*70)
              
              failed_cells = []
              success_count = 0
              for summary in ep.cell_summaries:
                  status_icon = "‚úÖ" if summary['status'] == 'success' else "‚ùå"
                  if summary['status'] == 'failed':
                      failed_cells.append(summary['cell'])
                      print(f"{status_icon} Cell {summary['cell']}: {summary['duration']:.1f}s - FAILED")
                      print(f"   ‚îî‚îÄ {summary.get('error', 'Unknown error')}")
                  else:
                      success_count += 1
                      print(f"{status_icon} Cell {summary['cell']}: {summary['duration']:.1f}s - {summary.get('key_outputs', 0)} key outputs")
              
              print(f"\n‚è±Ô∏è  Total Duration: {duration:.1f}s")
              print("="*70)
              
              # Save run report
              report = {
                  'timestamp': datetime.now().isoformat(),
                  'mode': 'tagged_cells',
                  'total_cells': len(ep.tagged_cells),
                  'successful': success_count,
                  'failed': len(failed_cells),
                  'duration': duration,
                  'cell_summaries': ep.cell_summaries
              }
              
              os.makedirs('.github/run_history', exist_ok=True)
              with open('.github/run_history/latest_run.json', 'w') as f:
                  json.dump(report, f, indent=2)
              
              if failed_cells:
                  print(f"\n‚ùå Execution completed with errors in cells: {', '.join(map(str, failed_cells))}")
                  return False
              else:
                  print(f"\n‚úÖ All cells executed successfully")
                  return True
          
          if __name__ == "__main__":
              notebook = "AI_Forex_Brain_2.ipynb"
              if not os.path.exists(notebook):
                  print(f"‚ùå Notebook not found: {notebook}")
                  sys.exit(1)
              
              try:
                  success = run_tagged_cells(notebook)
                  sys.exit(0 if success else 1)
              except Exception as e:
                  print(f"\n‚ùå FATAL ERROR: {type(e).__name__}")
                  sys.exit(1)
          EOFPYTHON
          
          # Create the full notebook executor
          cat > run_full_notebook.py << 'EOFPYTHON'
          import nbformat
          from nbconvert.preprocessors import ExecutePreprocessor
          import sys, os, time, re, json
          from datetime import datetime
          
          class SummaryExecutor(ExecutePreprocessor):
              def __init__(self, *args, **kwargs):
                  super().__init__(*args, **kwargs)
                  self.cell_count = 0
                  self.start_time = None
                  self.key_outputs = []
                  
              def preprocess(self, nb, resources=None, km=None):
                  print(f"üìä Processing {len(nb.cells)} cells...")
                  self.start_time = time.time()
                  return super().preprocess(nb, resources, km)
              
              def preprocess_cell(self, cell, resources, cell_index):
                  if cell.cell_type != 'code':
                      return cell, resources
                  
                  self.cell_count += 1
                  
                  if self.cell_count % 5 == 0:
                      elapsed = time.time() - self.start_time
                      print(f"‚è≥ Progress: {self.cell_count} cells ({elapsed:.0f}s elapsed)")
                  
                  cell, resources = super().preprocess_cell(cell, resources, cell_index)
                  
                  # Collect key outputs
                  if cell.outputs:
                      for output in cell.outputs:
                          if output.output_type == 'stream':
                              text = re.sub(r'\x1b\[[0-9;]*m', '', output.text)
                              lines = text.strip().split('\n')
                              for line in lines:
                                  if any(marker in line for marker in ['‚úÖ', '‚ö†Ô∏è', '‚ùå', 'üí∞', 'üß†', 'COMPLETE', 'Iteration', 'Win Rate', 'Total P&L']):
                                      print(f"   {line}")
                                      self.key_outputs.append(line)
                  
                  return cell, resources
          
          def run_notebook(notebook_path):
              with open(notebook_path, 'r', encoding='utf-8') as f:
                  nb = nbformat.read(f, as_version=4)
              
              ep = SummaryExecutor(timeout=2400, kernel_name='python3', allow_errors=False)
              
              print("="*70)
              print("üöÄ STARTING FULL NOTEBOOK EXECUTION")
              print("="*70)
              
              start = time.time()
              ep.preprocess(nb, {'metadata': {'path': '.'}})
              duration = time.time() - start
              
              print("\n" + "="*70)
              print(f"‚úÖ COMPLETED: {ep.cell_count} cells in {duration:.1f}s")
              print("="*70)
              
              # Save run report
              report = {
                  'timestamp': datetime.now().isoformat(),
                  'mode': 'full_notebook',
                  'total_cells': ep.cell_count,
                  'duration': duration,
                  'key_outputs': ep.key_outputs[-20:]
              }
              
              os.makedirs('.github/run_history', exist_ok=True)
              with open('.github/run_history/latest_run.json', 'w') as f:
                  json.dump(report, f, indent=2)
              
              return True
          
          if __name__ == "__main__":
              notebook = "AI_Forex_Brain_2.ipynb"
              if not os.path.exists(notebook):
                  print(f"‚ùå Notebook not found: {notebook}")
                  sys.exit(1)
              
              try:
                  success = run_notebook(notebook)
                  sys.exit(0 if success else 1)
              except Exception as e:
                  print(f"\n‚ùå FATAL ERROR: {str(e)}")
                  sys.exit(1)
          EOFPYTHON
          
          echo "‚úÖ Python executors created"

      - name: Run Weekend Tagged Cells (Weekend Mode)
        if: steps.detect_mode.outputs.execution_mode == 'weekend_tagged_cells' && steps.check_data.outputs.has_data == 'true'
        run: |
          echo "=========================================="
          echo "üèñÔ∏è WEEKEND MODE: TAGGED CELLS EXECUTION"
          echo "=========================================="
          echo "Day: $(date +'%A')"
          echo "Executing: Tagged cells only (#TAG: pipeline_main)"
          echo ""
          
          python run_tagged_cells.py "AI_Forex_Brain_2.ipynb"
          
          EXIT_CODE=$?
          if [ $EXIT_CODE -ne 0 ]; then
            echo "‚ùå Tagged cell execution failed with code $EXIT_CODE"
            exit $EXIT_CODE
          fi
          
          echo ""
          echo "‚úÖ Tagged cell execution completed successfully"
        timeout-minutes: 50

      - name: Run Full Notebook (No Data or Weekday Mode)
        if: steps.detect_mode.outputs.execution_mode == 'weekday_full_notebook' || steps.check_data.outputs.has_data == 'false'
        run: |
          echo "=========================================="
          if [ "${{ steps.check_data.outputs.has_data }}" = "false" ]; then
            echo "üîÑ FULL NOTEBOOK: INITIAL DATA COLLECTION"
            echo "=========================================="
            echo "Reason: No historical data found"
            echo "Mode: Weekend override -> Full notebook"
          else
            echo "üíº WEEKDAY MODE: FULL NOTEBOOK EXECUTION"
            echo "=========================================="
          fi
          echo ""
          
          python run_full_notebook.py "AI_Forex_Brain_2.ipynb"
          
          EXIT_CODE=$?
          if [ $EXIT_CODE -ne 0 ]; then
            echo "‚ùå Notebook execution failed with code $EXIT_CODE"
            exit $EXIT_CODE
          fi
          
          echo ""
          echo "‚úÖ Notebook execution completed successfully"
        timeout-minutes: 50

      - name: Save Run History
        if: always()
        run: |
          # Archive this run's report
          RUN_NUM="${{ steps.load_history.outputs.run_number }}"
          mkdir -p .github/run_history/archive
          
          if [ -f ".github/run_history/latest_run.json" ]; then
            cp .github/run_history/latest_run.json ".github/run_history/archive/run_${RUN_NUM}.json"
            echo "‚úÖ Archived run #${RUN_NUM} report"
          fi
          
          # Keep only last 20 runs
          cd .github/run_history/archive
          ls -t run_*.json | tail -n +21 | xargs rm -f 2>/dev/null || true
          echo "‚úÖ Cleaned old archives"

      - name: Generate Email Report
        if: steps.load_history.outputs.send_report == 'true'
        run: |
          echo "=========================================="
          echo "üìß GENERATING 10-RUN EMAIL REPORT"
          echo "=========================================="
          
          cat > generate_report.py << 'EOFPYTHON'
          import json
          import os
          from datetime import datetime
          from glob import glob
          
          def generate_html_report():
              run_files = sorted(glob('.github/run_history/archive/run_*.json'))[-10:]
              
              if not run_files:
                  return "<h2>No run history available</h2>"
              
              runs_data = []
              for file in run_files:
                  with open(file, 'r') as f:
                      runs_data.append(json.load(f))
              
              total_runs = len(runs_data)
              successful_runs = sum(1 for r in runs_data if r.get('failed', 0) == 0)
              failed_runs = total_runs - successful_runs
              avg_duration = sum(r.get('duration', 0) for r in runs_data) / total_runs
              total_cells = sum(r.get('total_cells', 0) for r in runs_data)
              
              html = f"""
              <!DOCTYPE html>
              <html>
              <head>
                  <style>
                      body {{ font-family: Arial, sans-serif; padding: 20px; background-color: #f5f5f5; }}
                      .container {{ max-width: 800px; margin: 0 auto; background: white; padding: 30px; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
                      h1 {{ color: #2c3e50; border-bottom: 3px solid #3498db; padding-bottom: 10px; }}
                      h2 {{ color: #34495e; margin-top: 30px; }}
                      .stats {{ display: grid; grid-template-columns: repeat(2, 1fr); gap: 15px; margin: 20px 0; }}
                      .stat-box {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 20px; border-radius: 8px; color: white; }}
                      .stat-box.success {{ background: linear-gradient(135deg, #11998e 0%, #38ef7d 100%); }}
                      .stat-box.warning {{ background: linear-gradient(135deg, #f093fb 0%, #f5576c 100%); }}
                      .stat-box h3 {{ margin: 0 0 10px 0; font-size: 14px; opacity: 0.9; }}
                      .stat-box .value {{ font-size: 32px; font-weight: bold; margin: 0; }}
                      .run-item {{ padding: 15px; margin: 10px 0; background: #f8f9fa; border-left: 4px solid #3498db; border-radius: 4px; }}
                      .run-item.failed {{ border-left-color: #e74c3c; }}
                      .run-item.success {{ border-left-color: #2ecc71; }}
                      .timestamp {{ color: #7f8c8d; font-size: 12px; }}
                      .mode-badge {{ display: inline-block; padding: 4px 12px; border-radius: 12px; font-size: 11px; font-weight: bold; margin-left: 10px; }}
                      .mode-weekend {{ background: #3498db; color: white; }}
                      .mode-weekday {{ background: #e74c3c; color: white; }}
                      .footer {{ margin-top: 30px; padding-top: 20px; border-top: 1px solid #ecf0f1; color: #7f8c8d; font-size: 12px; text-align: center; }}
                      .outputs {{ background: #2c3e50; color: #ecf0f1; padding: 10px; border-radius: 4px; font-family: monospace; font-size: 11px; max-height: 200px; overflow-y: auto; margin-top: 10px; }}
                  </style>
              </head>
              <body>
                  <div class="container">
                      <h1>ü§ñ Forex AI Pipeline - 10 Run Report</h1>
                      <p><strong>Report Period:</strong> {runs_data[0]['timestamp'][:10]} to {runs_data[-1]['timestamp'][:10]}</p>
                      
                      <div class="stats">
                          <div class="stat-box success">
                              <h3>‚úÖ Successful Runs</h3>
                              <p class="value">{successful_runs}/{total_runs}</p>
                          </div>
                          <div class="stat-box warning">
                              <h3>‚ùå Failed Runs</h3>
                              <p class="value">{failed_runs}</p>
                          </div>
                          <div class="stat-box">
                              <h3>‚è±Ô∏è Avg Duration</h3>
                              <p class="value">{avg_duration:.1f}s</p>
                          </div>
                          <div class="stat-box">
                              <h3>üìä Total Cells</h3>
                              <p class="value">{total_cells}</p>
                          </div>
                      </div>
                      
                      <h2>üìã Recent Runs</h2>
              """
              
              for i, run in enumerate(reversed(runs_data[-5:]), 1):
                  status = "success" if run.get('failed', 0) == 0 else "failed"
                  status_icon = "‚úÖ" if status == "success" else "‚ùå"
                  mode = run.get('mode', 'unknown')
                  mode_badge = f'<span class="mode-badge mode-weekend">üèñÔ∏è Weekend</span>' if mode == 'tagged_cells' else f'<span class="mode-badge mode-weekday">üíº Weekday</span>'
                  
                  timestamp = datetime.fromisoformat(run['timestamp']).strftime('%Y-%m-%d %H:%M UTC')
                  
                  html += f"""
                      <div class="run-item {status}">
                          <strong>{status_icon} Run #{len(runs_data) - i + 1}</strong> {mode_badge}
                          <div class="timestamp">{timestamp}</div>
                          <p>Duration: {run.get('duration', 0):.1f}s | Cells: {run.get('total_cells', 0)}</p>
                  """
                  
                  if 'key_outputs' in run and run['key_outputs']:
                      html += '<div class="outputs">'
                      for output in run['key_outputs'][-5:]:
                          html += f"{output}<br>"
                      html += '</div>'
                  
                  html += "</div>"
              
              html += f"""
                      <div class="footer">
                          <p>ü§ñ Generated by Trade Beacon v17.1 | Run #{len(runs_data)}</p>
                          <p>GitHub Repository: {os.getenv('GITHUB_USERNAME')}/{os.getenv('GITHUB_REPO')}</p>
                      </div>
                  </div>
              </body>
              </html>
              """
              
              return html
          
          if __name__ == "__main__":
              html_content = generate_html_report()
              with open('email_report.html', 'w') as f:
                  f.write(html_content)
              print("‚úÖ Email report generated")
          EOFPYTHON
          
          python generate_report.py
          echo "‚úÖ Report generated successfully"

      - name: Send Email Report
        if: steps.load_history.outputs.send_report == 'true'
        run: |
          echo "üìß Sending email report..."
          
          cat > send_email.py << 'EOFPYTHON'
          import smtplib
          from email.mime.multipart import MIMEMultipart
          from email.mime.text import MIMEText
          import os
          from datetime import datetime
          
          def send_email():
              sender = os.getenv('GMAIL_USER')
              password = os.getenv('GMAIL_APP_PASSWORD')
              recipient = os.getenv('GMAIL_USER')
              
              if not sender or not password:
                  print("‚ùå Gmail credentials not found")
                  return False
              
              with open('email_report.html', 'r') as f:
                  html_content = f.read()
              
              msg = MIMEMultipart('alternative')
              msg['Subject'] = f'ü§ñ Forex AI Pipeline - 10 Run Progress Report ({datetime.now().strftime("%Y-%m-%d")})'
              msg['From'] = sender
              msg['To'] = recipient
              
              html_part = MIMEText(html_content, 'html')
              msg.attach(html_part)
              
              try:
                  server = smtplib.SMTP('smtp.gmail.com', 587)
                  server.starttls()
                  server.login(sender, password)
                  server.send_message(msg)
                  server.quit()
                  
                  print(f"‚úÖ Email sent successfully to {recipient}")
                  return True
                  
              except Exception as e:
                  print(f"‚ùå Failed to send email: {str(e)}")
                  return False
          
          if __name__ == "__main__":
              success = send_email()
              exit(0 if success else 1)
          EOFPYTHON
          
          python send_email.py
          
          if [ $? -eq 0 ]; then
            echo "‚úÖ Email report sent successfully"
          else
            echo "‚ö†Ô∏è  Email sending failed, but continuing workflow"
          fi

      - name: Extract Performance Metrics
        if: always()
        run: |
          echo "=========================================="
          echo "üìä EXTRACTING PERFORMANCE METRICS"
          echo "=========================================="
          
          if [ -f "database/memory_v85.db" ]; then
            python << 'EOFPYTHON'
          import sqlite3
          import json
          import os
          
          try:
              conn = sqlite3.connect('database/memory_v85.db')
              cursor = conn.cursor()
              
              cursor.execute("SELECT COUNT(*), SUM(profit_loss), AVG(profit_loss) FROM completed_trades")
              total_trades, total_pnl, avg_pnl = cursor.fetchone()
              
              cursor.execute("SELECT COUNT(*) FROM completed_trades WHERE profit_loss > 0")
              winning_trades = cursor.fetchone()[0]
              
              win_rate = (winning_trades / total_trades * 100) if total_trades > 0 else 0
              
              cursor.execute("SELECT COUNT(*) FROM pending_trades")
              pending = cursor.fetchone()[0]
              
              metrics = {
                  'total_trades': total_trades or 0,
                  'total_pnl': float(total_pnl or 0),
                  'avg_pnl': float(avg_pnl or 0),
                  'win_rate': round(win_rate, 2),
                  'winning_trades': winning_trades or 0,
                  'pending_trades': pending or 0
              }
              
              conn.close()
              
              os.makedirs('.github/run_history', exist_ok=True)
              with open('.github/run_history/latest_metrics.json', 'w') as f:
                  json.dump(metrics, f, indent=2)
              
              print(f"‚úÖ Extracted metrics:")
              print(f"   Total Trades: {metrics['total_trades']}")
              print(f"   Win Rate: {metrics['win_rate']}%")
              print(f"   Total P&L: ${metrics['total_pnl']:.2f}")
              print(f"   Pending: {metrics['pending_trades']}")
              
          except Exception as e:
              print(f"‚ö†Ô∏è  Could not extract metrics: {str(e)}")
              with open('.github/run_history/latest_metrics.json', 'w') as f:
                  json.dump({'error': 'No data available'}, f)
          EOFPYTHON
          else
            echo "‚ö†Ô∏è  No database found, skipping metrics extraction"
          fi
          
          echo "=========================================="

      - name: Verify output files
        if: always()
        run: |
          echo "=========================================="
          echo "üìã CHECKING OUTPUT FILES"
          echo "=========================================="
          
          for dir in outputs data/processed logs database rl_memory rl_models omega_state; do
            if [ -d "$dir" ]; then
              FILE_COUNT=$(find "$dir" -type f 2>/dev/null | wc -l)
              echo "  ‚úÖ $dir/ ($FILE_COUNT files)"
            fi
          done
          
          PICKLE_COUNT=$(find data/processed -name "*.pkl" -type f 2>/dev/null | \
            grep -v "_sgd_model\|_rf_model\|indicator_cache\|ultra_\|alpha_\|_model.pkl\|\.bak" | wc -l)
          echo ""
          echo "üìä Post-execution data files: $PICKLE_COUNT pickles"
          
          echo "=========================================="

      - name: Clean up nested repositories
        if: always()
        run: |
          find . -mindepth 2 -type d -name ".git" -exec rm -rf {} + 2>/dev/null || true
          echo "‚úÖ Cleanup complete"

      - name: Commit and push changes
        if: always()
        run: |
          git add -A
          
          if git diff --cached --quiet; then
            echo "‚ÑπÔ∏è  No changes to commit"
          else
            TIMESTAMP=$(date +'%Y-%m-%d %H:%M UTC')
            DAY=$(date +'%A')
            MODE="${{ steps.detect_mode.outputs.execution_mode }}"
            HAS_DATA="${{ steps.check_data.outputs.has_data }}"
            RUN_NUM="${{ steps.load_history.outputs.run_number }}"
            
            if [ "$HAS_DATA" = "false" ]; then
              COMMIT_MSG="üîÑ Trade Beacon v17.1 [Run #${RUN_NUM}] Initial Data Collection - $DAY: $TIMESTAMP"
            elif [ "$MODE" = "weekend_tagged_cells" ]; then
              COMMIT_MSG="üèñÔ∏è Trade Beacon v17.1 [Run #${RUN_NUM}] Weekend Learning - $DAY: $TIMESTAMP"
            else
              COMMIT_MSG="üî¥ Trade Beacon v17.1 [Run #${RUN_NUM}] Live Trading - $DAY: $TIMESTAMP"
            fi
            
            if [ "${{ steps.load_history.outputs.send_report }}" = "true" ]; then
              COMMIT_MSG="${COMMIT_MSG} üìß"
            fi
            
            git commit -m "$COMMIT_MSG" || true
            
            for i in {1..3}; do
              if git push origin main 2>&1; then
                echo "‚úÖ Pushed on attempt $i"
                break
              else
                if [ $i -lt 3 ]; then
                  sleep 3
                  git pull --rebase origin main
                fi
              fi
            done
          fi

      - name: Upload logs and artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: execution-logs-${{ github.run_number }}
          path: |
            run_full_notebook.py
            run_tagged_cells.py
            email_report.html
            logs/*.log
            .github/run_history/*.json
          retention-days: 7
          if-no-files-found: ignore

      - name: Execution Summary
        if: always()
        run: |
          echo "=========================================="
          echo "üìä EXECUTION SUMMARY"
          echo "=========================================="
          echo "Run Number: #${{ steps.load_history.outputs.run_number }}"
          echo "Mode: ${{ steps.detect_mode.outputs.execution_mode }}"
          echo "Had Data: ${{ steps.check_data.outputs.has_data }}"
          echo "Day: $(date +'%A')"
          echo "Time: $(date +'%B %d, %Y %H:%M UTC')"
          
          if [ "${{ steps.load_history.outputs.send_report }}" = "true" ]; then
            echo "üìß Email Report: SENT (10-run milestone)"
          else
            NEXT_REPORT=$((10 - (${{ steps.load_history.outputs.run_number }} % 10)))
            echo "üìß Email Report: Next in ${NEXT_REPORT} run(s)"
          fi
          
          echo "=========================================="
          
          if [ "${{ steps.check_data.outputs.has_data }}" = "false" ]; then
            echo "‚úÖ Initial data collection completed"
          elif [ "${{ steps.detect_mode.outputs.execution_mode }}" = "weekend_tagged_cells" ]; then
            echo "‚úÖ Weekend tagged cells execution completed"
          else
            echo "‚úÖ Weekday full notebook execution completed"
          fi
          
          echo "=========================================="
