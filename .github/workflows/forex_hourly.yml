name: Run AI Forex Brain Pipeline (Hourly)

on:
  # Run every hour at minute 0
  schedule:
    - cron: '0 * * * *'
  
  # Manual trigger
  workflow_dispatch:
  
  # Trigger on push to notebook or trigger file
  push:
    paths:
      - 'colab_trigger.txt'
      - 'AI_Forex_Brain_2.ipynb'
    branches:
      - main

jobs:
  run-forex-brain:
    runs-on: ubuntu-latest
    timeout-minutes: 55  # Complete before next hourly run
    
    env:
      # Required secrets
      FOREX_PAT: ${{ secrets.FOREX_PAT }}
      BROWSERLESS_TOKEN: ${{ secrets.BROWSERLESS_TOKEN }}
      ALPHA_VANTAGE_KEY: ${{ secrets.ALPHA_VANTAGE_KEY }}
      
      # ğŸ”§ FIX: Remove environment variables for Gmail - let code use hardcoded values
      # GMAIL_USER: ${{ secrets.GMAIL_USER }}
      # GMAIL_APP_PASSWORD: ${{ secrets.GMAIL_APP_PASSWORD }}
      
      # Git configuration
      GIT_USER_NAME: "Forex AI Bot"
      GIT_USER_EMAIL: "nakatonabira3@gmail.com"
      GITHUB_USERNAME: "rahim-dotAI"
      GITHUB_REPO: "forex-ai-models"
      
      # Python configuration
      PYTHONIOENCODING: utf-8
      PYTHONUNBUFFERED: 1
      GITHUB_ACTIONS: "true"
      
      # Pipeline mode configuration
      SINGLE_RUN_MODE: "true"  # Force single run, no loop

    steps:
      # 0ï¸âƒ£ Cleanup
      - name: Pre-cleanup
        run: |
          echo "ğŸ§¹ Cleaning workspace..."
          sudo rm -rf /content 2>/dev/null || true
          rm -f .gitmodules 2>/dev/null || true
          echo "âœ… Workspace cleaned"

      # 1ï¸âƒ£ Checkout
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          persist-credentials: false
          fetch-depth: 0
          lfs: false
          submodules: false
          clean: true

      # 2ï¸âƒ£ Verify secrets (UPDATED - Skip Gmail check)
      - name: Verify required secrets
        run: |
          MISSING_SECRETS=()
          
          [ -z "${FOREX_PAT}" ] && MISSING_SECRETS+=("FOREX_PAT")
          [ -z "${BROWSERLESS_TOKEN}" ] && MISSING_SECRETS+=("BROWSERLESS_TOKEN")
          [ -z "${ALPHA_VANTAGE_KEY}" ] && MISSING_SECRETS+=("ALPHA_VANTAGE_KEY")
          # Gmail credentials are hardcoded in script, so we skip checking them here
          
          if [ ${#MISSING_SECRETS[@]} -gt 0 ]; then
            echo "âŒ Missing required secrets: ${MISSING_SECRETS[*]}"
            echo "âš ï¸ Pipeline will run with limited functionality"
          else
            echo "âœ… All required secrets are configured"
          fi
          
          echo "ğŸ“§ Gmail: Using hardcoded credentials from script"

      # 3ï¸âƒ£ Python setup
      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: 'pip'

      # 4ï¸âƒ£ Install dependencies
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip wheel setuptools
          pip install --no-cache-dir \
            mplfinance firebase-admin dropbox requests beautifulsoup4 \
            pandas numpy ta yfinance pyppeteer nest_asyncio lightgbm \
            joblib matplotlib alpha_vantage tqdm scikit-learn river \
            jupyter nbconvert
          echo "âœ… Dependencies installed"

      # 5ï¸âƒ£ Create unified directory structure
      - name: Create directory structure
        run: |
          # Create /content structure (Colab-style)
          sudo mkdir -p /content/forex-alpha-models/{csvs,pickles,logs,merged_data_pickles,temp_pickles,forex-ai-models}
          
          # Set ownership and permissions
          sudo chown -R $USER:$USER /content
          sudo chmod -R 755 /content
          
          # Create working directories in runner workspace
          mkdir -p $GITHUB_WORKSPACE/outputs/{csvs,pickles,logs,merged_data_pickles,temp_pickles}
          
          echo "âœ… Directory structure created"
          echo "ğŸ“‚ Created paths:"
          ls -la /content/forex-alpha-models/

      # 6ï¸âƒ£ Configure Git
      - name: Configure Git
        run: |
          git config --global user.name "${GIT_USER_NAME}"
          git config --global user.email "${GIT_USER_EMAIL}"
          git config --global advice.detachedHead false
          git config --global credential.helper store
          echo "https://${GITHUB_USERNAME}:${FOREX_PAT}@github.com" > ~/.git-credentials
          echo "âœ… Git configured"

      # 7ï¸âƒ£ Convert notebook and patch for single-run mode
      - name: Convert and patch notebook for hourly execution
        run: |
          echo "ğŸ“ Converting notebook to Python..."
          jupyter nbconvert --to python "AI_Forex_Brain_2.ipynb" --output ai_forex_brain_2
          
          echo "ğŸ”§ Applying comprehensive patches for SINGLE RUN MODE..."
          
          # Remove Jupyter magic commands
          sed -i '/get_ipython()/d' ai_forex_brain_2.py
          sed -i '/^get_ipython/d' ai_forex_brain_2.py
          
          # Fix all .mkdir() calls to include parents=True
          sed -i 's/\.mkdir(exist_ok=True)/.mkdir(parents=True, exist_ok=True)/g' ai_forex_brain_2.py
          
          # ğŸ”§ FIX: Remove os.environ.get() for Gmail credentials - force hardcoded values
          echo "ğŸ”§ Patching Gmail credentials to use hardcoded values..."
          sed -i 's/GMAIL_USER = os\.environ\.get("GMAIL_USER", "nakatonabira3@gmail\.com")/GMAIL_USER = "nakatonabira3@gmail.com"/g' ai_forex_brain_2.py
          sed -i 's/GMAIL_APP_PASSWORD = os\.environ\.get("GMAIL_APP_PASSWORD", "gmwohahtltmcewug")/GMAIL_APP_PASSWORD = "gmwohahtltmcewug"/g' ai_forex_brain_2.py
          
          # Comprehensive path fixes - Replace ALL path definitions
          cat > path_fixes.sed << 'EOF'
          # Root directory fixes
          s|ROOT_DIR = Path("/content")|ROOT_DIR = Path("/content/forex-alpha-models")|g
          s|ROOT_PATH = ROOT_DIR / "forex-alpha-models"|ROOT_PATH = Path("/content/forex-alpha-models")|g
          s|ROOT_DIR = Path(".")|ROOT_DIR = Path("/content/forex-alpha-models")|g
          
          # Base directory fixes
          s|BASE_DIR = Path("/content/forex-alpha-models")|BASE_DIR = Path("/content/forex-alpha-models")|g
          s|BASE_DIR = Path("./forex-alpha-models")|BASE_DIR = Path("/content/forex-alpha-models")|g
          s|BASE_FOLDER = Path("/content/forex-alpha-models")|BASE_FOLDER = Path("/content/forex-alpha-models")|g
          s|BASE_FOLDER = Path(".")|BASE_FOLDER = Path("/content/forex-alpha-models")|g
          
          # Repository folder fix
          s|REPO_FOLDER = .* / "forex-ai-models"|REPO_FOLDER = Path("/content/forex-alpha-models/forex-ai-models")|g
          
          # Pickle folder fixes
          s|PICKLE_FOLDER = .* / "pickles"|PICKLE_FOLDER = Path("/content/forex-alpha-models/pickles")|g
          s|FINAL_PICKLE_FOLDER = .* / "merged_data_pickles"|FINAL_PICKLE_FOLDER = Path("/content/forex-alpha-models/merged_data_pickles")|g
          s|CSV_FOLDER = .* / "csvs"|CSV_FOLDER = Path("/content/forex-alpha-models/csvs")|g
          s|LOG_FOLDER = .* / "logs"|LOG_FOLDER = Path("/content/forex-alpha-models/logs")|g
          s|LOGS_FOLDER = .* / "logs"|LOGS_FOLDER = Path("/content/forex-alpha-models/logs")|g
          s|TEMP_PICKLE_FOLDER = .* / "temp_pickles"|TEMP_PICKLE_FOLDER = Path("/content/forex-alpha-models/temp_pickles")|g
          
          # Database and state files
          s|INFINITE_MEMORY_DB = .* / "infinite_memory.db"|INFINITE_MEMORY_DB = Path("/content/forex-alpha-models/forex-ai-models/infinite_memory.db")|g
          s|TRADE_MEMORY_DB = .* / "hybrid_ml_memory.db"|TRADE_MEMORY_DB = Path("/content/forex-alpha-models/forex-ai-models/hybrid_ml_memory.db")|g
          s|MONDAY_RUNS_FILE = .* / "monday_runs.pkl"|MONDAY_RUNS_FILE = Path("/content/forex-alpha-models/forex-ai-models/monday_runs.pkl")|g
          s|LEARNING_PROGRESS_FILE = .* / "learning_progress.pkl"|LEARNING_PROGRESS_FILE = Path("/content/forex-alpha-models/forex-ai-models/learning_progress.pkl")|g
          s|PREVIOUS_SIGNALS_FILE = .* / "previous_signals.pkl"|PREVIOUS_SIGNALS_FILE = Path("/content/forex-alpha-models/forex-ai-models/previous_signals.pkl")|g
          s|ITERATION_COUNTER_FILE = .* / "iteration_counter.pkl"|ITERATION_COUNTER_FILE = Path("/content/forex-alpha-models/forex-ai-models/iteration_counter.pkl")|g
          s|ML_ITERATION_COUNTER_FILE = .* / "ml_iteration_counter.pkl"|ML_ITERATION_COUNTER_FILE = Path("/content/forex-alpha-models/forex-ai-models/ml_iteration_counter.pkl")|g
          
          # Signal files
          s|SIGNALS_JSON_PATH = .* / "broker_signals.json"|SIGNALS_JSON_PATH = Path("/content/forex-alpha-models/forex-ai-models/broker_signals.json")|g
          s|ENSEMBLE_SIGNALS_FILE = .* / "ensemble_signals.json"|ENSEMBLE_SIGNALS_FILE = Path("/content/forex-alpha-models/forex-ai-models/ensemble_signals.json")|g
          s|JSON_FILE = .* / "latest_signals.json"|JSON_FILE = Path("/content/forex-alpha-models/forex-ai-models/latest_signals.json")|g
          EOF
          
          sed -i -f path_fixes.sed ai_forex_brain_2.py
          
          # Fix the ensure_repo() function to clone into correct location
          sed -i 's|subprocess.run(\["git", "clone"|subprocess.run(["git", "clone", "-b", "main"|g' ai_forex_brain_2.py
          
          # ğŸ†• CRITICAL: Remove the infinite loop - convert to single run
          echo "ğŸ”§ Converting infinite loop to single run mode..."
          
          # Create single-run patch
          cat > single_run_patch.py << 'EOFPATCH'
          import re
          
          # Read the converted script
          with open('ai_forex_brain_2.py', 'r') as f:
              content = f.read()
          
          # Find and modify the main execution loop
          # Replace: while not shutdown_handler.is_shutdown_requested():
          # With: if True:  # Single run mode for hourly GitHub Actions
          
          content = re.sub(
              r'while not shutdown_handler\.is_shutdown_requested\(\):',
              'if True:  # Single run mode for hourly GitHub Actions',
              content
          )
          
          # Remove or modify sleep statements
          # Replace: time.sleep(CHECK_INTERVAL)
          # With: pass  # No sleep in single-run mode
          
          content = re.sub(
              r'time\.sleep\(CHECK_INTERVAL\)',
              'pass  # No sleep in single-run mode',
              content
          )
          
          # Also handle other sleep patterns
          content = re.sub(
              r'time\.sleep\(\d+\)',
              'pass  # No sleep in single-run mode',
              content
          )
          
          # Remove weekend replay continuous loop
          # Find: while replay_system.advance_time(REPLAY_CONFIG['replay_advance_minutes']):
          # Replace with conditional that runs once
          content = re.sub(
              r'while replay_system\.advance_time\(.*?\):',
              'if replay_system.advance_time(REPLAY_CONFIG["replay_advance_minutes"]):  # Single iteration',
              content
          )
          
          # BETTER APPROACH: Replace the entire main() function's try block end
          # Find the pattern: "while not shutdown" or "if True:" and change loop behavior
          # Instead of adding break, we'll modify the loop condition itself
          
          # Find: WEEKEND_MONDAY_MANAGER.should_sleep_after_iteration()
          # Add exit logic after that check
          content = re.sub(
              r'(if WEEKEND_MONDAY_MANAGER\.should_sleep_after_iteration\(\):.*?print_status.*?"info"\))',
              r'\1\n                break  # Exit after single iteration (hourly mode)',
              content,
              flags=re.DOTALL
          )
          
          # Alternative: Add break after the final else clause in the main loop
          content = re.sub(
              r'(else:\s+print_status\([^)]+no sleep in replay mode[^)]+\))',
              r'\1\n                break  # Exit after single iteration (hourly mode)',
              content
          )
          
          # Write patched content
          with open('ai_forex_brain_2.py', 'w') as f:
              f.write(content)
          
          print("âœ… Converted to single-run mode")
          EOFPATCH
          
          # Run the single-run patch
          python single_run_patch.py
          
          # Add safety check at the beginning of the script
          cat > safety_header.py << 'EOF'
          import os
          import sys
          from pathlib import Path
          
          # GitHub Actions environment check
          if os.environ.get("GITHUB_ACTIONS") == "true":
              print("ğŸ”§ GitHub Actions environment detected - HOURLY MODE")
              print("â° Single run mode: Pipeline will execute once and exit")
              os.environ["IN_GHA"] = "1"
          
          # Ensure /content directory exists
          Path("/content/forex-alpha-models").mkdir(parents=True, exist_ok=True)
          Path("/content/forex-alpha-models/forex-ai-models").mkdir(parents=True, exist_ok=True)
          
          print(f"âœ… Working directory: {os.getcwd()}")
          print(f"âœ… /content exists: {Path('/content/forex-alpha-models').exists()}")
          
          EOF
          
          # Prepend safety header to the script
          cat safety_header.py ai_forex_brain_2.py > ai_forex_brain_2_patched.py
          mv ai_forex_brain_2_patched.py ai_forex_brain_2.py
          
          echo "âœ… Notebook converted and patched for hourly single-run mode"
          echo "âœ… Gmail credentials patched to use hardcoded values"
          
          # Show conversion summary
          echo "ğŸ“Š Conversion Summary:"
          echo "  - Removed infinite loop"
          echo "  - Disabled sleep statements"
          echo "  - Single iteration mode enabled"
          echo "  - Gmail credentials: HARDCODED (not using env vars)"
          echo "  - Ready for hourly execution"

      # 8ï¸âƒ£ Pre-populate forex-ai-models repo
      - name: Clone forex-ai-models repository
        run: |
          cd /content/forex-alpha-models
          
          if [ ! -d "forex-ai-models/.git" ]; then
            echo "ğŸ“¥ Cloning forex-ai-models repository..."
            git clone -b main https://${GITHUB_USERNAME}:${FOREX_PAT}@github.com/${GITHUB_USERNAME}/${GITHUB_REPO}.git forex-ai-models
            echo "âœ… Repository cloned"
          else
            echo "âœ… Repository already exists"
            cd forex-ai-models
            git pull origin main
            echo "âœ… Repository updated"
          fi
          
          cd forex-ai-models
          git config user.name "${GIT_USER_NAME}"
          git config user.email "${GIT_USER_EMAIL}"
          
          echo "ğŸ“‚ Repository structure:"
          ls -la

      # 9ï¸âƒ£ Execute pipeline (SINGLE RUN)
      - name: Run AI Forex Brain Pipeline (Single Iteration)
        run: |
          echo "ğŸš€ Starting AI Forex Brain Pipeline (HOURLY MODE)..."
          echo "================================================"
          echo "â° Mode: SINGLE RUN (No loop, completes and exits)"
          echo "ğŸ“§ Gmail: Using hardcoded credentials"
          echo "ğŸ“Š Environment:"
          echo "  - Python: $(python --version)"
          echo "  - Working Dir: $(pwd)"
          echo "  - /content exists: $([ -d /content/forex-alpha-models ] && echo 'YES' || echo 'NO')"
          echo "  - Next run: In ~1 hour (automatic)"
          echo "================================================"
          
          # Run the pipeline (single iteration)
          python ai_forex_brain_2.py 2>&1 | tee pipeline_output.log
          
          EXIT_CODE=${PIPESTATUS[0]}
          
          echo "================================================"
          echo "ğŸ“Š Pipeline Exit Code: $EXIT_CODE"
          echo "================================================"
          
          if [ $EXIT_CODE -ne 0 ]; then
            echo "âŒ Pipeline failed with exit code $EXIT_CODE"
            echo "ğŸ“ Last 50 lines of output:"
            tail -n 50 pipeline_output.log
            exit $EXIT_CODE
          fi
          
          echo "âœ… Pipeline completed successfully (single iteration)"
          echo "â° Next automatic run: $(date -d '+1 hour' '+%Y-%m-%d %H:00:00 UTC')"
        timeout-minutes: 50

      # ğŸ”Ÿ Collect outputs
      - name: Collect pipeline outputs
        if: always()
        run: |
          echo "ğŸ“¦ Collecting outputs..."
          
          # Copy outputs to workspace for artifact upload
          cp -r /content/forex-alpha-models/logs $GITHUB_WORKSPACE/outputs/ 2>/dev/null || true
          cp -r /content/forex-alpha-models/merged_data_pickles $GITHUB_WORKSPACE/outputs/ 2>/dev/null || true
          cp -r /content/forex-alpha-models/pickles $GITHUB_WORKSPACE/outputs/ 2>/dev/null || true
          
          # Copy signals
          mkdir -p $GITHUB_WORKSPACE/outputs/signals
          cp /content/forex-alpha-models/forex-ai-models/*.json $GITHUB_WORKSPACE/outputs/signals/ 2>/dev/null || true
          
          # Copy logs
          cp pipeline_output.log $GITHUB_WORKSPACE/outputs/logs/ 2>/dev/null || true
          cp forex_pipeline.log $GITHUB_WORKSPACE/outputs/logs/ 2>/dev/null || true
          
          # Copy state files for persistence
          cp /content/forex-alpha-models/forex-ai-models/*.pkl $GITHUB_WORKSPACE/outputs/ 2>/dev/null || true
          cp /content/forex-alpha-models/forex-ai-models/*.db $GITHUB_WORKSPACE/outputs/ 2>/dev/null || true
          
          echo "âœ… Outputs collected"
          echo "ğŸ“‚ Output structure:"
          find $GITHUB_WORKSPACE/outputs -type f

      # 1ï¸âƒ£1ï¸âƒ£ Upload artifacts
      - name: Upload pipeline logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: forex-pipeline-logs-${{ github.run_number }}
          path: |
            outputs/logs/*.log
            pipeline_output.log
          retention-days: 7

      - name: Upload pickles
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: forex-pickles-${{ github.run_number }}
          path: |
            outputs/merged_data_pickles/*.pkl
            outputs/pickles/*.pkl
            outputs/*.pkl
          retention-days: 3

      - name: Upload signals
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: forex-signals-${{ github.run_number }}
          path: outputs/signals/*.json
          retention-days: 7

      # 1ï¸âƒ£2ï¸âƒ£ Commit and push
      - name: Commit and push results
        if: success()
        run: |
          cd /content/forex-alpha-models/forex-ai-models
          
          echo "ğŸ“¦ Staging changes..."
          git add -A
          
          if git diff --staged --quiet; then
            echo "âœ… No changes to commit"
            exit 0
          fi
          
          echo "ğŸ’¾ Committing changes..."
          ITERATION_INFO=$(grep -oP 'Iteration #\K\d+' /content/forex-alpha-models/pipeline_output.log | tail -1 || echo "N/A")
          git commit -m "ğŸ¤– Hourly update #${ITERATION_INFO}: AI Forex Brain [$(date '+%Y-%m-%d %H:%M:%S UTC')]" || {
            echo "âš ï¸ Commit failed or nothing to commit"
            exit 0
          }
          
          echo "ğŸ”„ Pulling latest changes..."
          git pull --rebase origin main || echo "âš ï¸ Nothing to pull"
          
          echo "ğŸ“¤ Pushing changes..."
          git push origin main && echo "âœ… Changes pushed" || echo "âš ï¸ Push failed"

      # 1ï¸âƒ£3ï¸âƒ£ Cleanup
      - name: Cleanup sensitive data
        if: always()
        run: |
          rm -f ~/.git-credentials
          rm -f /content/forex-alpha-models/forex-ai-models/.git/credentials 2>/dev/null || true
          echo "âœ… Sensitive data cleaned"

      # 1ï¸âƒ£4ï¸âƒ£ Summary
      - name: Pipeline summary
        if: always()
        run: |
          echo "================================================"
          echo "ğŸ¯ AI FOREX BRAIN HOURLY PIPELINE SUMMARY"
          echo "================================================"
          echo "ğŸ“… Timestamp: $(date)"
          echo "ğŸ”¢ Run Number: ${{ github.run_number }}"
          echo "ğŸ”§ Python: $(python --version)"
          echo "â° Execution Mode: SINGLE RUN (Hourly)"
          echo "ğŸ“§ Gmail: Hardcoded credentials (not using env vars)"
          echo "ğŸ“‚ Working Dir: $(pwd)"
          echo "================================================"
          
          if [ -f "pipeline_output.log" ]; then
            echo "ğŸ“ Pipeline Completion Status:"
            tail -n 30 pipeline_output.log | grep -E "(âœ…|âŒ|ğŸ†|ğŸ’¼|ğŸ¬)" || tail -n 30 pipeline_output.log
          fi
          
          echo "================================================"
          echo "Status: ${{ job.status }}"
          echo "â° Next scheduled run: $(date -d '+1 hour' '+%Y-%m-%d %H:00:00 UTC')"
          echo "================================================"
