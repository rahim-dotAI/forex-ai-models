name: Multi-Source Learning System v21.0 - Manual Trigger

on:
  workflow_dispatch:
  push:
    paths: ['colab_trigger.txt']
    branches: [main]

jobs:
  run-learning-system:
    runs-on: ubuntu-latest
    timeout-minutes: 55
    concurrency:
      group: forex-learning-system
      cancel-in-progress: false

    env:
      FOREX_PAT: ${{ secrets.FOREX_PAT }}
      BROWSERLESS_TOKEN: ${{ secrets.BROWSERLESS_TOKEN }}
      ALPHA_VANTAGE_KEY: ${{ secrets.ALPHA_VANTAGE_KEY }}
      GMAIL_USER: ${{ secrets.GMAIL_USER }}
      GMAIL_APP_PASSWORD: ${{ secrets.GMAIL_APP_PASSWORD }}
      GIT_USER_NAME: "Forex AI Bot"
      GIT_USER_EMAIL: "nakatonabira3@gmail.com"
      PYTHONIOENCODING: utf-8
      PYTHONUNBUFFERED: 1
      GITHUB_ACTIONS: "true"
      SINGLE_RUN_MODE: "true"

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          persist-credentials: false
          fetch-depth: 0
          token: ${{ secrets.FOREX_PAT }}

      - name: Fix Submodules
        run: |
          [ -f ".gitmodules" ] && rm -f .gitmodules && git rm --cached -r forex-alpha-models 2>/dev/null || true
          find . -mindepth 2 -name ".git" -type d -exec rm -rf {} + 2>/dev/null || true

      - name: Detect Day Type and Schedule
        id: day_info
        run: |
          HOUR=$(date +%H)
          DAY=$(date +%u)
          DAY_NAME=$(date +'%A')
          
          echo "day=$DAY" >> $GITHUB_OUTPUT
          echo "day_name=$DAY_NAME" >> $GITHUB_OUTPUT
          echo "hour=$HOUR" >> $GITHUB_OUTPUT
          
          # Alpha Vantage runs ONLY at 00:00 UTC on weekdays (SAME AS PIPEDREAM!)
          if [ "$HOUR" = "00" ] && [ $DAY -ge 1 ] && [ $DAY -le 5 ]; then
            echo "is_alpha_run=true" >> $GITHUB_OUTPUT
            echo "SKIP_ALPHA_VANTAGE=false" >> $GITHUB_ENV
            echo "ðŸŒ™ ALPHA VANTAGE RUN (00:00 UTC = 3:00 AM EAT)"
          else
            echo "is_alpha_run=false" >> $GITHUB_OUTPUT
            echo "SKIP_ALPHA_VANTAGE=true" >> $GITHUB_ENV
            echo "âš¡ Regular run - Alpha Vantage SKIPPED"
          fi
          
          if [ $DAY -eq 6 ] || [ $DAY -eq 7 ]; then
            echo "is_weekend=true" >> $GITHUB_OUTPUT
            echo "ðŸ–ï¸ $DAY_NAME (Weekend - Adaptive Learning Mode)"
            echo "ðŸ“Š Using 2-hour intervals (adaptive evaluation windows)"
          else
            echo "is_weekend=false" >> $GITHUB_OUTPUT
            echo "ðŸ’¼ $DAY_NAME (Weekday - Live Trading)"
          fi
          
          echo ""
          echo "ðŸ“… Current: $DAY_NAME at $HOUR:00 UTC"
          echo "âš¡ Triggered by: Push to colab_trigger.txt or Manual"
          echo "ðŸ• Next run: Manual trigger required"

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip

      - name: Install Dependencies
        run: |
          pip install -q --no-cache-dir pandas numpy requests beautifulsoup4 scikit-learn \
            jupyter nbconvert nbformat ta yfinance mplfinance firebase-admin dropbox \
            pyppeteer nest_asyncio lightgbm joblib matplotlib alpha_vantage tqdm river scipy

      - name: Configure Git
        run: |
          git config --global user.name "Forex AI Bot"
          git config --global user.email "nakatonabira3@gmail.com"
          echo "https://${{ github.actor }}:${{ secrets.FOREX_PAT }}@github.com" > ~/.git-credentials
          git config --global credential.helper store

      - name: Check Data Status
        id: data
        run: |
          echo "ðŸ“Š Checking existing data files..."
          
          PICKLE_COUNT=$(find data/processed -name "*.pkl" -type f ! -name "*_model.pkl" 2>/dev/null | wc -l)
          echo "pickle_count=$PICKLE_COUNT" >> $GITHUB_OUTPUT
          
          if [ -f "rl_memory/experience_replay.json.gz" ]; then
            echo "rl_memory_exists=true" >> $GITHUB_OUTPUT
          else
            echo "rl_memory_exists=false" >> $GITHUB_OUTPUT
          fi
          
          if [ -f "learning_data/learning_outcomes.json" ]; then
            LEARNING_COUNT=$(python3 -c "import json; print(len(json.load(open('learning_data/learning_outcomes.json'))))" 2>/dev/null || echo "0")
            echo "learning_outcomes=$LEARNING_COUNT" >> $GITHUB_OUTPUT
          else
            echo "learning_outcomes=0" >> $GITHUB_OUTPUT
          fi
          
          # Check last evaluation time for adaptive scheduling
          if [ -f "learning_data/predictions_history.json" ]; then
            PENDING=$(python3 -c "
          import json
          from datetime import datetime, timezone
          try:
              with open('learning_data/predictions_history.json') as f:
                  preds = json.load(f)
              pending = sum(1 for p in preds if not p.get('evaluated', False))
              print(pending)
          except:
              print(0)
          " 2>/dev/null || echo "0")
            echo "pending_predictions=$PENDING" >> $GITHUB_OUTPUT
            echo "ðŸ“Š Pending predictions: $PENDING"
          else
            echo "pending_predictions=0" >> $GITHUB_OUTPUT
          fi
          
          [ -f ".github/run_history/run_counter.txt" ] && RUN_NUM=$(cat .github/run_history/run_counter.txt) || RUN_NUM=0
          RUN_NUM=$((RUN_NUM + 1))
          echo $RUN_NUM > .github/run_history/run_counter.txt
          echo "run_number=$RUN_NUM" >> $GITHUB_OUTPUT
          
          echo "ðŸ“Š Status:"
          echo "   Pickle files: $PICKLE_COUNT"
          echo "   RL Memory: $([ -f "rl_memory/experience_replay.json.gz" ] && echo "Yes" || echo "No")"
          echo "   Learning outcomes: $LEARNING_COUNT"
          echo "   Pending evaluations: $PENDING"
          echo "   Run number: $RUN_NUM"
          
          mkdir -p data/raw/yfinance data/raw/alpha_vantage data/processed data/quarantine \
                   database logs outputs omega_state rl_memory backups learning_data .github/run_history regime_stats

      - name: Verify Notebook
        run: |
          if [ ! -f "AI_Forex_Brain_2.ipynb" ]; then
            echo "âŒ ERROR: AI_Forex_Brain_2.ipynb not found!"
            exit 1
          fi
          echo "âœ… Found AI_Forex_Brain_2.ipynb"

      - name: Create Enhanced Notebook Executor with Weekend Contrarian Logic
        run: |
          cat > run_full.py << 'EOF'
          import nbformat
          import sys
          import time
          import json
          import os
          import re
          from nbconvert.preprocessors import ExecutePreprocessor
          from datetime import datetime, timezone
          
          class WeekendContrarianExecutor(ExecutePreprocessor):
              def __init__(self, *args, **kwargs):
                  super().__init__(*args, **kwargs)
                  self.cell_count = 0
                  self.start_time = None
                  self.successful_cells = 0
                  self.failed_cells = 0
                  self.critical_errors = []
                  self.stage_timings = {}
                  self.current_stage = "Unknown"
                  self.is_weekend = datetime.now(timezone.utc).weekday() in [5, 6]
              
              def preprocess(self, nb, resources=None, km=None):
                  print("="*80)
                  print("ðŸš€ WEEKEND CONTRARIAN SCHEDULE v21.0 (1.5x Optimized)")
                  print("="*80)
                  print(f"ðŸ“… Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}")
                  
                  skip_av = os.environ.get('SKIP_ALPHA_VANTAGE', 'false').lower() == 'true'
                  print(f"ðŸ”§ Alpha Vantage: {'SKIPPED â­ï¸' if skip_av else 'ACTIVE âœ… (00:00 UTC)'}")
                  
                  if self.is_weekend:
                      print("ðŸ–ï¸  WEEKEND MODE: Pipeline v6.3.1 Contrarian Active")
                      print("   â€¢ Using 1.5x SL/TP (optimized for low volatility)")
                      print("   â€¢ A/B Testing: 50% normal, 50% contrarian")
                      print("   â€¢ Min eval window: 2-12 hours")
                      print("   â€¢ Max timeout: 24-72 hours")
                      print("   â€¢ Regime-aware Trade Beacon v21.0")
                  else:
                      print("ðŸ’¼ WEEKDAY MODE: Live trading with regime detection")
                      print("   â€¢ Pipeline v6.3.1 normal mode")
                      print("   â€¢ Using 2x normal SL/TP")
                      print("   â€¢ Min eval window: 1-6 hours")
                      print("   â€¢ Max timeout: 12-36 hours")
                      print("   â€¢ Trade Beacon v21.0 with full regime detection")
                  
                  print(f"ðŸ“Š Total cells to execute: {len([c for c in nb.cells if c.cell_type == 'code'])}")
                  print(f"â° Trigger: Manual or colab_trigger.txt")
                  print("="*80)
                  print()
                  
                  self.start_time = time.time()
                  return super().preprocess(nb, resources, km)
              
              def detect_stage(self, cell_source):
                  source_lower = cell_source.lower()
                  if 'api_keys' in source_lower or 'api keys' in source_lower:
                      return "ðŸ”‘ API Keys Setup"
                  elif 'environment detection' in source_lower:
                      return "ðŸŒ Environment Detection"
                  elif 'github sync' in source_lower:
                      return "ðŸ”„ GitHub Sync"
                  elif 'alpha vantage' in source_lower and 'fetcher' in source_lower:
                      return "ðŸ“ˆ Alpha Vantage Fetcher"
                  elif 'yfinance' in source_lower and 'fetcher' in source_lower:
                      return "ðŸ“Š YFinance Fetcher"
                  elif 'combiner' in source_lower:
                      return "ðŸ”— CSV Combiner"
                  elif 'pipeline v6.3' in source_lower or 'weekend contrarian' in source_lower:
                      return "ðŸ§  Pipeline v6.3.1 Weekend Contrarian"
                  elif 'trade beacon' in source_lower and 'v21' in source_lower:
                      return "ðŸŒ Trade Beacon v21.0 - Regime-Aware"
                  elif 'learning' in source_lower and 'system' in source_lower:
                      return "ðŸŽ“ Adaptive Learning System"
                  elif 'backtest' in source_lower:
                      return "ðŸ“‰ Backtesting Module"
                  return self.current_stage
              
              def preprocess_cell(self, cell, resources, idx):
                  if cell.cell_type != 'code':
                      return cell, resources
                  
                  self.cell_count += 1
                  new_stage = self.detect_stage(cell.source)
                  
                  if new_stage != self.current_stage:
                      if self.current_stage != "Unknown":
                          duration = time.time() - self.stage_timings[self.current_stage]['start']
                          print(f"   â±ï¸  Stage completed in {duration:.1f}s")
                          print()
                      
                      self.current_stage = new_stage
                      self.stage_timings[new_stage] = {'start': time.time(), 'duration': 0}
                      print("="*80)
                      print(f"ðŸ“ STAGE: {new_stage}")
                      if self.is_weekend and 'Pipeline' in new_stage:
                          print("   ðŸ–ï¸  Weekend contrarian mode (1.5x SL/TP)")
                      if 'Beacon' in new_stage:
                          print("   ðŸŒ Market regime detection active")
                      print("="*80)
                  
                  elapsed = time.time() - self.start_time
                  cell_start = time.time()
                  
                  preview = cell.source[:100].replace('\n', ' ')
                  if len(cell.source) > 100:
                      preview += "..."
                  
                  print(f"\nðŸ”· Cell {self.cell_count} | {int(elapsed)}s elapsed")
                  print(f"   Code: {preview}")
                  
                  try:
                      cell, resources = super().preprocess_cell(cell, resources, idx)
                      cell_duration = time.time() - cell_start
                      self.successful_cells += 1
                      
                      if cell.outputs:
                          print(f"   â±ï¸  Executed in {cell_duration:.2f}s")
                          print(f"   ðŸ“¤ Output:")
                          print("   " + "-"*70)
                          
                          output_lines = 0
                          for output in cell.outputs:
                              if output.output_type == 'stream':
                                  text = re.sub(r'\x1b\[[0-9;]*m', '', output.text)
                                  
                                  for line in text.split('\n'):
                                      if line.strip():
                                          print(f"   â”‚ {line}")
                                          output_lines += 1
                                          
                              elif output.output_type == 'execute_result':
                                  if 'text/plain' in output.data:
                                      result = output.data['text/plain']
                                      print(f"   â”‚ Result: {result}")
                                      output_lines += 1
                                      
                              elif output.output_type == 'error':
                                  print(f"   â”‚ âš ï¸  Error: {output.ename}: {output.evalue}")
                                  output_lines += 1
                          
                          print("   " + "-"*70)
                          print(f"   âœ… Success ({output_lines} output lines)")
                      else:
                          print(f"   âœ… Success (no output) - {cell_duration:.2f}s")
                      
                  except Exception as e:
                      cell_duration = time.time() - cell_start
                      self.failed_cells += 1
                      error_msg = str(e)
                      print(f"   âŒ FAILED after {cell_duration:.2f}s")
                      print(f"   â”‚ Error: {error_msg[:200]}")
                      
                      if "CRITICAL" in error_msg.upper() or "FATAL" in error_msg.upper():
                          self.critical_errors.append({
                              'cell': self.cell_count,
                              'stage': self.current_stage,
                              'error': error_msg[:200]
                          })
                  
                  return cell, resources
          
          # Load notebook
          with open('AI_Forex_Brain_2.ipynb', 'r') as f:
              nb = nbformat.read(f, as_version=4)
          
          print("\n" + "="*80)
          print("ðŸ¤– FOREX AI BRAIN - WEEKEND CONTRARIAN v21.0")
          print("="*80)
          print(f"ðŸ““ Notebook: AI_Forex_Brain_2.ipynb")
          print(f"ðŸ”§ Mode: Weekend Contrarian with Regime Detection")
          print(f"âš™ï¸  Pipeline: v6.3.1 (1.5x SL/TP optimization)")
          print(f"âš™ï¸  Trade Beacon: v21.0 (Market regime awareness)")
          print(f"â° Trigger: Manual or colab_trigger.txt")
          print("="*80)
          print()
          
          # Execute
          ep = WeekendContrarianExecutor(timeout=2400, kernel_name='python3', allow_errors=True)
          start = time.time()
          
          try:
              ep.preprocess(nb, {'metadata': {'path': '.'}})
              duration = time.time() - start
              
              print("\n" + "="*80)
              print("âœ… EXECUTION COMPLETED SUCCESSFULLY")
              print("="*80)
              print(f"â±ï¸  Total Duration: {duration:.1f}s ({duration/60:.1f} minutes)")
              print(f"âœ… Successful Cells: {ep.successful_cells}")
              print(f"âŒ Failed Cells: {ep.failed_cells}")
              print(f"ðŸ“Š Success Rate: {(ep.successful_cells/(ep.successful_cells+ep.failed_cells)*100):.1f}%")
              
              if ep.is_weekend:
                  print(f"\nðŸ–ï¸  Weekend Mode Summary:")
                  print(f"   â€¢ Pipeline v6.3.1 contrarian active (1.5x SL/TP)")
                  print(f"   â€¢ A/B testing 50% normal vs 50% contrarian")
                  print(f"   â€¢ Faster evaluation with tighter stops")
                  print(f"   â€¢ Trade Beacon v21.0 regime detection active")
              
              if ep.stage_timings:
                  print("\nðŸ“Š Stage Timings:")
                  for stage, timing in ep.stage_timings.items():
                      duration = timing.get('duration', 0)
                      if duration == 0:
                          duration = time.time() - timing['start']
                      print(f"   {stage}: {duration:.1f}s")
              
              if ep.critical_errors:
                  print(f"\nâš ï¸  Critical Errors: {len(ep.critical_errors)}")
                  for err in ep.critical_errors:
                      print(f"   Cell {err['cell']} ({err['stage']}): {err['error'][:100]}")
              
              print("="*80 + "\n")
              
              report = {
                  'timestamp': datetime.now().isoformat(),
                  'trigger': 'manual_or_colab_trigger',
                  'schedule_type': 'manual_trigger',
                  'is_weekend': ep.is_weekend,
                  'duration': duration,
                  'cells_executed': ep.cell_count,
                  'successful': ep.successful_cells,
                  'failed': ep.failed_cells,
                  'success_rate': round(ep.successful_cells/(ep.successful_cells+ep.failed_cells)*100, 2),
                  'stage_timings': {k: v.get('duration', 0) for k, v in ep.stage_timings.items()},
                  'critical_errors': len(ep.critical_errors),
                  'status': 'success',
                  'version': 'v21.0',
                  'pipeline_version': 'v6.3.1',
                  'beacon_version': 'v21.0'
              }
              
          except Exception as e:
              duration = time.time() - start
              print("\n" + "="*80)
              print("âŒ EXECUTION FAILED")
              print("="*80)
              print(f"Error: {str(e)[:300]}")
              print("="*80 + "\n")
              
              report = {
                  'timestamp': datetime.now().isoformat(),
                  'trigger': 'manual_or_colab_trigger',
                  'schedule_type': 'manual_trigger',
                  'is_weekend': ep.is_weekend,
                  'duration': duration,
                  'cells_executed': ep.cell_count,
                  'status': 'error',
                  'error': str(e)[:300],
                  'version': 'v21.0'
              }
          
          # Save report
          os.makedirs('.github/run_history', exist_ok=True)
          with open('.github/run_history/latest_run.json', 'w') as f:
              json.dump(report, f, indent=2)
          
          print(f"ðŸ’¾ Run report saved to .github/run_history/latest_run.json")
          EOF

      - name: Run Full Notebook Pipeline v6.3.1 (Weekend Contrarian - Optimized)
        run: |
          echo "ðŸš€ STARTING WEEKEND CONTRARIAN v21.0 EXECUTION"
          echo "======================================================"
          echo "âš¡ Triggered at: $(date +'%H:%M UTC')"
          echo "ðŸ“… Day: ${{ steps.day_info.outputs.day_name }}"
          echo "ðŸ”¢ Run: #${{ steps.data.outputs.run_number }}"
          echo "ðŸ“Š Mode: MANUAL TRIGGER (colab_trigger.txt)"
          echo "â° Trigger: Manual or Push Event"
          echo "ðŸŽ¯ Pending Predictions: ${{ steps.data.outputs.pending_predictions }}"
          echo "ðŸŒ Pipeline: v6.3.1 | Beacon: v21.0"
          echo ""
          python run_full.py
        timeout-minutes: 50

      - name: Extract Pipeline Metrics with Weekend Contrarian Analysis
        if: always()
        run: |
          cat > extract_metrics.py << 'EOF'
          import sqlite3
          import json
          import os
          from pathlib import Path
          from datetime import datetime, timezone
          
          metrics = {
              'status': 'no_data',
              'version': 'v21.0',
              'pipeline_version': 'v6.3.1',
              'beacon_version': 'v21.0',
              'trigger': 'manual_or_colab_trigger',
              'scheduler': 'manual_trigger',
              'is_weekend': datetime.now(timezone.utc).weekday() in [5, 6]
          }
          
          # Database metrics
          db_path = Path('database/memory_v85.db')
          if db_path.exists():
              try:
                  conn = sqlite3.connect(str(db_path))
                  c = conn.cursor()
                  c.execute("SELECT COUNT(*), SUM(CASE WHEN hit_tp THEN 1 ELSE 0 END) FROM completed_trades")
                  result = c.fetchone()
                  if result and result[0]:
                      metrics['pipeline_trades'] = result[0]
                      metrics['pipeline_wins'] = result[1] or 0
                      metrics['pipeline_win_rate'] = round((result[1] or 0) / result[0] * 100, 2)
                  conn.close()
                  metrics['status'] = 'active'
              except Exception as e:
                  metrics['db_error'] = str(e)[:100]
          
          # RL Memory
          rl_memory = Path('rl_memory/experience_replay.json.gz')
          if rl_memory.exists():
              metrics['rl_memory_size'] = rl_memory.stat().st_size
              metrics['rl_memory_mb'] = round(rl_memory.stat().st_size / 1024 / 1024, 2)
          
          # Learning stats
          stats_file = Path('rl_memory/learning_stats.json')
          if stats_file.exists():
              try:
                  with open(stats_file) as f:
                      rl_stats = json.load(f)
                  metrics['rl_trades'] = rl_stats.get('total_trades', 0)
                  metrics['rl_win_rate'] = round(rl_stats.get('win_rate', 0) * 100, 2)
                  metrics['rl_pnl'] = round(rl_stats.get('total_pnl', 0.0), 2)
                  metrics['epsilon'] = rl_stats.get('epsilon_history', [0.7])[-1] if rl_stats.get('epsilon_history') else 0.7
                  metrics['regime_filtered'] = rl_stats.get('regime_filtered_trades', 0)
              except Exception as e:
                  metrics['learning_stats_error'] = str(e)[:100]
          
          # Learning outcomes with weekend contrarian split
          learning_db = Path('learning_data/learning_outcomes.json')
          if learning_db.exists():
              try:
                  with open(learning_db) as f:
                      outcomes = json.load(f)
                  
                  metrics['total_outcomes'] = len(outcomes)
                  
                  # Split by weekend/weekday AND contrarian strategy
                  weekend_normal = [o for o in outcomes if o.get('was_weekend_pred', False) and not o.get('is_contrarian', False)]
                  weekend_contrarian = [o for o in outcomes if o.get('was_weekend_pred', False) and o.get('is_contrarian', False)]
                  weekday_outcomes = [o for o in outcomes if not o.get('was_weekend_pred', False)]
                  
                  if weekend_normal:
                      weekend_normal_wins = sum(1 for o in weekend_normal if o.get('was_correct', False))
                      metrics['weekend_normal_outcomes'] = len(weekend_normal)
                      metrics['weekend_normal_win_rate'] = round(weekend_normal_wins / len(weekend_normal) * 100, 2)
                  
                  if weekend_contrarian:
                      weekend_contrarian_wins = sum(1 for o in weekend_contrarian if o.get('was_correct', False))
                      metrics['weekend_contrarian_outcomes'] = len(weekend_contrarian)
                      metrics['weekend_contrarian_win_rate'] = round(weekend_contrarian_wins / len(weekend_contrarian) * 100, 2)
                  
                  if weekday_outcomes:
                      weekday_wins = sum(1 for o in weekday_outcomes if o.get('was_correct', False))
                      metrics['weekday_outcomes'] = len(weekday_outcomes)
                      metrics['weekday_win_rate'] = round(weekday_wins / len(weekday_outcomes) * 100, 2)
                  
                  # Check if adaptive windows are being used
                  if outcomes and 'min_wait_hours' in outcomes[-1]:
                      metrics['using_adaptive_windows'] = True
                      last_outcome = outcomes[-1]
                      metrics['last_min_wait'] = last_outcome.get('min_wait_hours', 0)
                      metrics['last_max_wait'] = last_outcome.get('max_wait_hours', 0)
                  else:
                      metrics['using_adaptive_windows'] = False
                  
              except Exception as e:
                  metrics['outcomes_error'] = str(e)[:100]
          
          # Predictions status
          predictions_file = Path('learning_data/predictions_history.json')
          if predictions_file.exists():
              try:
                  with open(predictions_file) as f:
                      predictions = json.load(f)
                  
                  pending = sum(1 for p in predictions if not p.get('evaluated', False))
                  evaluated = sum(1 for p in predictions if p.get('evaluated', False))
                  
                  metrics['pending_predictions'] = pending
                  metrics['evaluated_predictions'] = evaluated
                  metrics['total_predictions'] = len(predictions)
                  
                  # Check oldest pending prediction age
                  if predictions:
                      pending_preds = [p for p in predictions if not p.get('evaluated', False)]
                      if pending_preds:
                          oldest = pending_preds[0]
                          pred_time = datetime.fromisoformat(oldest['timestamp'].replace('Z', '+00:00'))
                          hours_waiting = (datetime.now(timezone.utc) - pred_time).total_seconds() / 3600
                          metrics['oldest_pending_hours'] = round(hours_waiting, 1)
                  
              except Exception as e:
                  metrics['predictions_error'] = str(e)[:100]
          
          # Regime performance stats
          regime_stats_file = Path('regime_stats/regime_performance.json')
          if regime_stats_file.exists():
              try:
                  with open(regime_stats_file) as f:
                      regime_data = json.load(f)
                  
                  # Find best performing regimes
                  best_regimes = []
                  for key, data in regime_data.items():
                      if data.get('total', 0) >= 5:
                          win_rate = data['wins'] / data['total']
                          best_regimes.append((key, win_rate, data['total']))
                  
                  best_regimes.sort(key=lambda x: x[1], reverse=True)
                  metrics['best_regimes'] = [
                      {'regime': r[0], 'win_rate': round(r[1] * 100, 2), 'trades': r[2]}
                      for r in best_regimes[:5]
                  ]
                  
              except Exception as e:
                  metrics['regime_error'] = str(e)[:100]
          
          # Save metrics
          os.makedirs('.github/run_history', exist_ok=True)
          with open('.github/run_history/metrics.json', 'w') as f:
              json.dump(metrics, f, indent=2)
          
          # Print summary
          print("\n" + "="*70)
          print("ðŸ“Š EXTRACTED METRICS (WEEKEND CONTRARIAN v21.0)")
          print("="*70)
          for key, value in metrics.items():
              print(f"{key}: {value}")
          print("="*70)
          
          # Weekend-specific analysis
          if metrics.get('is_weekend'):
              print("\nðŸ–ï¸  WEEKEND CONTRARIAN A/B TEST:")
              print("="*70)
              
              if metrics.get('weekend_normal_outcomes', 0) > 0:
                  print(f"   ðŸ“Š NORMAL Strategy:")
                  print(f"      Predictions: {metrics['weekend_normal_outcomes']}")
                  print(f"      Win Rate: {metrics['weekend_normal_win_rate']}%")
              
              if metrics.get('weekend_contrarian_outcomes', 0) > 0:
                  print(f"\n   ðŸ”„ CONTRARIAN Strategy:")
                  print(f"      Predictions: {metrics['weekend_contrarian_outcomes']}")
                  print(f"      Win Rate: {metrics['weekend_contrarian_win_rate']}%")
                  
                  # Compare
                  if metrics.get('weekend_normal_outcomes', 0) > 0:
                      normal_wr = metrics['weekend_normal_win_rate']
                      contrarian_wr = metrics['weekend_contrarian_win_rate']
                      diff = contrarian_wr - normal_wr
                      
                      print(f"\n   ðŸ“ˆ Performance Comparison:")
                      print(f"      Difference: {diff:+.2f}%")
                      
                      if diff > 20:
                          print(f"      Status: ðŸŽ‰ CONTRARIAN HUGE SUCCESS!")
                          print(f"      Recommendation: Switch to 100% contrarian on weekends")
                      elif diff > 5:
                          print(f"      Status: âœ… CONTRARIAN BETTER")
                          print(f"      Recommendation: Continue A/B testing")
                      elif diff < -5:
                          print(f"      Status: âŒ CONTRARIAN WORSE")
                          print(f"      Recommendation: Stick with normal strategy")
                      else:
                          print(f"      Status: âš–ï¸  INCONCLUSIVE")
                          print(f"      Recommendation: Need more data")
              
              if metrics.get('weekday_outcomes', 0) > 0:
                  print(f"\n   ðŸ’¼ WEEKDAY Baseline:")
                  print(f"      Predictions: {metrics['weekday_outcomes']}")
                  print(f"      Win Rate: {metrics['weekday_win_rate']}%")
              
              if metrics.get('using_adaptive_windows'):
                  print(f"\n   âœ… Adaptive Windows: ACTIVE")
                  print(f"   Last min wait: {metrics.get('last_min_wait', 0)}h")
                  print(f"   Last max wait: {metrics.get('last_max_wait', 0)}h")
              
              if metrics.get('pending_predictions', 0) > 0:
                  print(f"\n   ðŸ“Š Pending: {metrics['pending_predictions']} predictions")
                  print(f"   Oldest waiting: {metrics.get('oldest_pending_hours', 0)}h")
                  
                  oldest_hours = metrics.get('oldest_pending_hours', 0)
                  if oldest_hours >= 2:
                      print(f"   âœ… Ready for evaluation (>2h wait)")
                  else:
                      print(f"   â³ Needs more time ({2 - oldest_hours:.1f}h remaining)")
              
              print("="*70)
          
          # Regime detection summary
          if metrics.get('best_regimes'):
              print("\nðŸŒ TOP PERFORMING REGIMES:")
              print("="*70)
              for i, regime in enumerate(metrics['best_regimes'], 1):
                  print(f"   {i}. {regime['regime']}")
                  print(f"      Win Rate: {regime['win_rate']}%")
                  print(f"      Trades: {regime['trades']}")
              print("="*70)
          
          # Trade Beacon v21.0 stats
          if metrics.get('regime_filtered', 0) > 0:
              print(f"\nðŸŒ REGIME FILTERING:")
              print(f"   Trades filtered by regime detection: {metrics['regime_filtered']}")
              print(f"   This prevents trading in unfavorable market conditions")
          
          EOF
          python extract_metrics.py

      - name: Prepare Git for Commit
        if: success()
        run: |
          echo "ðŸ”„ Preparing git..."
          
          if ! git diff --quiet; then
            git stash push -m "Auto-stash - run ${{ steps.data.outputs.run_number }}"
            STASHED=true
          else
            STASHED=false
          fi
          
          git pull --rebase origin main || {
            git rebase --abort 2>/dev/null || true
            git pull --no-rebase origin main
          }
          
          if [ "$STASHED" = "true" ]; then
            git stash pop || echo "âš ï¸ Kept both versions"
          fi

      - name: Commit Everything
        if: success()
        run: |
          echo "ðŸ’¾ Committing changes..."
          git add -A
          
          if git diff --cached --quiet; then
            echo "â„¹ï¸ No changes to commit"
          else
            RUN="${{ steps.data.outputs.run_number }}"
            DAY="${{ steps.day_info.outputs.day_name }}"
            HOUR="${{ steps.day_info.outputs.hour }}"
            
            # Read metrics if available
            if [ -f ".github/run_history/metrics.json" ]; then
              OUTCOMES=$(python3 -c "import json; d=json.load(open('.github/run_history/metrics.json')); print(d.get('total_outcomes', 0))" 2>/dev/null || echo "0")
              PENDING=$(python3 -c "import json; d=json.load(open('.github/run_history/metrics.json')); print(d.get('pending_predictions', 0))" 2>/dev/null || echo "0")
              REGIME_FILTERED=$(python3 -c "import json; d=json.load(open('.github/run_history/metrics.json')); print(d.get('regime_filtered', 0))" 2>/dev/null || echo "0")
              
              if [ "${{ steps.day_info.outputs.is_weekend }}" = "true" ]; then
                git commit -m "ðŸ–ï¸  v21.0 Run #${RUN} - ${DAY} ${HOUR}:00 UTC | ${OUTCOMES} outcomes | ${PENDING} pending | ${REGIME_FILTERED} regime-filtered | Manual" || true
              else
                git commit -m "ðŸ’¼ v21.0 Run #${RUN} - ${DAY} ${HOUR}:00 UTC | ${OUTCOMES} outcomes | ${PENDING} pending | ${REGIME_FILTERED} regime-filtered | Manual" || true
              fi
            else
              git commit -m "ðŸŽ“ v21.0 Run #${RUN} - ${DAY} ${HOUR}:00 UTC | Manual Trigger" || true
            fi
            
            # Push with retry
            for i in {1..5}; do
              if git push origin main; then
                echo "âœ… Successfully pushed (attempt $i)"
                break
              else
                if [ $i -lt 5 ]; then
                  echo "âš ï¸ Push failed, retrying in 10s..."
                  sleep 10
                  git pull --rebase origin main || git pull --strategy-option=theirs origin main
                else
                  echo "âŒ Failed to push after 5 attempts"
                fi
              fi
            done
          fi

      - name: Upload Artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: learning-logs-run-${{ steps.data.outputs.run_number }}
          path: |
            .github/run_history/*.json
            logs/*.log
            outputs/*.json
            rl_memory/learning_stats.json
            learning_data/learning_outcomes.json
            learning_data/predictions_history.json
            regime_stats/regime_performance.json
          retention-days: 7
          if-no-files-found: ignore

      - name: Final Summary with Weekend Contrarian Analysis
        if: always()
        run: |
          echo ""
          echo "=========================================="
          echo "ðŸŽ“ WEEKEND CONTRARIAN v21.0 - RUN SUMMARY"
          echo "=========================================="
          echo "ðŸ“… Day: ${{ steps.day_info.outputs.day_name }}"
          echo "ðŸ”¢ Run: #${{ steps.data.outputs.run_number }}"
          echo "â° Time: $(date +'%Y-%m-%d %H:%M UTC')"
          echo "âš¡ Trigger: Manual or colab_trigger.txt"
          echo "ðŸ”§ Version: v21.0"
          echo ""
          
          if [ "${{ steps.day_info.outputs.is_weekend }}" = "true" ]; then
            echo "ðŸ–ï¸  WEEKEND MODE ACTIVE"
            echo "   â€¢ Pipeline v6.3.1: Weekend Contrarian A/B Test"
            echo "   â€¢ Using 1.5x TIGHTER SL/TP (not 3x)"
            echo "   â€¢ A/B Test: 50% normal vs 50% contrarian"
            echo "   â€¢ Adaptive windows: 2-12h min, 24-72h max"
            echo "   â€¢ Trade Beacon v21.0: Market regime detection"
            echo ""
            echo "   ðŸ§ª HYPOTHESIS: Weekend markets are range-bound"
            echo "      Normal predictions: Low win rate (~2.6%)"
            echo "      Contrarian predictions: Should succeed (~97%?)"
            echo ""
            echo "   âš¡ v6.3.1 OPTIMIZATION:"
            echo "      â€¢ Tighter stops for faster evaluation"
            echo "      â€¢ Low-volatility optimized"
            echo "      â€¢ Results available in 4-8 hours (was 24-72h)"
          else
            echo "ðŸ’¼ WEEKDAY MODE ACTIVE"
            echo "   â€¢ Pipeline v6.3.1: Normal prediction logic"
            echo "   â€¢ Using 2x normal SL/TP"
            echo "   â€¢ Adaptive windows: 1-6h min, 12-36h max"
            echo "   â€¢ Trade Beacon v21.0: Full regime detection"
            echo ""
            echo "   ðŸŒ REGIME DETECTION:"
            echo "      â€¢ Volatility: LOW/NORMAL/HIGH/EXTREME"
            echo "      â€¢ Trend: 5 types (STRONG_UP to STRONG_DOWN)"
            echo "      â€¢ Session: ASIA/LONDON/NY/OVERLAP"
            echo "      â€¢ Behavior: MOMENTUM/MEAN_REVERT/NEUTRAL"
            echo ""
            echo "   ðŸŽ¯ SMART FILTERING:"
            echo "      â€¢ Only trade in favorable regimes"
            echo "      â€¢ Dynamic SL/TP adjustment"
            echo "      â€¢ Session-matched pairs"
          fi
          echo ""
          
          echo "ðŸ“ˆ Data Status:"
          echo "   Pickle files: ${{ steps.data.outputs.pickle_count }}"
          echo "   RL Memory: ${{ steps.data.outputs.rl_memory_exists == 'true' && 'Yes' || 'No' }}"
          echo "   Learning outcomes: ${{ steps.data.outputs.learning_outcomes }}"
          echo "   Pending predictions: ${{ steps.data.outputs.pending_predictions }}"
          echo ""
          
          if [ -f ".github/run_history/metrics.json" ]; then
            echo "ðŸ“Š Latest Metrics:"
            cat .github/run_history/metrics.json | python3 -m json.tool 2>/dev/null || cat .github/run_history/metrics.json
            echo ""
          fi
          
          if [ -f ".github/run_history/latest_run.json" ]; then
            echo "â±ï¸ Execution Stats:"
            cat .github/run_history/latest_run.json | python3 -m json.tool 2>/dev/null || cat .github/run_history/latest_run.json
            echo ""
          fi
          
          echo "âœ… Run complete"
          echo "=========================================="
          echo ""
          echo "ðŸ’¡ Next run trigger options:"
          echo "   â€¢ Manual: workflow_dispatch from GitHub Actions"
          echo "   â€¢ Automatic: Push changes to colab_trigger.txt"
          echo ""
          echo "ðŸ”§ v21.0 Key Features:"
          echo "   âœ… Pipeline v6.3.1: Weekend contrarian (1.5x SL/TP)"
          echo "   âœ… Trade Beacon v21.0: Market regime detection"
          echo "   âœ… Volatility regime: LOW/NORMAL/HIGH/EXTREME"
          echo "   âœ… Trend regime: 5 types (STRONG_UP to STRONG_DOWN)"
          echo "   âœ… Session regime: ASIA/LONDON/NY/OVERLAP"
          echo "   âœ… Behavior regime: MOMENTUM/MEAN_REVERT/NEUTRAL"
          echo "   âœ… Dynamic SL/TP adjustment by regime"
          echo "   âœ… Smart trade filtering (avoid unfavorable conditions)"
          echo "   âœ… Weekend: 100% contrarian in ranging markets"
          echo "   âœ… Weekday: Regime-aware normal trading"
          echo ""
          echo "ðŸŽ¯ Benefits:"
          echo "   âœ… Manual control over evaluation timing"
          echo "   âœ… Weekend volatility properly accounted for"
          echo "   âœ… Reduced false losses from premature evaluation"
          echo "   âœ… Better learning signal quality"
          echo "   âœ… Regime filtering prevents bad trades"
          echo "   âœ… 1.5x optimization = faster weekend results"
          echo "   âœ… A/B testing proves which strategy works best"
          echo "=========================================="
