name: Smart Forex Brain Pipeline (Weekend-Aware Auto-Detect)

on:
  workflow_dispatch:
  push:
    paths:
      - 'colab_trigger.txt'
    branches:
      - main
  schedule:
    - cron: '0 */4 * * *'  # Every 4 hours

jobs:
  run-forex-brain:
    runs-on: ubuntu-latest
    timeout-minutes: 55

    env:
      FOREX_PAT: ${{ secrets.FOREX_PAT }}
      BROWSERLESS_TOKEN: ${{ secrets.BROWSERLESS_TOKEN }}
      ALPHA_VANTAGE_KEY: ${{ secrets.ALPHA_VANTAGE_KEY }}
      GMAIL_USER: ${{ secrets.GMAIL_USER }}
      GMAIL_APP_PASSWORD: ${{ secrets.GMAIL_APP_PASSWORD }}
      GIT_USER_NAME: "Forex AI Bot"
      GIT_USER_EMAIL: "nakatonabira3@gmail.com"
      GITHUB_USERNAME: "rahim-dotAI"
      GITHUB_REPO: "forex-ai-models"
      PYTHONIOENCODING: utf-8
      PYTHONUNBUFFERED: 1
      GITHUB_ACTIONS: "true"
      SINGLE_RUN_MODE: "true"

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          persist-credentials: false
          fetch-depth: 0
          lfs: false
          token: ${{ secrets.FOREX_PAT }}

      - name: Detect Weekend vs Weekday Mode
        id: detect_mode
        run: |
          DAY_OF_WEEK=$(date +%u)
          
          echo "=========================================="
          echo "üóìÔ∏è  DAY DETECTION"
          echo "=========================================="
          echo "Current day: $DAY_OF_WEEK (1=Mon, 7=Sun)"
          echo "Date: $(date +'%A, %B %d, %Y %H:%M UTC')"
          
          if [ $DAY_OF_WEEK -eq 6 ] || [ $DAY_OF_WEEK -eq 7 ]; then
            echo "is_weekend=true" >> $GITHUB_OUTPUT
            echo "execution_mode=weekend_v85_only" >> $GITHUB_OUTPUT
            echo "üéØ MODE: WEEKEND (v8.5 Pipeline Only)"
          elif [ $DAY_OF_WEEK -eq 1 ]; then
            echo "is_weekend=false" >> $GITHUB_OUTPUT
            echo "execution_mode=monday_full" >> $GITHUB_OUTPUT
            echo "üéØ MODE: MONDAY (Full Pipeline)"
          else
            echo "is_weekend=false" >> $GITHUB_OUTPUT
            echo "execution_mode=weekday_smart" >> $GITHUB_OUTPUT
            echo "üéØ MODE: WEEKDAY (Smart Detection)"
          fi
          echo "=========================================="

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip wheel setuptools
          pip install --no-cache-dir \
            pandas numpy requests beautifulsoup4 scikit-learn

      - name: Configure Git
        run: |
          git config --global user.name "${GIT_USER_NAME}"
          git config --global user.email "${GIT_USER_EMAIL}"
          git config --global credential.helper store
          echo "https://${GITHUB_USERNAME}:${FOREX_PAT}@github.com" > ~/.git-credentials

      - name: Check data availability (Weekday Smart Mode Only)
        if: steps.detect_mode.outputs.execution_mode == 'weekday_smart'
        id: check_data
        run: |
          echo "=========================================="
          echo "CHECKING DATA FOR SMART MODE"
          echo "=========================================="
          
          MERGED_PKL_COUNT=$(find . -maxdepth 1 -name "*_2244.pkl" -type f -size +10k 2>/dev/null | wc -l)
          
          echo "üìä Found $MERGED_PKL_COUNT merged pickle files"
          
          if [ $MERGED_PKL_COUNT -ge 4 ]; then
            echo "decision=v85_only" >> $GITHUB_OUTPUT
            echo "‚úÖ DECISION: Run v8.5 only"
          else
            echo "decision=full_pipeline" >> $GITHUB_OUTPUT
            echo "‚ö†Ô∏è  DECISION: Run full pipeline"
          fi
          echo "=========================================="

      - name: Verify data files exist (Weekend/Smart v8.5 mode)
        if: |
          steps.detect_mode.outputs.is_weekend == 'true' || 
          (steps.detect_mode.outputs.execution_mode == 'weekday_smart' && steps.check_data.outputs.decision == 'v85_only')
        run: |
          echo "=========================================="
          echo "VERIFYING DATA FILES"
          echo "=========================================="
          
          PICKLE_COUNT=$(find . -maxdepth 1 -name "*_2244.pkl" -type f 2>/dev/null | wc -l)
          
          if [ $PICKLE_COUNT -lt 4 ]; then
            echo "‚ùå ERROR: Only $PICKLE_COUNT/4 pickle files found"
            echo "Available files:"
            ls -lh *.pkl 2>/dev/null || echo "No pickle files"
            exit 1
          fi
          
          echo "‚úÖ Found all required data files ($PICKLE_COUNT)"
          echo "Files:"
          ls -lh *_2244.pkl
          echo "=========================================="

      - name: Extract and prepare v8.5 pipeline script
        if: |
          steps.detect_mode.outputs.is_weekend == 'true' || 
          (steps.detect_mode.outputs.execution_mode == 'weekday_smart' && steps.check_data.outputs.decision == 'v85_only')
        run: |
          cat > forex_pipeline_v85.py << 'PIPELINE_EOF'
          ${{ steps.read_pipeline.outputs.content }}
          PIPELINE_EOF
          
          # Fix paths for GitHub Actions environment
          sed -i 's|ROOT_DIR = Path("/content")|ROOT_DIR = Path(".")|g' forex_pipeline_v85.py
          sed -i 's|ROOT_PATH = ROOT_DIR / "forex-alpha-models"|ROOT_PATH = Path(".")|g' forex_pipeline_v85.py
          sed -i 's|PICKLE_FOLDER = ROOT_PATH / "merged_data_pickles"|PICKLE_FOLDER = Path(".")|g' forex_pipeline_v85.py
          sed -i 's|REPO_FOLDER = ROOT_PATH / "forex-ai-models"|REPO_FOLDER = Path(".")|g' forex_pipeline_v85.py
          
          echo "‚úÖ Pipeline script prepared"

      - name: Read pipeline code
        id: read_pipeline
        run: |
          # Extract just the pipeline code from the document
          PIPELINE_CONTENT=$(cat << 'PIPELINE_CODE'
          #!/usr/bin/env python3
          """
          Ultimate Forex Pipeline v8.5.1 - FIXED GIT EDITION
          Simplified for GitHub Actions execution
          """
          
          import os
          import sys
          import json
          import pickle
          import random
          import logging
          import sqlite3
          from pathlib import Path
          from datetime import datetime, timedelta, timezone
          from collections import defaultdict
          from dataclasses import dataclass
          
          import numpy as np
          import pandas as pd
          
          # ======================================================
          # CONFIGURATION
          # ======================================================
          logging.basicConfig(
              filename='pipeline.log',
              level=logging.INFO,
              format='%(asctime)s [%(levelname)s] %(message)s'
          )
          
          def print_status(msg, level="info"):
              icons = {"info": "‚ÑπÔ∏è", "success": "‚úÖ", "warn": "‚ö†Ô∏è", "error": "‚ùå"}
              print(f"{icons.get(level, '‚ÑπÔ∏è')} {msg}")
          
          # Paths - all in current directory for GitHub Actions
          ROOT_PATH = Path(".")
          PICKLE_FOLDER = ROOT_PATH
          REPO_FOLDER = ROOT_PATH
          
          # Git config
          GIT_NAME = os.environ.get("GIT_USER_NAME", "Forex AI Bot")
          GIT_EMAIL = os.environ.get("GIT_USER_EMAIL", "nakatonabira3@gmail.com")
          
          # Trading parameters
          PAIRS = ["EUR/USD", "GBP/USD", "USD/JPY", "AUD/USD"]
          ATR_PERIOD = 14
          MIN_ATR = 1e-5
          BASE_CAPITAL = 100
          EPS = 1e-8
          
          # File paths
          SIGNALS_JSON = ROOT_PATH / "broker_signals.json"
          ENSEMBLE_JSON = ROOT_PATH / "ensemble_signals.json"
          MEMORY_DB = ROOT_PATH / "memory_v85.db"
          LEARNING_FILE = ROOT_PATH / "learning_v85.pkl"
          ITERATION_FILE = ROOT_PATH / "iteration_v85.pkl"
          
          # Model configs
          COMPETITION_MODELS = {
              "Alpha Momentum": {
                  "color": "üî¥",
                  "atr_sl_range": (1.5, 2.5),
                  "atr_tp_range": (2.0, 3.5),
                  "risk_range": (0.015, 0.03),
                  "confidence_range": (0.3, 0.5),
                  "pop_size": 15,
                  "generations": 20,
                  "mutation_rate": 0.3
              },
              "Beta Conservative": {
                  "color": "üîµ",
                  "atr_sl_range": (1.0, 1.8),
                  "atr_tp_range": (1.5, 2.5),
                  "risk_range": (0.005, 0.015),
                  "confidence_range": (0.5, 0.7),
                  "pop_size": 12,
                  "generations": 15,
                  "mutation_rate": 0.2
              },
              "Gamma Adaptive": {
                  "color": "üü¢",
                  "atr_sl_range": (1.2, 2.2),
                  "atr_tp_range": (1.8, 3.0),
                  "risk_range": (0.01, 0.025),
                  "confidence_range": (0.4, 0.6),
                  "pop_size": 18,
                  "generations": 22,
                  "mutation_rate": 0.25
              }
          }
          
          # ======================================================
          # CORE CLASSES
          # ======================================================
          class IterationCounter:
              def __init__(self, file=ITERATION_FILE):
                  self.file = file
                  self.data = self._load()
              
              def _load(self):
                  if self.file.exists():
                      try:
                          with open(self.file, 'rb') as f:
                              return pickle.load(f)
                      except:
                          pass
                  return {'total': 0, 'start': datetime.now(timezone.utc).isoformat()}
              
              def increment(self):
                  self.data['total'] += 1
                  try:
                      with open(self.file, 'wb') as f:
                          pickle.dump(self.data, f, protocol=4)
                  except Exception as e:
                      logging.error(f"Counter save failed: {e}")
                  return self.data['total']
              
              def get_stats(self):
                  days = max(1, (datetime.now(timezone.utc) - datetime.fromisoformat(self.data['start'])).days)
                  return {'total': self.data['total'], 'days': days, 'per_day': self.data['total'] / days}
          
          COUNTER = IterationCounter()
          
          # ======================================================
          # UTILITY FUNCTIONS
          # ======================================================
          def ensure_atr(df):
              if "atr" in df.columns and not df["atr"].isna().all():
                  df["atr"] = df["atr"].fillna(MIN_ATR).clip(lower=MIN_ATR)
                  return df
              
              high, low, close = df["high"].values, df["low"].values, df["close"].values
              tr = np.maximum.reduce([
                  high - low,
                  np.abs(high - np.roll(close, 1)),
                  np.abs(low - np.roll(close, 1))
              ])
              tr[0] = high[0] - low[0] if len(tr) > 0 else MIN_ATR
              df["atr"] = pd.Series(tr, index=df.index).rolling(ATR_PERIOD, min_periods=1).mean().fillna(MIN_ATR).clip(lower=MIN_ATR)
              return df
          
          def seed_hybrid_signal(df):
              if "hybrid_signal" not in df.columns:
                  fast = df["close"].rolling(10, min_periods=1).mean()
                  slow = df["close"].rolling(50, min_periods=1).mean()
                  df["hybrid_signal"] = (fast - slow).fillna(0)
              return df
          
          def load_data(folder):
              combined = {}
              for pair in PAIRS:
                  prefix = pair.replace("/", "_")
                  pkl_file = folder / f"{prefix}_2244.pkl"
                  
                  if not pkl_file.exists():
                      print_status(f"‚ö†Ô∏è  Missing {pkl_file.name}", "warn")
                      continue
                  
                  try:
                      df = pd.read_pickle(pkl_file)
                      if not isinstance(df, pd.DataFrame) or len(df) < 50:
                          continue
                      
                      df.index = pd.to_datetime(df.index, errors="coerce")
                      if df.index.tz is not None:
                          df.index = df.index.tz_convert(None)
                      
                      df = ensure_atr(df)
                      df = seed_hybrid_signal(df)
                      
                      combined[pair] = {"merged": df}
                      print_status(f"‚úÖ Loaded {pair}: {len(df)} rows", "success")
                      
                  except Exception as e:
                      print_status(f"‚ùå Error loading {pkl_file.name}: {e}", "error")
              
              return combined
          
          def create_chromosome(config):
              return [
                  float(random.uniform(*config['atr_sl_range'])),
                  float(random.uniform(*config['atr_tp_range'])),
                  float(random.uniform(*config['risk_range'])),
                  float(random.uniform(*config['confidence_range']))
              ]
          
          def decode_chromosome(chrom):
              return np.clip(chrom[0], 1.0, 3.0), np.clip(chrom[1], 1.0, 3.0), chrom[2], chrom[3]
          
          # ======================================================
          # BACKTEST
          # ======================================================
          def backtest_strategy(data, chromosome):
              atr_sl, atr_tp, risk, conf = decode_chromosome(chromosome)
              
              equity = BASE_CAPITAL
              trades = []
              position = None
              
              all_times = sorted(set().union(*[df.index for tfs in data.values() for df in tfs.values()]))
              
              for t in all_times:
                  if position:
                      pair = position['pair']
                      if pair in data and "merged" in data[pair] and t in data[pair]["merged"].index:
                          price = data[pair]["merged"].loc[t, 'close']
                          
                          hit_tp = (position['dir'] == 'BUY' and price >= position['tp']) or (position['dir'] == 'SELL' and price <= position['tp'])
                          hit_sl = (position['dir'] == 'BUY' and price <= position['sl']) or (position['dir'] == 'SELL' and price >= position['sl'])
                          
                          if hit_tp or hit_sl:
                              exit_price = position['tp'] if hit_tp else position['sl']
                              pnl = (exit_price - position['entry']) * position['size'] if position['dir'] == 'BUY' else (position['entry'] - exit_price) * position['size']
                              equity += pnl
                              trades.append({'pnl': pnl, 'correct': hit_tp})
                              position = None
                  
                  if position is None:
                      for pair in PAIRS:
                          if pair not in data or "merged" not in data[pair]:
                              continue
                          
                          if t in data[pair]["merged"].index:
                              row = data[pair]["merged"].loc[t]
                              signal = row.get('hybrid_signal', 0)
                              
                              if abs(signal) > conf:
                                  price = row['close']
                                  atr = max(row.get('atr', MIN_ATR), MIN_ATR)
                                  direction = 'BUY' if signal > 0 else 'SELL'
                                  size = min(equity * risk, BASE_CAPITAL * 0.05) / (atr * atr_sl)
                                  
                                  if direction == 'BUY':
                                      sl, tp = price - (atr * atr_sl), price + (atr * atr_tp)
                                  else:
                                      sl, tp = price + (atr * atr_sl), price - (atr * atr_tp)
                                  
                                  position = {'pair': pair, 'dir': direction, 'entry': price, 'sl': sl, 'tp': tp, 'size': size}
                                  break
              
              total = len(trades)
              wins = sum(1 for t in trades if t['correct'])
              return {
                  'total_trades': total,
                  'winning_trades': wins,
                  'accuracy': (wins / total * 100) if total > 0 else 0,
                  'total_pnl': sum(t['pnl'] for t in trades)
              }
          
          # ======================================================
          # GENETIC ALGORITHM
          # ======================================================
          def run_ga(data, model_name, config):
              print_status(f"{config['color']} Training {model_name}...", "info")
              
              pop_size = config['pop_size']
              generations = config['generations']
              mutation_rate = config['mutation_rate']
              
              population = []
              for _ in range(pop_size):
                  chrom = create_chromosome(config)
                  metrics = backtest_strategy(data, chrom)
                  fitness = metrics['total_pnl'] + (metrics['accuracy'] / 100) * 10
                  population.append((fitness, chrom))
              
              population.sort(reverse=True, key=lambda x: x[0])
              
              for gen in range(generations):
                  new_pop = population[:max(1, int(pop_size * 0.2))]
                  
                  while len(new_pop) < pop_size:
                      p1, p2 = random.sample(population, 2)
                      point = random.randint(1, len(p1[1]) - 1)
                      child = p1[1][:point] + p2[1][point:]
                      
                      for i in range(len(child)):
                          if random.random() < mutation_rate:
                              child[i] = float(child[i] + random.gauss(0, 0.1))
                      
                      metrics = backtest_strategy(data, child)
                      fitness = metrics['total_pnl'] + (metrics['accuracy'] / 100) * 10
                      new_pop.append((fitness, child))
                  
                  population = sorted(new_pop, reverse=True, key=lambda x: x[0])
                  
                  if (gen + 1) % 5 == 0:
                      print_status(f"  Gen {gen+1}/{generations}: Best={population[0][0]:.4f}", "info")
              
              best_chrom = population[0][1]
              final_metrics = backtest_strategy(data, best_chrom)
              
              print_status(
                  f"  ‚úÖ {model_name}: {final_metrics['accuracy']:.1f}% accuracy | "
                  f"${final_metrics['total_pnl']:.4f} PnL | {final_metrics['total_trades']} trades",
                  "success"
              )
              
              return {'chromosome': best_chrom, 'metrics': final_metrics}
          
          # ======================================================
          # SIGNAL GENERATION
          # ======================================================
          def generate_signals(data, chromosome, model_name):
              atr_sl, atr_tp, risk, conf = decode_chromosome(chromosome)
              signals = {}
              
              for pair in PAIRS:
                  if pair not in data or "merged" not in data[pair]:
                      continue
                  
                  df = data[pair]["merged"]
                  if len(df) == 0:
                      continue
                  
                  row = df.iloc[-1]
                  signal_strength = row.get('hybrid_signal', 0)
                  price = row['close']
                  atr = max(row.get('atr', MIN_ATR), MIN_ATR)
                  
                  direction = 'HOLD'
                  sl = tp = price
                  
                  if abs(signal_strength) > conf:
                      direction = 'BUY' if signal_strength > 0 else 'SELL'
                      
                      if direction == 'BUY':
                          sl, tp = price - (atr * atr_sl), price + (atr * atr_tp)
                      else:
                          sl, tp = price + (atr * atr_sl), price - (atr * atr_tp)
                  
                  signals[pair] = {
                      'direction': direction,
                      'last_price': float(price),
                      'SL': float(sl),
                      'TP': float(tp),
                      'atr': float(atr),
                      'score_1_100': int(abs(signal_strength) * 100),
                      'model': model_name,
                      'timestamp': datetime.now(timezone.utc).isoformat()
                  }
              
              return signals
          
          # ======================================================
          # MAIN
          # ======================================================
          def main():
              print_status("=" * 70, "info")
              print_status("üöÄ FOREX PIPELINE v8.5.1", "success")
              print_status("=" * 70, "info")
              
              try:
                  current_iter = COUNTER.increment()
                  stats = COUNTER.get_stats()
                  
                  print_status(f"\nüìä Iteration #{current_iter}", "info")
                  print_status(f"Total: {stats['total']} | Days: {stats['days']} | Avg/Day: {stats['per_day']:.1f}", "info")
                  
                  print_status("\nüì¶ Loading data...", "info")
                  data = load_data(PICKLE_FOLDER)
                  
                  if not data:
                      raise ValueError("No data loaded!")
                  
                  print_status(f"‚úÖ Loaded {len(data)} pairs", "success")
                  
                  print_status("\nüèÜ Running Competition...", "info")
                  results = {}
                  signals_by_model = {}
                  
                  for model_name, config in COMPETITION_MODELS.items():
                      result = run_ga(data, model_name, config)
                      results[model_name] = result
                      signals = generate_signals(data, result['chromosome'], model_name)
                      signals_by_model[model_name] = signals
                  
                  print_status("\nüíæ Saving signals...", "info")
                  with open(SIGNALS_JSON, 'w') as f:
                      json.dump(signals_by_model, f, indent=2, default=str)
                  
                  with open(ENSEMBLE_JSON, 'w') as f:
                      json.dump({
                          'timestamp': datetime.now(timezone.utc).isoformat(),
                          'iteration': current_iter,
                          'models': signals_by_model
                      }, f, indent=2, default=str)
                  
                  print_status("\n" + "=" * 70, "success")
                  print_status("‚úÖ PIPELINE COMPLETED", "success")
                  print_status("=" * 70, "success")
                  
              except Exception as e:
                  print_status(f"\n‚ùå Error: {e}", "error")
                  import traceback
                  traceback.print_exc()
                  sys.exit(1)
          
          if __name__ == "__main__":
              main()
          PIPELINE_CODE
          )
          
          echo "content<<EOF" >> $GITHUB_OUTPUT
          echo "$PIPELINE_CONTENT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Run v8.5 Pipeline Only (Weekend or Data Exists)
        if: |
          steps.detect_mode.outputs.is_weekend == 'true' || 
          (steps.detect_mode.outputs.execution_mode == 'weekday_smart' && steps.check_data.outputs.decision == 'v85_only')
        run: |
          echo "=========================================="
          echo "üü¢ RUNNING v8.5 PIPELINE ONLY"
          echo "=========================================="
          echo "Mode: ${{ steps.detect_mode.outputs.execution_mode }}"
          echo ""
          
          python forex_pipeline_v85.py 2>&1 | tee pipeline_output.log
          
          EXIT_CODE=${PIPESTATUS[0]}
          if [ $EXIT_CODE -ne 0 ]; then
            echo "‚ùå Pipeline failed"
            tail -n 100 pipeline_output.log
            exit $EXIT_CODE
          fi
        timeout-minutes: 20

      - name: Commit and push changes
        if: always()
        run: |
          git add -A
          
          if git diff --cached --quiet; then
            echo "‚ÑπÔ∏è  No changes to commit"
          else
            MODE="${{ steps.detect_mode.outputs.execution_mode }}"
            git commit -m "ü§ñ Auto-update [$MODE]: $(date +'%Y-%m-%d %H:%M:%S UTC')" || true
            
            # Pull and push with retry
            for i in {1..3}; do
              git pull --rebase origin main && git push origin main && break
              echo "Retry $i failed, waiting..."
              sleep 2
            done
          fi

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-logs-${{ github.run_number }}
          path: |
            pipeline_output.log
            pipeline.log
          retention-days: 7

      - name: Summary
        if: always()
        run: |
          echo "=========================================="
          echo "üìä EXECUTION SUMMARY"
          echo "=========================================="
          echo "Mode: ${{ steps.detect_mode.outputs.execution_mode }}"
          echo "Weekend: ${{ steps.detect_mode.outputs.is_weekend }}"
          echo "Date: $(date +'%A, %B %d, %Y %H:%M UTC')"
          echo "=========================================="
