name: Smart Forex Brain Pipeline (Trade Beacon v17.0)

on:
  workflow_dispatch:
  push:
    paths:
      - 'colab_trigger.txt'
    branches:
      - main
  schedule:
    # Weekdays (Mon-Fri): Every 2 hours - Full notebook execution
    - cron: '0 */2 * * 1-5'
    # Weekends (Sat-Sun): Every 30 minutes - Tagged cells only
    - cron: '*/30 * * * 0,6'

jobs:
  run-forex-brain:
    runs-on: ubuntu-latest
    timeout-minutes: 55

    env:
      FOREX_PAT: ${{ secrets.FOREX_PAT }}
      BROWSERLESS_TOKEN: ${{ secrets.BROWSERLESS_TOKEN }}
      ALPHA_VANTAGE_KEY: ${{ secrets.ALPHA_VANTAGE_KEY }}
      GMAIL_USER: ${{ secrets.GMAIL_USER }}
      GMAIL_APP_PASSWORD: ${{ secrets.GMAIL_APP_PASSWORD }}
      GIT_USER_NAME: "Forex AI Bot"
      GIT_USER_EMAIL: "nakatonabira3@gmail.com"
      GITHUB_USERNAME: "rahim-dotAI"
      GITHUB_REPO: "forex-ai-models"
      PYTHONIOENCODING: utf-8
      PYTHONUNBUFFERED: 1
      GITHUB_ACTIONS: "true"
      SINGLE_RUN_MODE: "true"

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          persist-credentials: false
          fetch-depth: 0
          lfs: true
          token: ${{ secrets.FOREX_PAT }}

      - name: Fix submodule issue
        run: |
          echo "=========================================="
          echo "üîß FIXING SUBMODULE CONFIGURATION"
          echo "=========================================="
          
          if [ -f ".gitmodules" ]; then
            echo "‚ö†Ô∏è Found .gitmodules file - removing it"
            rm -f .gitmodules
            git rm --cached -r forex-alpha-models 2>/dev/null || true
            rm -rf forex-alpha-models
            git add .gitmodules 2>/dev/null || true
            echo "‚úÖ Submodule configuration removed"
          else
            echo "‚úÖ No .gitmodules file found"
          fi
          
          find . -mindepth 2 -name ".git" -type d -exec rm -rf {} + 2>/dev/null || true
          echo "=========================================="

      - name: Detect Execution Mode
        id: detect_mode
        run: |
          DAY_OF_WEEK=$(date +%u)
          HOUR=$(date +%H)
          
          echo "=========================================="
          echo "üóìÔ∏è  EXECUTION MODE DETECTION"
          echo "=========================================="
          echo "Current day: $DAY_OF_WEEK (1=Mon, 5=Fri, 6=Sat, 7=Sun)"
          echo "Current hour: $HOUR UTC"
          echo "Date: $(date +'%A, %B %d, %Y %H:%M UTC')"
          echo ""
          
          # Weekend = Saturday (6) or Sunday (7)
          if [ $DAY_OF_WEEK -eq 6 ] || [ $DAY_OF_WEEK -eq 7 ]; then
            echo "execution_mode=weekend_tagged_cells" >> $GITHUB_OUTPUT
            echo "schedule_type=30min_tagged" >> $GITHUB_OUTPUT
            echo "ÔøΩÔ∏è MODE: WEEKEND (Saturday/Sunday)"
            echo "   ‚Ä¢ Execution: Tagged cells only (#TAG: pipeline_main)"
            echo "   ‚Ä¢ Schedule: Every 30 minutes"
            echo "   ‚Ä¢ Features: Ultra-Persistent Pipeline + Trade Beacon v17.0"
            echo "   ‚Ä¢ Trading: LEARNING MODE (no live signals stored)"
          else
            echo "execution_mode=weekday_full_notebook" >> $GITHUB_OUTPUT
            echo "schedule_type=2hourly" >> $GITHUB_OUTPUT
            echo "üíº MODE: WEEKDAY (Monday-Friday)"
            echo "   ‚Ä¢ Execution: Full notebook (all cells)"
            echo "   ‚Ä¢ Schedule: Every 2 hours"
            echo "   ‚Ä¢ Features: Complete pipeline + Trade Beacon v17.0"
            echo "   ‚Ä¢ Trading: LIVE MODE (full trading active)"
          fi
          echo "=========================================="

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip

      - name: Install dependencies
        run: |
          echo "üì¶ Installing Python dependencies..."
          python -m pip install --upgrade pip wheel setuptools
          pip install --no-cache-dir \
            pandas numpy requests beautifulsoup4 scikit-learn \
            jupyter nbconvert nbformat ta yfinance \
            mplfinance firebase-admin dropbox \
            pyppeteer nest_asyncio lightgbm joblib matplotlib \
            alpha_vantage tqdm river scipy
          echo "‚úÖ Dependencies installed"

      - name: Configure Git
        run: |
          git config --global user.name "${GIT_USER_NAME}"
          git config --global user.email "${GIT_USER_EMAIL}"
          git config --global credential.helper store
          echo "https://${GITHUB_USERNAME}:${FOREX_PAT}@github.com" > ~/.git-credentials
          echo "‚úÖ Git configured"

      - name: Check for Required Data Files
        id: check_data
        run: |
          echo "=========================================="
          echo "üîç CHECKING FOR REQUIRED DATA FILES"
          echo "=========================================="
          
          # Check for processed pickle files (excluding model and cache files)
          PICKLE_COUNT=$(find data/processed -name "*.pkl" -type f 2>/dev/null | \
            grep -v "_sgd_model\|_rf_model\|indicator_cache\|ultra_\|alpha_\|_model.pkl\|\.bak" | wc -l)
          
          # Check for Pipeline database
          PIPELINE_DB_EXISTS=false
          if [ -f "database/memory_v85.db" ]; then
            DB_SIZE=$(wc -c < "database/memory_v85.db")
            echo "   ‚Ä¢ Pipeline database: ‚úÖ ($DB_SIZE bytes)"
          else
            echo "   ‚Ä¢ Pipeline database: ‚ö†Ô∏è  Not found"
          fi
          
          if [ -d "rl_memory" ]; then
            RL_EXPERIENCE=$([ -f "rl_memory/experience_replay.pkl" ] && echo "‚úÖ" || echo "‚ö†Ô∏è")
            RL_QNET=$([ -f "rl_models/q_network.npz" ] && echo "‚úÖ" || echo "‚ö†Ô∏è")
            echo "   ‚Ä¢ RL experience replay: $RL_EXPERIENCE"
            echo "   ‚Ä¢ RL Q-network: $RL_QNET"
          else
            echo "   ‚Ä¢ RL state: ‚ö†Ô∏è  Not found"
          fi
          
          if [ $PICKLE_COUNT -ge 4 ]; then
            echo "   ‚Ä¢ Data Status: ‚úÖ Ready for Trade Beacon v17.0"
          else
            echo "   ‚Ä¢ Data Status: ‚ö†Ô∏è  Needs more data (‚â•4 pickles)"
          fi
          echo ""
          
          echo "üî¥ TRADE BEACON v17.0 - INTEGRATED LEARNING EDITION"
          echo "=========================================="
          echo ""
          echo "üéØ NEW FEATURES:"
          echo "   ‚Ä¢ Deep Q-Learning with Experience Replay"
          echo "   ‚Ä¢ Pipeline Database Integration (learns from completed trades)"
          echo "   ‚Ä¢ Weekend Learning Mode (backtest + database sync)"
          echo "   ‚Ä¢ Weekday Live Trading Mode (full trading active)"
          echo "   ‚Ä¢ 6 Chart Pattern Detection (double top/bottom, H&S, etc.)"
          echo "   ‚Ä¢ Adaptive Confidence System"
          echo "   ‚Ä¢ Dynamic Position Sizing"
          echo ""
          echo "üõ°Ô∏è  VALIDATION SYSTEM:"
          echo "   ‚Ä¢ Confidence-based trade execution"
          echo "   ‚Ä¢ Adaptive thresholds (early: 35%, mature: 65%)"
          echo "   ‚Ä¢ Q-value spread validation"
          echo "   ‚Ä¢ Entropy-based certainty checks"
          echo "   ‚Ä¢ Position sizing based on confidence"
          echo ""
          echo "üß† DEEP Q-LEARNING:"
          echo "   ‚Ä¢ State size: 30 features"
          echo "   ‚Ä¢ Action space: BUY, SELL, HOLD"
          echo "   ‚Ä¢ Experience replay: 10,000 memory"
          echo "   ‚Ä¢ Target network updates every 10 iterations"
          echo "   ‚Ä¢ Epsilon decay: 1.0 ‚Üí 0.05"
          echo ""
          echo "üíæ PIPELINE INTEGRATION:"
          echo "   ‚Ä¢ Learns from Ultra-Persistent Pipeline database"
          echo "   ‚Ä¢ Syncs completed trades automatically"
          echo "   ‚Ä¢ Converts pipeline trades to RL experiences"
          echo "   ‚Ä¢ Tracks learning statistics"
          echo ""
          echo "üìä STATE VECTOR (30 FEATURES):"
          echo "   ‚Ä¢ Price position (1)"
          echo "   ‚Ä¢ Recent returns (5)"
          echo "   ‚Ä¢ RSI 1h + 1d (2)"
          echo "   ‚Ä¢ MACD + Signal (2)"
          echo "   ‚Ä¢ Bollinger Bands (2)"
          echo "   ‚Ä¢ ATR + Volatility (2)"
          echo "   ‚Ä¢ Trend indicators (3)"
          echo "   ‚Ä¢ Volume ratio (1)"
          echo "   ‚Ä¢ Session indicators (3)"
          echo "   ‚Ä¢ Time features (2)"
          echo "   ‚Ä¢ Chart patterns (6)"
          echo ""
          echo "üé≤ REWARD SYSTEM:"
          echo "   ‚Ä¢ Profit reward scale: 100x"
          echo "   ‚Ä¢ Loss penalty scale: 100x"
          echo "   ‚Ä¢ Win streak bonus: +5.0"
          echo "   ‚Ä¢ Loss streak penalty: -3.0"
          echo "   ‚Ä¢ Sharpe ratio component: 10x"
          echo "   ‚Ä¢ Time efficiency rewards"
          echo ""
          echo "‚öôÔ∏è  WEEKEND vs WEEKDAY MODES:"
          echo ""
          echo "   üñèÔ∏è WEEKEND (Every 30min):"
          echo "      ‚Ä¢ Runs tagged cells only"
          echo "      ‚Ä¢ Ultra-Persistent Pipeline learns"
          echo "      ‚Ä¢ Trade Beacon runs backtest"
          echo "      ‚Ä¢ Syncs with pipeline database"
          echo "      ‚Ä¢ NO live signals stored"
          echo "      ‚Ä¢ Evaluation age: 30 minutes"
          echo "      ‚Ä¢ 50+ backtest trades per run"
          echo ""
          echo "   üíº WEEKDAY (Every 2hrs):"
          echo "      ‚Ä¢ Full notebook execution"
          echo "      ‚Ä¢ Complete data pipeline"
          echo "      ‚Ä¢ Live trading signals"
          echo "      ‚Ä¢ Real trade execution"
          echo "      ‚Ä¢ Pipeline stores live trades"
          echo "      ‚Ä¢ Evaluation age: 2 hours"
          echo "      ‚Ä¢ Email notifications"
          echo ""
          echo "üìß EMAIL NOTIFICATIONS:"
          echo "   ‚Ä¢ Beautiful HTML design"
          echo "   ‚Ä¢ RL agent statistics"
          echo "   ‚Ä¢ Pipeline integration stats"
          echo "   ‚Ä¢ Recent trade history"
          echo "   ‚Ä¢ Confidence metrics"
          echo "   ‚Ä¢ Mode-specific badges"
          echo ""
          echo "üíæ STATE PERSISTENCE:"
          echo "   ‚Ä¢ Q-network weights saved"
          echo "   ‚Ä¢ Target network saved"
          echo "   ‚Ä¢ Experience replay memory"
          echo "   ‚Ä¢ Learning statistics"
          echo "   ‚Ä¢ Trade history"
          echo "   ‚Ä¢ Pipeline sync timestamp"
          echo "   ‚Ä¢ Iteration counter"
          echo ""
          echo "üîí SAFETY FEATURES:"
          echo "   ‚Ä¢ Max 2 concurrent positions"
          echo "   ‚Ä¢ 2% max risk per trade"
          echo "   ‚Ä¢ $10 max trade cap"
          echo "   ‚Ä¢ ATR-based SL/TP (2x/3x)"
          echo "   ‚Ä¢ Confidence-based position sizing"
          echo "   ‚Ä¢ Exploration/exploitation balance"
          echo "   ‚Ä¢ Comprehensive error handling"
          echo ""
          echo "üóÑÔ∏è  DATABASE STRUCTURE:"
          echo "   ‚Ä¢ pending_trades: Live positions"
          echo "   ‚Ä¢ completed_trades: Historical results"
          echo "   ‚Ä¢ model_stats_cache: Performance metrics"
          echo "   ‚Ä¢ RL learns from all completed trades"
          echo ""
          echo "=========================================="
          echo "‚úÖ Pipeline execution completed"
          echo "=========================================="
            PIPELINE_DB_EXISTS=true
          fi
          
          # Check for RL state files
          RL_STATE_EXISTS=false
          if [ -d "rl_memory" ]; then
            if [ -f "rl_memory/experience_replay.pkl" ] || [ -f "rl_models/q_network.npz" ]; then
              RL_STATE_EXISTS=true
            fi
          fi
          
          echo "üìä Data Status:"
          echo "   Processed pickle files: $PICKLE_COUNT"
          echo "   Pipeline database exists: $PIPELINE_DB_EXISTS"
          echo "   RL state exists: $RL_STATE_EXISTS"
          echo ""
          
          if [ $PICKLE_COUNT -ge 4 ]; then
            echo "has_data=true" >> $GITHUB_OUTPUT
            echo "‚úÖ SUFFICIENT DATA FOUND"
            echo "   ‚Ä¢ Pickle files: $PICKLE_COUNT/4 ‚úì"
            echo "   ‚Ä¢ Pipeline DB: $PIPELINE_DB_EXISTS"
            echo "   ‚Ä¢ RL State: $RL_STATE_EXISTS"
            echo "   ‚Ä¢ Ready for execution"
          else
            echo "has_data=false" >> $GITHUB_OUTPUT
            echo "‚ö†Ô∏è  INSUFFICIENT DATA"
            echo "   ‚Ä¢ Pickle files: $PICKLE_COUNT/4 (need ‚â•4)"
            echo "   ‚Ä¢ Will generate via full notebook"
          fi
          echo "=========================================="

      - name: Run Weekend Tagged Cells (Weekend Mode)
        if: steps.detect_mode.outputs.execution_mode == 'weekend_tagged_cells'
        run: |
          echo "=========================================="
          echo "üñèÔ∏è WEEKEND MODE: TAGGED CELLS EXECUTION"
          echo "=========================================="
          echo "Day: $(date +'%A')"
          echo "Schedule: Every 30 minutes"
          echo "Executing: Tagged cells only (#TAG: pipeline_main)"
          echo "  1. Ultra-Persistent Pipeline (Learning Mode)"
          echo "  2. Trade Beacon v17.0 (Learning Mode)"
          echo ""
          
          # Create Python script for tagged cell execution
          cat > run_tagged_cells.py << 'EOFPYTHON'
          import nbformat
          from nbconvert.preprocessors import ExecutePreprocessor
          import sys
          import os
          import time
          import re
          from datetime import datetime
          
          class TaggedCellExecutor(ExecutePreprocessor):
              """Execute only cells with #TAG: pipeline_main"""
              
              def __init__(self, *args, **kwargs):
                  super().__init__(*args, **kwargs)
                  self.tagged_cells = []
                  self.current_cell = 0
                  self.start_time = None
                  
              def preprocess(self, nb, resources=None, km=None):
                  # Find all tagged cells
                  for idx, cell in enumerate(nb.cells):
                      if cell.cell_type == 'code':
                          if '#TAG: pipeline_main' in cell.source or 'TAG: pipeline_main' in cell.source:
                              self.tagged_cells.append(idx)
                  
                  print(f"üìä Found {len(self.tagged_cells)} tagged cells")
                  print("=" * 70)
                  
                  self.start_time = time.time()
                  return super().preprocess(nb, resources, km)
              
              def preprocess_cell(self, cell, resources, cell_index):
                  if cell.cell_type != 'code':
                      return cell, resources
                  
                  # Only execute tagged cells
                  if cell_index not in self.tagged_cells:
                      return cell, resources
                  
                  self.current_cell += 1
                  elapsed = time.time() - self.start_time
                  
                  print(f"\nüîÑ Tagged Cell {self.current_cell}/{len(self.tagged_cells)} (Cell #{cell_index}) | ‚è±Ô∏è {elapsed:.1f}s")
                  
                  # Show cell preview
                  first_lines = cell.source.split('\n')[:3]
                  preview = '\n'.join(first_lines)
                  print(f"üìù Preview:\n{preview[:200]}...")
                  
                  cell_start = time.time()
                  cell, resources = super().preprocess_cell(cell, resources, cell_index)
                  cell_time = time.time() - cell_start
                  
                  if cell.outputs:
                      for output in cell.outputs:
                          if output.output_type == 'stream':
                              cleaned = self._clean_output(output.text)
                              if cleaned.strip():
                                  print(cleaned)
                          elif output.output_type == 'error':
                              print(f"‚ùå {output.ename}: {output.evalue}")
                  
                  print(f"‚úÖ Completed in {cell_time:.1f}s")
                  
                  return cell, resources
              
              def _clean_output(self, text):
                  if not text:
                      return ""
                  lines = []
                  for line in text.split('\n'):
                      if any(skip in line for skip in ['[DEBUG]', 'WARNING:', 'DeprecationWarning']):
                          continue
                      if not line.strip():
                          continue
                      line = re.sub(r'\x1b\[[0-9;]*m', '', line)
                      lines.append(line)
                  return '\n'.join(lines)
          
          def run_tagged_cells(notebook_path):
              print(f"üìñ Reading: {notebook_path}")
              
              with open(notebook_path, 'r', encoding='utf-8') as f:
                  nb = nbformat.read(f, as_version=4)
              
              print(f"‚úÖ Loaded: {len(nb.cells)} total cells")
              print()
              
              ep = TaggedCellExecutor(
                  timeout=2400,
                  kernel_name='python3',
                  allow_errors=False
              )
              
              print("üöÄ Starting tagged cells execution...")
              print()
              
              try:
                  start = time.time()
                  ep.preprocess(nb, {'metadata': {'path': '.'}})
                  duration = time.time() - start
                  
                  print()
                  print("=" * 70)
                  print("‚úÖ TAGGED CELLS EXECUTION COMPLETED!")
                  print("=" * 70)
                  print(f"‚è±Ô∏è  Time: {duration:.1f}s ({duration/60:.1f} min)")
                  print(f"üìä Tagged Cells: {len(ep.tagged_cells)}")
                  print("=" * 70)
                  return True
              except Exception as e:
                  print()
                  print("=" * 70)
                  print("‚ùå EXECUTION FAILED!")
                  print("=" * 70)
                  print(f"Error: {type(e).__name__}: {str(e)}")
                  print("=" * 70)
                  return False
          
          if __name__ == "__main__":
              notebook = sys.argv[1] if len(sys.argv) > 1 else "AI_Forex_Brain_2.ipynb"
              
              if not os.path.exists(notebook):
                  print(f"‚ùå Not found: {notebook}")
                  sys.exit(1)
              
              print("=" * 70)
              print("üñèÔ∏è WEEKEND MODE - TAGGED CELLS ONLY")
              print("=" * 70)
              print(f"üìÖ {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}")
              print(f"üìì {notebook}")
              print("üî¥ Trade Beacon v17.0 - Learning Mode")
              print("   ‚Ä¢ Ultra-Persistent Pipeline (Learning)")
              print("   ‚Ä¢ Trade Beacon (Backtest + Database Sync)")
              print("   ‚Ä¢ No live trading signals stored")
              print("   ‚Ä¢ Database learning continues")
              print("=" * 70)
              print()
              
              success = run_tagged_cells(notebook)
              
              print()
              print("=" * 70)
              if success:
                  print("‚úÖ WEEKEND EXECUTION COMPLETED")
              else:
                  print("‚ùå WEEKEND EXECUTION FAILED")
              print(f"üìÖ {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}")
              print("=" * 70)
              
              sys.exit(0 if success else 1)
          EOFPYTHON
          
          # Find notebook file
          NOTEBOOK_FILE="AI_Forex_Brain_2.ipynb"
          
          if [ ! -f "$NOTEBOOK_FILE" ]; then
            echo "‚ùå Notebook not found: $NOTEBOOK_FILE"
            exit 1
          fi
          
          echo "‚úÖ Found: $NOTEBOOK_FILE"
          echo ""
          
          python run_tagged_cells.py "$NOTEBOOK_FILE" 2>&1 | tee notebook_execution.log
          
          EXIT_CODE=${PIPESTATUS[0]}
          if [ $EXIT_CODE -ne 0 ]; then
            echo ""
            echo "‚ùå Tagged cell execution failed with exit code $EXIT_CODE"
            tail -n 200 notebook_execution.log
            exit $EXIT_CODE
          fi
          
          echo ""
          echo "‚úÖ Tagged cell execution completed successfully"
        timeout-minutes: 50

      - name: Run Full Notebook (Weekday Mode)
        if: steps.detect_mode.outputs.execution_mode == 'weekday_full_notebook'
        run: |
          echo "=========================================="
          echo "üíº WEEKDAY MODE: FULL NOTEBOOK EXECUTION"
          echo "=========================================="
          echo "Day: $(date +'%A')"
          echo "Schedule: Every 2 hours"
          echo "Executing: All cells in sequence"
          echo "Trade Beacon: v17.0 Enhanced Production"
          echo ""
          
          # Create Python script with progress tracking
          cat > run_full_notebook.py << 'EOFPYTHON'
          import nbformat
          from nbconvert.preprocessors import ExecutePreprocessor
          import sys
          import os
          import time
          import re
          from datetime import datetime
          
          class ProgressTrackingExecutor(ExecutePreprocessor):
              """Custom executor with progress tracking"""
              
              def __init__(self, *args, **kwargs):
                  super().__init__(*args, **kwargs)
                  self.total_cells = 0
                  self.current_cell = 0
                  self.start_time = None
                  
              def preprocess(self, nb, resources=None, km=None):
                  self.total_cells = sum(1 for cell in nb.cells if cell.cell_type == 'code')
                  self.current_cell = 0
                  self.start_time = time.time()
                  
                  print(f"üìä Total code cells: {self.total_cells}")
                  print("=" * 70)
                  
                  return super().preprocess(nb, resources, km)
              
              def preprocess_cell(self, cell, resources, cell_index):
                  if cell.cell_type != 'code':
                      return cell, resources
                  
                  self.current_cell += 1
                  elapsed = time.time() - self.start_time
                  progress = (self.current_cell / self.total_cells) * 100
                  
                  print(f"\nüîÑ Cell {self.current_cell}/{self.total_cells} ({progress:.1f}%) | ‚è±Ô∏è {elapsed:.1f}s")
                  
                  # Show first line preview if it's meaningful
                  if cell.source:
                      first_line = cell.source.split('\n')[0][:60]
                      if first_line.strip() and not first_line.strip().startswith('#'):
                          print(f"üìù {first_line}...")
                  
                  cell_start = time.time()
                  cell, resources = super().preprocess_cell(cell, resources, cell_index)
                  cell_time = time.time() - cell_start
                  
                  if cell.outputs:
                      for output in cell.outputs:
                          if output.output_type == 'stream':
                              cleaned = self._clean_output(output.text)
                              if cleaned.strip():
                                  print(cleaned)
                          elif output.output_type == 'error':
                              print(f"‚ùå {output.ename}: {output.evalue}")
                  
                  print(f"‚úÖ Completed in {cell_time:.1f}s")
                  
                  return cell, resources
              
              def _clean_output(self, text):
                  if not text:
                      return ""
                  lines = []
                  for line in text.split('\n'):
                      if any(skip in line for skip in ['[DEBUG]', 'WARNING:', 'DeprecationWarning']):
                          continue
                      if not line.strip():
                          continue
                      line = re.sub(r'\x1b\[[0-9;]*m', '', line)
                      lines.append(line)
                  return '\n'.join(lines)
          
          def run_notebook(notebook_path):
              print(f"üìñ Reading: {notebook_path}")
              
              with open(notebook_path, 'r', encoding='utf-8') as f:
                  nb = nbformat.read(f, as_version=4)
              
              code_cells = sum(1 for c in nb.cells if c.cell_type == 'code')
              print(f"‚úÖ Loaded: {len(nb.cells)} cells ({code_cells} code)")
              print()
              
              ep = ProgressTrackingExecutor(
                  timeout=2400,
                  kernel_name='python3',
                  allow_errors=False
              )
              
              print("üöÄ Starting full notebook execution...")
              print()
              
              try:
                  start = time.time()
                  ep.preprocess(nb, {'metadata': {'path': '.'}})
                  duration = time.time() - start
                  
                  print()
                  print("=" * 70)
                  print("‚úÖ FULL NOTEBOOK COMPLETED!")
                  print("=" * 70)
                  print(f"‚è±Ô∏è  Time: {duration:.1f}s ({duration/60:.1f} min)")
                  print(f"üìä Cells: {code_cells}")
                  print("=" * 70)
                  return True
              except Exception as e:
                  print()
                  print("=" * 70)
                  print("‚ùå EXECUTION FAILED!")
                  print("=" * 70)
                  print(f"Error: {type(e).__name__}: {str(e)}")
                  print("=" * 70)
                  return False
          
          if __name__ == "__main__":
              notebook = sys.argv[1] if len(sys.argv) > 1 else "AI_Forex_Brain_2.ipynb"
              
              if not os.path.exists(notebook):
                  print(f"‚ùå Not found: {notebook}")
                  sys.exit(1)
              
              print("=" * 70)
              print("üíº WEEKDAY FULL NOTEBOOK - TRADE BEACON v17.0")
              print("=" * 70)
              print(f"üìÖ {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}")
              print(f"üìì {notebook}")
              print("üî¥ Trade Beacon v17.0: Enhanced Production Edition")
              print("   ‚Ä¢ Full Data Pipeline")
              print("   ‚Ä¢ Ultra-Persistent Learning")
              print("   ‚Ä¢ Deep Q-Learning with Experience Replay")
              print("   ‚Ä¢ Pipeline Database Integration")
              print("   ‚Ä¢ Live Trading Mode Active")
              print("=" * 70)
              print()
              
              success = run_notebook(notebook)
              
              print()
              print("=" * 70)
              if success:
                  print("‚úÖ WEEKDAY EXECUTION COMPLETED")
              else:
                  print("‚ùå WEEKDAY EXECUTION FAILED")
              print(f"üìÖ {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}")
              print("=" * 70)
              
              sys.exit(0 if success else 1)
          EOFPYTHON
          
          # Find notebook file
          NOTEBOOK_FILE="AI_Forex_Brain_2.ipynb"
          
          if [ ! -f "$NOTEBOOK_FILE" ]; then
            echo "‚ùå Notebook not found: $NOTEBOOK_FILE"
            exit 1
          fi
          
          echo "‚úÖ Found: $NOTEBOOK_FILE"
          echo ""
          
          python run_full_notebook.py "$NOTEBOOK_FILE" 2>&1 | tee notebook_execution.log
          
          EXIT_CODE=${PIPESTATUS[0]}
          if [ $EXIT_CODE -ne 0 ]; then
            echo ""
            echo "‚ùå Notebook execution failed with exit code $EXIT_CODE"
            tail -n 200 notebook_execution.log
            exit $EXIT_CODE
          fi
          
          echo ""
          echo "‚úÖ Notebook execution completed successfully"
        timeout-minutes: 50

      - name: Verify output files
        if: always()
        run: |
          echo "=========================================="
          echo "üìã CHECKING OUTPUT FILES"
          echo "=========================================="
          echo "Mode: ${{ steps.detect_mode.outputs.execution_mode }}"
          echo ""
          
          for dir in outputs data/processed logs database rl_memory rl_models omega_state; do
            if [ -d "$dir" ]; then
              FILE_COUNT=$(find "$dir" -type f 2>/dev/null | wc -l)
              echo "  ‚úÖ $dir/ ($FILE_COUNT files)"
            else
              echo "  ‚ö†Ô∏è  $dir/ not found"
            fi
          done
          
          echo ""
          echo "Key Files:"
          for file in outputs/omega_signals.json outputs/latest_signals.json database/memory_v85.db; do
            if [ -f "$file" ]; then
              SIZE=$(wc -c < "$file")
              echo "  ‚úÖ $file ($SIZE bytes)"
            else
              echo "  ‚ö†Ô∏è  $file missing"
            fi
          done
          
          PICKLE_COUNT=$(find data/processed -name "*.pkl" -type f 2>/dev/null | \
            grep -v "_model\|cache\|\.bak" | wc -l)
          echo ""
          echo "üì¶ Data Files:"
          echo "   ‚Ä¢ Processed pickles: $PICKLE_COUNT"
          
          # Check RL state
          if [ -d "rl_memory" ]; then
            RL_FILES=$(find rl_memory -name "*.pkl" -o -name "*.json" -type f 2>/dev/null | wc -l)
            echo "   ‚Ä¢ RL memory files: $RL_FILES"
            
            if [ -f "rl_memory/experience_replay.pkl" ]; then
              echo "   ‚Ä¢ Experience replay: ‚úÖ"
            fi
            if [ -f "rl_models/q_network.npz" ]; then
              echo "   ‚Ä¢ Q-network: ‚úÖ"
            fi
          else
            echo "   ‚Ä¢ RL state: ‚ö†Ô∏è  Not found"
          fi
          
          if [ $PICKLE_COUNT -ge 4 ]; then
            echo ""
            echo "‚úÖ Data ready for Trade Beacon v17.0"
          else
            echo ""
            echo "‚ö†Ô∏è  Insufficient data (need ‚â•4 pickles)"
          fi
          echo "=========================================="

      - name: Clean up nested repositories
        if: always()
        run: |
          find . -mindepth 2 -type d -name ".git" -exec rm -rf {} + 2>/dev/null || true
          [ -d "forex-alpha-models" ] && rm -rf forex-alpha-models
          echo "‚úÖ Cleanup complete"

      - name: Commit and push changes
        if: always()
        run: |
          git add -A
          
          if git diff --cached --quiet; then
            echo "‚ÑπÔ∏è  No changes to commit"
          else
            TIMESTAMP=$(date +'%Y-%m-%d %H:%M UTC')
            DAY=$(date +'%A')
            MODE="${{ steps.detect_mode.outputs.execution_mode }}"
            
            if [ "$MODE" = "weekend_tagged_cells" ]; then
              COMMIT_MSG="üñèÔ∏è Trade Beacon v17.0 [Weekend Learning] - $DAY: $TIMESTAMP"
            else
              COMMIT_MSG="üî¥ Trade Beacon v17.0 [Live Trading] - $DAY: $TIMESTAMP"
            fi
            
            git commit -m "$COMMIT_MSG" || true
            
            echo "Syncing with remote..."
            for i in {1..3}; do
              echo "Attempt $i: Pulling..."
              if git pull --rebase origin main 2>&1 | grep -q "CONFLICT"; then
                echo "‚ö†Ô∏è  Resolving conflict..."
                git checkout --ours .
                git add -A
                git rebase --continue || true
              fi
              
              echo "Attempt $i: Pushing..."
              if git push origin main 2>&1; then
                echo "‚úÖ Pushed on attempt $i"
                break
              else
                echo "‚ö†Ô∏è  Failed attempt $i"
                if [ $i -lt 3 ]; then
                  sleep 3
                  git fetch origin main
                  git reset --soft origin/main
                  git add -A
                  git commit -m "$COMMIT_MSG" || true
                fi
              fi
            done
          fi

      - name: Upload logs and artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: execution-logs-${{ github.run_number }}
          path: |
            notebook_execution.log
            run_full_notebook.py
            run_tagged_cells.py
            logs/*.log
          retention-days: 7
          if-no-files-found: ignore

      - name: Execution Summary
        if: always()
        run: |
          echo "=========================================="
          echo "üìä EXECUTION SUMMARY"
          echo "=========================================="
          echo "Mode: ${{ steps.detect_mode.outputs.execution_mode }}"
          echo "Schedule: ${{ steps.detect_mode.outputs.schedule_type }}"
          echo "Day: $(date +'%A')"
          echo "Time: $(date +'%B %d, %Y %H:%M UTC')"
          echo ""
          
          if [ "${{ steps.detect_mode.outputs.execution_mode }}" = "weekend_tagged_cells" ]; then
            echo "üñèÔ∏è Weekend Mode (Sat-Sun):"
            echo "   ‚Ä¢ Executed: Tagged cells only (#TAG: pipeline_main)"
            echo "   ‚Ä¢ Schedule: Every 30 minutes"
            echo "   ‚Ä¢ Components:"
            echo "     1. Ultra-Persistent Pipeline (Learning Mode)"
            echo "     2. Trade Beacon v17.0 (Learning Mode)"
            echo "   ‚Ä¢ Trading: Learning only, no live signals"
            echo "   ‚Ä¢ Database: Learning continues from completed trades"
            echo "   ‚Ä¢ Backtest: Running on historical data"
            echo "   ‚Ä¢ Next run: In ~30 minutes"
          else
            echo "üíº Weekday Mode (Mon-Fri):"
            echo "   ‚Ä¢ Executed: Full notebook (all cells)"
            echo "   ‚Ä¢ Schedule: Every 2 hours"
            echo "   ‚Ä¢ Pipeline: Complete data fetch + processing"
            echo "   ‚Ä¢ Components:"
            echo "     1. API Keys ‚Üí Environment Setup"
            echo "     2. GitHub Sync"
            echo "     3. Alpha Vantage Data Fetch"
            echo "     4. YFinance Data Fetch"
            echo "     5. CSV Combiner with Indicators"
            echo "     6. Ultra-Persistent Pipeline (Live Mode)"
            echo "     7. Trade Beacon v17.0 (Live Trading)"
            echo "   ‚Ä¢ Trading: LIVE MODE - Real money at risk"
            echo "   ‚Ä¢ Database: Full learning + live signal storage"
            echo "   ‚Ä¢ Next run: In ~2 hours"
          fi
          echo ""
          
          echo "Generated Files:"
          find outputs -type f -exec sh -c 'echo "  ‚úÖ $(basename {}) ($(wc -c < {} 2>/dev/null || echo 0) bytes)"' \; 2>/dev/null | head -10
          echo ""
          
          PICKLE_COUNT=$(find data/processed -name "*.pkl" -type f 2>/dev/null | \
            grep -v "_sgd_model\|_rf_model\|indicator_cache\|ultra_\|alpha_\|_model.pkl\|\.bak" | wc -l)
          
          echo "üì¶ Data Files:"
          echo "   ‚Ä¢ Processed pickles: $PICKLE_COUNT"
          
          if [ -f "database/memory_v85.db" ]; then
