name: Smart Forex Brain Pipeline (Weekday Full / Weekend Tagged)

on:
  workflow_dispatch:
  push:
    paths:
      - 'colab_trigger.txt'
    branches:
      - main
  schedule:
    - cron: '0 */4 * * *'

jobs:
  run-forex-brain:
    runs-on: ubuntu-latest
    timeout-minutes: 55

    env:
      FOREX_PAT: ${{ secrets.FOREX_PAT }}
      BROWSERLESS_TOKEN: ${{ secrets.BROWSERLESS_TOKEN }}
      ALPHA_VANTAGE_KEY: ${{ secrets.ALPHA_VANTAGE_KEY }}
      GMAIL_USER: ${{ secrets.GMAIL_USER }}
      GMAIL_APP_PASSWORD: ${{ secrets.GMAIL_APP_PASSWORD }}
      GIT_USER_NAME: "Forex AI Bot"
      GIT_USER_EMAIL: "nakatonabira3@gmail.com"
      GITHUB_USERNAME: "rahim-dotAI"
      GITHUB_REPO: "forex-ai-models"
      PYTHONIOENCODING: utf-8
      PYTHONUNBUFFERED: 1
      GITHUB_ACTIONS: "true"
      SINGLE_RUN_MODE: "true"

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          persist-credentials: false
          fetch-depth: 0
          lfs: true
          token: ${{ secrets.FOREX_PAT }}

      - name: Fix submodule issue
        run: |
          echo "=========================================="
          echo "üîß FIXING SUBMODULE CONFIGURATION"
          echo "=========================================="
          
          if [ -f ".gitmodules" ]; then
            echo "‚ö†Ô∏è Found .gitmodules file - removing it"
            rm -f .gitmodules
            git rm --cached -r forex-alpha-models 2>/dev/null || true
            rm -rf forex-alpha-models
            git add .gitmodules 2>/dev/null || true
            echo "‚úÖ Submodule configuration removed"
          else
            echo "‚úÖ No .gitmodules file found"
          fi
          
          find . -mindepth 2 -name ".git" -type d -exec rm -rf {} + 2>/dev/null || true
          echo "=========================================="

      - name: Detect Weekend vs Weekday Mode
        id: detect_mode
        run: |
          DAY_OF_WEEK=$(date +%u)
          
          echo "=========================================="
          echo "üóìÔ∏è  DAY DETECTION"
          echo "=========================================="
          echo "Current day: $DAY_OF_WEEK (1=Mon, 7=Sun)"
          echo "Date: $(date +'%A, %B %d, %Y %H:%M UTC')"
          
          if [ $DAY_OF_WEEK -eq 6 ] || [ $DAY_OF_WEEK -eq 7 ]; then
            echo "is_weekend=true" >> $GITHUB_OUTPUT
            echo "execution_mode=weekend_tagged_cell" >> $GITHUB_OUTPUT
            echo "üéØ MODE: WEEKEND (Tagged Cell v8.5 Only)"
          else
            echo "is_weekend=false" >> $GITHUB_OUTPUT
            echo "execution_mode=weekday_full_notebook" >> $GITHUB_OUTPUT
            echo "üéØ MODE: WEEKDAY (Full Notebook Execution)"
          fi
          echo "=========================================="

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip wheel setuptools
          pip install --no-cache-dir \
            pandas numpy requests beautifulsoup4 scikit-learn jupyter nbconvert ta nbformat

      - name: Configure Git
        run: |
          git config --global user.name "${GIT_USER_NAME}"
          git config --global user.email "${GIT_USER_EMAIL}"
          git config --global credential.helper store
          echo "https://${GITHUB_USERNAME}:${FOREX_PAT}@github.com" > ~/.git-credentials

      - name: Verify data files exist (WEEKEND ONLY)
        if: steps.detect_mode.outputs.is_weekend == 'true'
        run: |
          echo "=========================================="
          echo "VERIFYING DATA FILES FOR WEEKEND RUN"
          echo "=========================================="
          
          PICKLE_COUNT=$(find . -maxdepth 1 -name "*_2244.pkl" -type f 2>/dev/null | wc -l)
          
          if [ $PICKLE_COUNT -lt 4 ]; then
            echo "‚ùå ERROR: Only $PICKLE_COUNT/4 pickle files found"
            echo "Weekend mode requires existing data files!"
            echo ""
            echo "Available files:"
            ls -lh *.pkl 2>/dev/null || echo "No pickle files found"
            echo ""
            echo "üí° TIP: Run the workflow on a weekday first to generate data files"
            exit 1
          fi
          
          echo "‚úÖ Found all required data files ($PICKLE_COUNT)"
          echo "Files:"
          ls -lh *_2244.pkl
          echo "=========================================="

      - name: Run Tagged Cell v8.5 Pipeline (WEEKEND ONLY)
        if: steps.detect_mode.outputs.is_weekend == 'true'
        run: |
          echo "=========================================="
          echo "üü¢ RUNNING TAGGED CELL v8.5 PIPELINE"
          echo "=========================================="
          echo "Mode: ${{ steps.detect_mode.outputs.execution_mode }}"
          echo ""
          
          PIPELINE_FILE=""
          if [ -f "forex_pipeline_v851.py" ]; then
            PIPELINE_FILE="forex_pipeline_v851.py"
          elif [ -f "forex_pipeline_v85.py" ]; then
            PIPELINE_FILE="forex_pipeline_v85.py"
          elif [ -f "Ultimate_Forex_Pipeline_v851.py" ]; then
            PIPELINE_FILE="Ultimate_Forex_Pipeline_v851.py"
          fi
          
          if [ -z "$PIPELINE_FILE" ]; then
            echo "‚ùå ERROR: Could not find v8.5 pipeline file!"
            exit 1
          fi
          
          echo "‚úÖ Found: $PIPELINE_FILE"
          echo ""
          
          # Run with clean output (suppress verbose logs)
          python "$PIPELINE_FILE" 2>&1 | grep -v "^\[DEBUG\]" | tee pipeline_output.log
          
          EXIT_CODE=${PIPESTATUS[0]}
          if [ $EXIT_CODE -ne 0 ]; then
            echo ""
            echo "‚ùå Pipeline failed with exit code $EXIT_CODE"
            tail -n 100 pipeline_output.log
            exit $EXIT_CODE
          fi
          
          echo ""
          echo "‚úÖ Pipeline completed successfully"
        timeout-minutes: 25

      - name: Run Full Notebook (WEEKDAY ONLY - Monday to Friday)
        if: steps.detect_mode.outputs.is_weekend == 'false'
        run: |
          echo "=========================================="
          echo "üìì RUNNING FULL NOTEBOOK"
          echo "=========================================="
          echo "Mode: ${{ steps.detect_mode.outputs.execution_mode }}"
          echo "Day: $(date +'%A')"
          echo ""
          
          # Check if notebook exists
          NOTEBOOK_FILE=""
          if [ -f "AI_Forex_Brain_2.ipynb" ]; then
            NOTEBOOK_FILE="AI_Forex_Brain_2.ipynb"
          elif [ -f "AI_Forex_Brain.ipynb" ]; then
            NOTEBOOK_FILE="AI_Forex_Brain.ipynb"
          elif [ -f "forex_brain.ipynb" ]; then
            NOTEBOOK_FILE="forex_brain.ipynb"
          fi
          
          if [ -z "$NOTEBOOK_FILE" ]; then
            echo "‚ùå ERROR: No notebook file found!"
            exit 1
          fi
          
          echo "‚úÖ Found: $NOTEBOOK_FILE"
          echo ""
          
          # CRITICAL FIX: Patch notebook to fix /content paths
          echo "üîß Patching notebook for GitHub Actions environment..."
          python3 << PATCH_EOF
import json
import sys
import os

try:
    notebook_file = "${NOTEBOOK_FILE}"
    
    # Read notebook
    with open(notebook_file, 'r') as f:
        nb = json.load(f)
    
    patched_cells = 0
    
    # Fix each code cell
    for cell in nb.get('cells', []):
        if cell.get('cell_type') == 'code':
            source = cell.get('source', [])
            if isinstance(source, list):
                source = ''.join(source)
            
            # Check if this cell has /content path issues
            if '/content' in source and 'IN_COLAB' not in source:
                # Replace /content paths with proper environment detection
                original = source
                
                # Fix common patterns
                source = source.replace(
                    'ROOT_DIR = Path("/content/forex-alpha-models")',
                    'ROOT_DIR = Path.cwd() if "GITHUB_ACTIONS" in os.environ else Path("/content/forex-alpha-models")'
                )
                
                source = source.replace(
                    'os.makedirs("/content/forex-alpha-models"',
                    'os.makedirs(str(ROOT_DIR)'
                )
                
                # Add environment check if missing
                if 'Path("/content' in source and 'IN_COLAB' not in source:
                    source = source.replace(
                        'from pathlib import Path',
                        'from pathlib import Path\nimport os\n\n# Auto-detect environment\nROOT_DIR = Path.cwd() if os.environ.get("GITHUB_ACTIONS") else Path("/content/forex-alpha-models")\n'
                    )
                
                if source != original:
                    cell['source'] = source.split('\n')
                    if cell['source'][-1] == '':
                        cell['source'] = [line + '\n' for line in cell['source'][:-1]] + [cell['source'][-1]]
                    else:
                        cell['source'] = [line + '\n' for line in cell['source']]
                    patched_cells += 1
    
    # Save patched notebook
    with open(notebook_file, 'w') as f:
        json.dump(nb, f, indent=1)
    
    print(f"‚úÖ Patched {patched_cells} cells")
    
except Exception as e:
    print(f"‚ö†Ô∏è Patch warning: {e}")
    print("Continuing anyway...")

PATCH_EOF
          
          echo ""
          
          # Create enhanced Python script with cell progress tracking
          cat > run_full_notebook.py << 'EOFPYTHON'
          import nbformat
          from nbconvert.preprocessors import ExecutePreprocessor, CellExecutionError
          import sys
          import os
          import time
          import re
          from datetime import datetime
          
          class ProgressTrackingExecutor(ExecutePreprocessor):
              """Custom executor that shows progress and only cell outputs"""
              
              def __init__(self, *args, **kwargs):
                  super().__init__(*args, **kwargs)
                  self.total_cells = 0
                  self.current_cell = 0
                  self.start_time = None
                  self.cell_errors = []
                  
              def preprocess(self, nb, resources=None, km=None):
                  """Override to track total cells"""
                  # Count code cells
                  self.total_cells = sum(1 for cell in nb.cells if cell.cell_type == 'code')
                  self.current_cell = 0
                  self.start_time = time.time()
                  
                  print(f"üìä Total code cells to execute: {self.total_cells}")
                  print("=" * 70)
                  print()
                  
                  return super().preprocess(nb, resources, km)
              
              def preprocess_cell(self, cell, resources, cell_index):
                  """Override to show progress before executing each cell"""
                  if cell.cell_type != 'code':
                      return cell, resources
                  
                  self.current_cell += 1
                  elapsed = time.time() - self.start_time
                  
                  # Calculate progress
                  progress_pct = (self.current_cell / self.total_cells) * 100
                  
                  # Show cell header with progress
                  print()
                  print("=" * 70)
                  print(f"üîÑ EXECUTING CELL {self.current_cell}/{self.total_cells} " 
                        f"({progress_pct:.1f}% complete)")
                  print(f"‚è±Ô∏è  Elapsed time: {elapsed:.1f}s")
                  
                  # Show first line of cell source (if not too long)
                  if cell.source:
                      first_line = cell.source.split('\n')[0][:60]
                      if first_line.strip():
                          print(f"üìù Cell preview: {first_line}...")
                  
                  print("-" * 70)
                  
                  # Execute the cell
                  cell_start = time.time()
                  
                  try:
                      cell, resources = super().preprocess_cell(cell, resources, cell_index)
                      cell_duration = time.time() - cell_start
                      
                      # Show cell outputs (cleaned)
                      if cell.outputs:
                          for output in cell.outputs:
                              # Handle different output types
                              if output.output_type == 'stream':
                                  text = output.text
                                  # Clean up the output
                                  text = self._clean_output(text)
                                  if text.strip():
                                      print(text)
                              
                              elif output.output_type == 'execute_result':
                                  if 'text/plain' in output.data:
                                      text = output.data['text/plain']
                                      text = self._clean_output(text)
                                      if text.strip():
                                          print(text)
                              
                              elif output.output_type == 'error':
                                  error_info = f"Cell {self.current_cell}: {output.ename}: {output.evalue}"
                                  self.cell_errors.append(error_info)
                                  print(f"‚ùå ERROR in cell {self.current_cell}:")
                                  print(f"   {output.ename}: {output.evalue}")
                                  if output.traceback:
                                      # Show only last 3 lines of traceback
                                      print("   Traceback (last 3 lines):")
                                      for line in output.traceback[-3:]:
                                          # Remove ANSI codes
                                          line = re.sub(r'\x1b\[[0-9;]*m', '', line)
                                          print(f"   {line}")
                      
                      # Show cell completion
                      print("-" * 70)
                      print(f"‚úÖ Cell {self.current_cell}/{self.total_cells} completed in {cell_duration:.1f}s")
                      print("=" * 70)
                      
                  except Exception as e:
                      cell_duration = time.time() - cell_start
                      error_msg = f"Cell {self.current_cell}: {type(e).__name__}: {str(e)}"
                      self.cell_errors.append(error_msg)
                      
                      print("-" * 70)
                      print(f"‚ùå Cell {self.current_cell}/{self.total_cells} FAILED after {cell_duration:.1f}s")
                      print(f"   Error: {type(e).__name__}: {str(e)}")
                      print("=" * 70)
                      
                      # Re-raise to stop execution
                      raise
                  
                  return cell, resources
              
              def _clean_output(self, text):
                  """Clean output text - remove debug logs, empty lines, etc."""
                  if not text:
                      return ""
                  
                  lines = []
                  skip_patterns = [
                      '[DEBUG]', 'WARNING:', 'DeprecationWarning',
                      'FutureWarning', 'UserWarning', 'RuntimeWarning'
                  ]
                  
                  for line in text.split('\n'):
                      # Skip debug/verbose lines
                      if any(skip in line for skip in skip_patterns):
                          continue
                      
                      # Skip very long lines (likely progress bars)
                      if len(line) > 200:
                          continue
                      
                      # Remove ANSI color codes
                      line = re.sub(r'\x1b\[[0-9;]*m', '', line)
                      
                      # Keep the line if it has content
                      if line.strip():
                          lines.append(line)
                  
                  return '\n'.join(lines)
          
          def run_notebook(notebook_path):
              """Execute entire Jupyter notebook with progress tracking"""
              print(f"üìñ Reading notebook: {notebook_path}")
              
              # Read the notebook
              try:
                  with open(notebook_path, 'r', encoding='utf-8') as f:
                      nb = nbformat.read(f, as_version=4)
              except Exception as e:
                  print(f"‚ùå Failed to read notebook: {e}")
                  return False
              
              code_cells = sum(1 for c in nb.cells if c.cell_type == 'code')
              markdown_cells = sum(1 for c in nb.cells if c.cell_type == 'markdown')
              
              print(f"‚úÖ Loaded notebook:")
              print(f"   ‚Ä¢ Total cells: {len(nb.cells)}")
              print(f"   ‚Ä¢ Code cells: {code_cells}")
              print(f"   ‚Ä¢ Markdown cells: {markdown_cells}")
              print()
              
              # Configure custom executor
              ep = ProgressTrackingExecutor(
                  timeout=2400,  # 40 minutes per cell
                  kernel_name='python3',
                  allow_errors=False,
                  store_widget_state=True
              )
              
              print("üöÄ Starting notebook execution...")
              print()
              
              try:
                  # Execute the notebook
                  start_time = time.time()
                  ep.preprocess(nb, {'metadata': {'path': '.'}})
                  total_duration = time.time() - start_time
                  
                  print()
                  print("=" * 70)
                  print("‚úÖ NOTEBOOK EXECUTION COMPLETED SUCCESSFULLY!")
                  print("=" * 70)
                  print(f"‚è±Ô∏è  Total execution time: {total_duration:.1f}s ({total_duration/60:.1f} minutes)")
                  print(f"üìä Cells executed: {code_cells}")
                  print(f"‚ö° Average time per cell: {total_duration/code_cells:.1f}s")
                  
                  if ep.cell_errors:
                      print(f"‚ö†Ô∏è  Errors encountered: {len(ep.cell_errors)}")
                      for error in ep.cell_errors:
                          print(f"   - {error}")
                  
                  print("=" * 70)
                  
                  # Save executed notebook
                  output_path = notebook_path.replace('.ipynb', '_executed.ipynb')
                  try:
                      with open(output_path, 'w', encoding='utf-8') as f:
                          nbformat.write(nb, f)
                      print(f"üíæ Saved executed notebook: {output_path}")
                  except Exception as e:
                      print(f"‚ö†Ô∏è  Could not save executed notebook: {e}")
                  
                  return True
                  
              except CellExecutionError as e:
                  print()
                  print("=" * 70)
                  print("‚ùå CELL EXECUTION FAILED!")
                  print("=" * 70)
                  
                  # Extract cell information
                  cell_num = getattr(ep, 'current_cell', 'unknown')
                  print(f"Failed at: Cell {cell_num}/{ep.total_cells}")
                  
                  if hasattr(e, 'ename') and hasattr(e, 'evalue'):
                      print(f"Error type: {e.ename}")
                      print(f"Error message: {e.evalue}")
                  else:
                      print(f"Error: {str(e)}")
                  
                  if hasattr(e, 'traceback') and e.traceback:
                      print("\nTraceback (last 5 lines):")
                      for line in e.traceback[-5:]:
                          line = re.sub(r'\x1b\[[0-9;]*m', '', line)
                          print(line)
                  
                  if ep.cell_errors:
                      print(f"\nAll errors encountered ({len(ep.cell_errors)}):")
                      for error in ep.cell_errors:
                          print(f"   - {error}")
                  
                  print("=" * 70)
                  return False
              
              except Exception as e:
                  print()
                  print("=" * 70)
                  print("‚ùå UNEXPECTED ERROR!")
                  print("=" * 70)
                  print(f"Error type: {type(e).__name__}")
                  print(f"Error: {str(e)}")
                  
                  if hasattr(ep, 'cell_errors') and ep.cell_errors:
                      print(f"\nErrors before crash ({len(ep.cell_errors)}):")
                      for error in ep.cell_errors:
                          print(f"   - {error}")
                  
                  print("=" * 70)
                  return False
          
          if __name__ == "__main__":
              notebook = sys.argv[1] if len(sys.argv) > 1 else "AI_Forex_Brain_2.ipynb"
              
              if not os.path.exists(notebook):
                  print(f"‚ùå ERROR: Notebook not found: {notebook}")
                  sys.exit(1)
              
              print("=" * 70)
              print("üß† FOREX AI BRAIN - FULL NOTEBOOK EXECUTION")
              print("=" * 70)
              print(f"üìÖ Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}")
              print(f"üìì Notebook: {notebook}")
              print(f"üåç Environment: GitHub Actions")
              print(f"üìÇ Working Directory: {os.getcwd()}")
              print("=" * 70)
              print()
              
              success = run_notebook(notebook)
              
              print()
              print("=" * 70)
              if success:
                  print("‚úÖ EXECUTION COMPLETED SUCCESSFULLY")
              else:
                  print("‚ùå EXECUTION FAILED")
              print(f"üìÖ Finished: {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}")
              print("=" * 70)
              
              sys.exit(0 if success else 1)
          EOFPYTHON
          
          echo "üîß Created enhanced notebook executor"
          echo ""
          
          # Execute the notebook
          python run_full_notebook.py "$NOTEBOOK_FILE" 2>&1 | tee notebook_execution.log
          
          EXIT_CODE=${PIPESTATUS[0]}
          if [ $EXIT_CODE -ne 0 ]; then
            echo ""
            echo "‚ùå Notebook execution failed with exit code $EXIT_CODE"
            echo ""
            echo "Last 200 lines of output:"
            tail -n 200 notebook_execution.log
            exit $EXIT_CODE
          fi
          
          echo ""
          echo "‚úÖ Full notebook executed successfully"
        timeout-minutes: 50

      - name: Verify output files
        if: always()
        run: |
          echo "=========================================="
          echo "üìã CHECKING OUTPUT FILES"
          echo "=========================================="
          
          # Check for pickle files
          echo "Pickle files:"
          if ls *_2244.pkl 1> /dev/null 2>&1; then
            ls -lh *_2244.pkl
          else
            echo "  ‚ö†Ô∏è  No pickle files found"
          fi
          echo ""
          
          # Check for signal files
          echo "Signal files:"
          if [ -f "broker_signals.json" ]; then
            FILE_SIZE=$(wc -c < "broker_signals.json")
            echo "  ‚úÖ broker_signals.json (${FILE_SIZE} bytes)"
          else
            echo "  ‚ö†Ô∏è  broker_signals.json not found"
          fi
          
          if [ -f "ensemble_signals.json" ]; then
            FILE_SIZE=$(wc -c < "ensemble_signals.json")
            echo "  ‚úÖ ensemble_signals.json (${FILE_SIZE} bytes)"
          else
            echo "  ‚ö†Ô∏è  ensemble_signals.json not found"
          fi
          echo ""
          
          # Check for learning files
          echo "Learning files:"
          for file in learning_v85.pkl iteration_v85.pkl memory_v85.db; do
            if [ -f "$file" ]; then
              FILE_SIZE=$(wc -c < "$file")
              echo "  ‚úÖ $file (${FILE_SIZE} bytes)"
            else
              echo "  ‚ö†Ô∏è  $file not found"
            fi
          done
          echo "=========================================="

      - name: Clean up nested git repositories and folders
        if: always()
        run: |
          echo "=========================================="
          echo "üßπ CLEANING NESTED REPOSITORIES & FOLDERS"
          echo "=========================================="
          
          if [ -d "forex-alpha-models" ]; then
            echo "üóëÔ∏è  Removing entire forex-alpha-models folder"
            rm -rf forex-alpha-models
            echo "‚úÖ Removed nested folder structure"
          fi
          
          NESTED_REPOS=$(find . -mindepth 2 -type d -name ".git" 2>/dev/null)
          
          if [ -n "$NESTED_REPOS" ]; then
            echo "Found additional nested repositories:"
            echo "$NESTED_REPOS"
            
            while IFS= read -r git_dir; do
              if [ -n "$git_dir" ] && [ -d "$git_dir" ]; then
                echo "üóëÔ∏è  Removing: $git_dir"
                rm -rf "$git_dir"
              fi
            done <<< "$NESTED_REPOS"
            
            echo "‚úÖ All nested git repositories removed"
          else
            echo "‚úÖ No additional nested repositories found"
          fi
          
          echo "=========================================="

      - name: Commit and push changes
        if: always()
        run: |
          git add -A
          
          if git diff --cached --quiet; then
            echo "‚ÑπÔ∏è  No changes to commit"
          else
            MODE="${{ steps.detect_mode.outputs.execution_mode }}"
            TIMESTAMP=$(date +'%Y-%m-%d %H:%M:%S UTC')
            DAY=$(date +'%A')
            
            git commit -m "ü§ñ Auto-update [$MODE] - $DAY: $TIMESTAMP" || true
            
            echo "Syncing with remote..."
            for i in {1..3}; do
              echo "Attempt $i: Pulling latest changes..."
              if git pull --rebase origin main 2>&1 | grep -q "CONFLICT"; then
                echo "‚ö†Ô∏è  Conflict detected, resolving with ours strategy..."
                git checkout --ours .
                git add -A
                git rebase --continue || true
              fi
              
              echo "Attempt $i: Pushing to GitHub..."
              if git push origin main 2>&1; then
                echo "‚úÖ Successfully pushed on attempt $i"
                break
              else
                echo "‚ö†Ô∏è  Push failed on attempt $i"
                if [ $i -lt 3 ]; then
                  echo "Waiting 3 seconds before retry..."
                  sleep 3
                  git fetch origin main
                  git reset --soft origin/main
                  git add -A
                  git commit -m "ü§ñ Auto-update [$MODE] - $DAY: $TIMESTAMP" || true
                else
                  echo "‚ùå All push attempts failed"
                  exit 1
                fi
              fi
            done
          fi

      - name: Upload logs and artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-logs-${{ github.run_number }}
          path: |
            pipeline_output.log
            notebook_execution.log
            *_executed.ipynb
            run_full_notebook.py
            forex_pipeline_v85.log
            pipeline.log
          retention-days: 7
          if-no-files-found: ignore

      - name: Summary
        if: always()
        run: |
          echo "=========================================="
          echo "üìä EXECUTION SUMMARY"
          echo "=========================================="
          echo "Mode: ${{ steps.detect_mode.outputs.execution_mode }}"
          echo "Weekend: ${{ steps.detect_mode.outputs.is_weekend }}"
          echo "Day: $(date +'%A')"
          echo "Date: $(date +'%B %d, %Y %H:%M UTC')"
          echo ""
          echo "Generated Files:"
          
          if [ -f "broker_signals.json" ]; then
            FILE_SIZE=$(wc -c < "broker_signals.json" 2>/dev/null || echo "0")
            echo "  ‚úÖ broker_signals.json (${FILE_SIZE} bytes)"
          fi
          
          if [ -f "ensemble_signals.json" ]; then
            FILE_SIZE=$(wc -c < "ensemble_signals.json" 2>/dev/null || echo "0")
            echo "  ‚úÖ ensemble_signals.json (${FILE_SIZE} bytes)"
          fi
          
          if [ -f "learning_v85.pkl" ]; then
            FILE_SIZE=$(wc -c < "learning_v85.pkl" 2>/dev/null || echo "0")
            echo "  ‚úÖ learning_v85.pkl (${FILE_SIZE} bytes)"
          fi
          
          if [ -f "iteration_v85.pkl" ]; then
            FILE_SIZE=$(wc -c < "iteration_v85.pkl" 2>/dev/null || echo "0")
            echo "  ‚úÖ iteration_v85.pkl (${FILE_SIZE} bytes)"
          fi
          
          if [ -f "memory_v85.db" ]; then
            FILE_SIZE=$(wc -c < "memory_v85.db" 2>/dev/null || echo "0")
            echo "  ‚úÖ memory_v85.db (${FILE_SIZE} bytes)"
          fi
          
          PICKLE_COUNT=$(find . -maxdepth 1 -name "*_2244.pkl" -type f 2>/dev/null | wc -l)
          if [ $PICKLE_COUNT -gt 0 ]; then
            echo "  ‚úÖ ${PICKLE_COUNT} pickle data files"
          fi
          
          echo "=========================================="
