name: Smart Forex Brain Pipeline (Weekend-Aware Auto-Detect)

on:
  workflow_dispatch:
  push:
    paths:
      - 'colab_trigger.txt'
    branches:
      - main
  schedule:
    # Run multiple times on weekdays and weekends
    - cron: '0 */4 * * *'  # Every 4 hours

jobs:
  run-forex-brain:
    runs-on: ubuntu-latest
    timeout-minutes: 55

    env:
      FOREX_PAT: ${{ secrets.FOREX_PAT }}
      BROWSERLESS_TOKEN: ${{ secrets.BROWSERLESS_TOKEN }}
      ALPHA_VANTAGE_KEY: ${{ secrets.ALPHA_VANTAGE_KEY }}
      GMAIL_USER: ${{ secrets.GMAIL_USER }}
      GMAIL_APP_PASSWORD: ${{ secrets.GMAIL_APP_PASSWORD }}
      GIT_USER_NAME: "Forex AI Bot"
      GIT_USER_EMAIL: "nakatonabira3@gmail.com"
      GITHUB_USERNAME: "rahim-dotAI"
      GITHUB_REPO: "forex-ai-models"
      PYTHONIOENCODING: utf-8
      PYTHONUNBUFFERED: 1
      GITHUB_ACTIONS: "true"
      SINGLE_RUN_MODE: "true"

    steps:
      - name: Pre-cleanup
        run: |
          sudo rm -rf /content 2>/dev/null || true
          rm -f .gitmodules 2>/dev/null || true

      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          persist-credentials: false
          fetch-depth: 0
          lfs: false
          submodules: false
          clean: true

      - name: Detect Weekend vs Weekday Mode
        id: detect_mode
        run: |
          # Get current day of week (0=Sunday, 1=Monday, ..., 6=Saturday)
          DAY_OF_WEEK=$(date +%u)  # 1=Monday, 7=Sunday
          
          echo "=========================================="
          echo "üóìÔ∏è  DAY DETECTION"
          echo "=========================================="
          echo "Current day number: $DAY_OF_WEEK (1=Mon, 7=Sun)"
          echo "Current date: $(date +'%A, %B %d, %Y %H:%M UTC')"
          echo ""
          
          # Saturday (6) or Sunday (7) = Weekend
          if [ $DAY_OF_WEEK -eq 6 ] || [ $DAY_OF_WEEK -eq 7 ]; then
            echo "is_weekend=true" >> $GITHUB_OUTPUT
            echo "execution_mode=weekend_v85_only" >> $GITHUB_OUTPUT
            echo "üéØ MODE: WEEKEND (v8.5 Pipeline Only)"
            echo "   ‚úÖ Will execute ONLY forex pipeline v8.5 code"
            echo "   ‚è≠Ô∏è  Skipping data fetching and full notebook"
          elif [ $DAY_OF_WEEK -eq 1 ]; then
            echo "is_weekend=false" >> $GITHUB_OUTPUT
            echo "execution_mode=monday_full" >> $GITHUB_OUTPUT
            echo "üéØ MODE: MONDAY (Full Pipeline)"
            echo "   ‚úÖ Will execute full notebook (data fetch + v8.5)"
          else
            echo "is_weekend=false" >> $GITHUB_OUTPUT
            echo "execution_mode=weekday_smart" >> $GITHUB_OUTPUT
            echo "üéØ MODE: WEEKDAY (Smart Detection)"
            echo "   ‚úÖ Will check data availability"
            echo "   ‚úÖ Full pipeline if missing data, v8.5 only if data exists"
          fi
          
          echo "=========================================="

      - name: Verify secrets
        run: |
          MISSING_SECRETS=()
          [ -z "${FOREX_PAT}" ] && MISSING_SECRETS+=("FOREX_PAT")
          [ -z "${BROWSERLESS_TOKEN}" ] && MISSING_SECRETS+=("BROWSERLESS_TOKEN")
          [ -z "${ALPHA_VANTAGE_KEY}" ] && MISSING_SECRETS+=("ALPHA_VANTAGE_KEY")
          [ -z "${GMAIL_USER}" ] && MISSING_SECRETS+=("GMAIL_USER")
          [ -z "${GMAIL_APP_PASSWORD}" ] && MISSING_SECRETS+=("GMAIL_APP_PASSWORD")
          
          if [ ${#MISSING_SECRETS[@]} -gt 0 ]; then
            echo "‚ö†Ô∏è  Missing secrets: ${MISSING_SECRETS[*]}"
          else
            echo "‚úÖ All secrets configured"
          fi

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip wheel setuptools
          pip install --no-cache-dir \
            mplfinance firebase-admin dropbox requests beautifulsoup4 \
            pandas numpy ta yfinance pyppeteer nest_asyncio lightgbm \
            joblib matplotlib alpha_vantage tqdm scikit-learn river \
            jupyter nbconvert

      - name: Create directory structure
        run: |
          sudo mkdir -p /content/forex-alpha-models/{csvs,pickles,logs,merged_data_pickles,temp_pickles,forex-ai-models}
          sudo chown -R $USER:$USER /content
          sudo chmod -R 755 /content
          mkdir -p $GITHUB_WORKSPACE/outputs/{csvs,pickles,logs,merged_data_pickles,temp_pickles}

      - name: Configure Git
        run: |
          git config --global user.name "${GIT_USER_NAME}"
          git config --global user.email "${GIT_USER_EMAIL}"
          git config --global advice.detachedHead false
          git config --global credential.helper store
          echo "https://${GITHUB_USERNAME}:${FOREX_PAT}@github.com" > ~/.git-credentials

      - name: Clone forex-ai-models repository
        run: |
          cd /content/forex-alpha-models
          if [ ! -d "forex-ai-models/.git" ]; then
            echo "üîÑ Cloning forex-ai-models repository..."
            git clone -b main https://${GITHUB_USERNAME}:${FOREX_PAT}@github.com/${GITHUB_USERNAME}/${GITHUB_REPO}.git forex-ai-models
          else
            echo "üì• Pulling latest changes..."
            cd forex-ai-models
            git pull origin main
          fi
          cd forex-ai-models
          git config user.name "${GIT_USER_NAME}"
          git config user.email "${GIT_USER_EMAIL}"
          
          echo ""
          echo "üìÇ Repository contents:"
          ls -la

      - name: Check data availability (Weekday Smart Mode Only)
        if: steps.detect_mode.outputs.execution_mode == 'weekday_smart'
        id: check_data
        run: |
          echo "=========================================="
          echo "CHECKING DATA FOR SMART MODE DECISION"
          echo "=========================================="
          
          REPO_PATH="/content/forex-alpha-models/forex-ai-models"
          
          # Check for merged pickle files (the key dependency for v8.5)
          MERGED_PKL_COUNT=$(find "$REPO_PATH" -maxdepth 1 -name "*_2244.pkl" -type f -size +10k 2>/dev/null | wc -l)
          
          echo "üìä Found $MERGED_PKL_COUNT merged pickle files (*_2244.pkl)"
          
          if [ $MERGED_PKL_COUNT -ge 4 ]; then
            echo "decision=v85_only" >> $GITHUB_OUTPUT
            echo "‚úÖ DECISION: Run v8.5 only (sufficient data exists)"
          else
            echo "decision=full_pipeline" >> $GITHUB_OUTPUT
            echo "‚ö†Ô∏è  DECISION: Run full pipeline (need fresh data)"
          fi
          
          echo "=========================================="

      - name: Copy existing data to working directories
        if: |
          steps.detect_mode.outputs.is_weekend == 'true' || 
          (steps.detect_mode.outputs.execution_mode == 'weekday_smart' && steps.check_data.outputs.decision == 'v85_only')
        run: |
          echo "üì¶ Copying existing data from repository..."
          
          REPO_PATH="/content/forex-alpha-models/forex-ai-models"
          
          # Create target directories
          mkdir -p /content/forex-alpha-models/{csvs,pickles,merged_data_pickles,logs}
          
          # Copy merged pickle files (CRITICAL for v8.5)
          if ls "$REPO_PATH"/*_2244.pkl 1> /dev/null 2>&1; then
            cp -v "$REPO_PATH"/*_2244.pkl /content/forex-alpha-models/merged_data_pickles/
            echo "‚úÖ Copied merged pickle files"
          else
            echo "‚ùå WARNING: No merged pickle files found!"
          fi
          
          # Copy other necessary files
          [ -d "$REPO_PATH"/*.csv ] && cp -v "$REPO_PATH"/*.csv /content/forex-alpha-models/csvs/ 2>/dev/null || true
          [ -d "$REPO_PATH"/*_indicators.pkl ] && cp -v "$REPO_PATH"/*_indicators.pkl /content/forex-alpha-models/pickles/ 2>/dev/null || true
          
          echo "‚úÖ Data copy complete"

      - name: Convert notebook to Python
        run: |
          jupyter nbconvert --to python "AI_Forex_Brain_2.ipynb" --output ai_forex_brain_2
          sed -i '/get_ipython()/d' ai_forex_brain_2.py
          sed -i '/^get_ipython/d' ai_forex_brain_2.py
          sed -i 's/\.mkdir(exist_ok=True)/.mkdir(parents=True, exist_ok=True)/g' ai_forex_brain_2.py

      - name: Apply path fixes
        run: |
          cat > path_fixes.sed << 'EOF'
          s|ROOT_DIR = Path("/content")|ROOT_DIR = Path("/content/forex-alpha-models")|g
          s|ROOT_PATH = ROOT_DIR / "forex-alpha-models"|ROOT_PATH = Path("/content/forex-alpha-models")|g
          s|BASE_DIR = Path(".")|BASE_DIR = Path("/content/forex-alpha-models")|g
          s|REPO_FOLDER = .* / "forex-ai-models"|REPO_FOLDER = Path("/content/forex-alpha-models/forex-ai-models")|g
          s|PICKLE_FOLDER = .* / "pickles"|PICKLE_FOLDER = Path("/content/forex-alpha-models/pickles")|g
          s|FINAL_PICKLE_FOLDER = .* / "merged_data_pickles"|FINAL_PICKLE_FOLDER = Path("/content/forex-alpha-models/merged_data_pickles")|g
          s|CSV_FOLDER = .* / "csvs"|CSV_FOLDER = Path("/content/forex-alpha-models/csvs")|g
          s|LOG_FOLDER = .* / "logs"|LOG_FOLDER = Path("/content/forex-alpha-models/logs")|g
          EOF
          sed -i -f path_fixes.sed ai_forex_brain_2.py

      - name: Extract v8.5 Pipeline Code Only
        if: |
          steps.detect_mode.outputs.is_weekend == 'true' || 
          (steps.detect_mode.outputs.execution_mode == 'weekday_smart' && steps.check_data.outputs.decision == 'v85_only')
        run: |
          cat > extract_v85.py << 'PYTHON_EOF'
          import re
          
          with open("ai_forex_brain_2.py", "r", encoding="utf-8") as f:
              content = f.read()
          
          print("=" * 80)
          print("üéØ EXTRACTING FOREX PIPELINE v8.5 CODE ONLY")
          print("=" * 80)
          
          # Search for the v8.5 pipeline cell marker
          pattern = r'#!/usr/bin/env python3\s*\n\s*"""\s*Ultimate.*?Forex.*?Pipeline.*?v8[.\d]*.*?OPTIMIZED'
          
          match = re.search(pattern, content, re.DOTALL | re.IGNORECASE)
          
          if match:
              start_pos = match.start()
              extracted_code = content[start_pos:]
              
              print(f"‚úÖ Found v8.5 pipeline at position {start_pos:,}")
              print(f"‚úÖ Extracted {len(extracted_code):,} characters")
              
              # Write extracted code
              with open("forex_pipeline_v85_only.py", "w", encoding="utf-8") as f:
                  f.write(extracted_code)
              
              lines = extracted_code.split('\n')
              print(f"‚úÖ Total lines: {len(lines):,}")
              print(f"\nFirst 5 lines:")
              for i, line in enumerate(lines[:5], 1):
                  print(f"  {i}: {line[:75]}")
              
              print("\n‚úÖ v8.5 pipeline script ready: forex_pipeline_v85_only.py")
          else:
              print("‚ùå ERROR: Could not find v8.5 pipeline code!")
              print("‚ö†Ô∏è  Falling back to full notebook")
              
              # Fallback: use full notebook
              with open("forex_pipeline_v85_only.py", "w", encoding="utf-8") as f:
                  f.write(content)
          
          print("=" * 80)
          PYTHON_EOF
          
          python extract_v85.py

      - name: Run Full Pipeline (Monday or Missing Data)
        if: |
          steps.detect_mode.outputs.execution_mode == 'monday_full' ||
          (steps.detect_mode.outputs.execution_mode == 'weekday_smart' && steps.check_data.outputs.decision == 'full_pipeline')
        run: |
          echo "=========================================="
          echo "üî¥ RUNNING FULL PIPELINE"
          echo "=========================================="
          echo "Executing all notebook cells:"
          echo "  1. Data fetching from APIs"
          echo "  2. Indicator calculation"
          echo "  3. Pickle creation & merging"
          echo "  4. Forex Pipeline v8.5"
          echo "=========================================="
          python ai_forex_brain_2.py 2>&1 | tee pipeline_output.log
          EXIT_CODE=${PIPESTATUS[0]}
          if [ $EXIT_CODE -ne 0 ]; then
            echo "‚ùå Pipeline failed with exit code $EXIT_CODE"
            tail -n 100 pipeline_output.log
            exit $EXIT_CODE
          fi
        timeout-minutes: 50

      - name: Run v8.5 Pipeline Only (Weekend or Data Exists)
        if: |
          steps.detect_mode.outputs.is_weekend == 'true' || 
          (steps.detect_mode.outputs.execution_mode == 'weekday_smart' && steps.check_data.outputs.decision == 'v85_only')
        run: |
          echo "=========================================="
          echo "üü¢ RUNNING v8.5 PIPELINE ONLY"
          echo "=========================================="
          echo "Mode: ${{ steps.detect_mode.outputs.execution_mode }}"
          echo ""
          echo "Executing:"
          echo "  ‚úÖ Forex Pipeline v8.5"
          echo "  ‚è≠Ô∏è  Skipping data fetching"
          echo "  ‚è≠Ô∏è  Skipping indicator calculation"
          echo "  ‚è≠Ô∏è  Using existing merged pickle files"
          echo "=========================================="
          
          # Verify merged pickles exist
          PICKLE_COUNT=$(ls -1 /content/forex-alpha-models/merged_data_pickles/*_2244.pkl 2>/dev/null | wc -l)
          if [ $PICKLE_COUNT -lt 4 ]; then
            echo "‚ùå ERROR: Not enough merged pickle files found ($PICKLE_COUNT/4)"
            echo "‚ö†Ô∏è  Cannot run v8.5 without data. Exiting..."
            exit 1
          fi
          
          echo "‚úÖ Found $PICKLE_COUNT merged pickle files"
          echo ""
          
          python forex_pipeline_v85_only.py 2>&1 | tee pipeline_output.log
          EXIT_CODE=${PIPESTATUS[0]}
          if [ $EXIT_CODE -ne 0 ]; then
            echo "‚ùå Pipeline failed with exit code $EXIT_CODE"
            tail -n 100 pipeline_output.log
            exit $EXIT_CODE
          fi
        timeout-minutes: 20

      - name: Copy outputs back to repository
        if: always()
        run: |
          echo "üì¶ Copying outputs back to repository..."
          
          REPO_DIR="/content/forex-alpha-models/forex-ai-models"
          
          # Copy CSV files (if any new ones)
          if ls /content/forex-alpha-models/csvs/*.csv 1> /dev/null 2>&1; then
            for file in /content/forex-alpha-models/csvs/*.csv; do
              filename=$(basename "$file")
              if [ ! -f "$REPO_DIR/$filename" ] || ! cmp -s "$file" "$REPO_DIR/$filename"; then
                cp -v "$file" "$REPO_DIR/"
              fi
            done
          fi
          
          # Copy merged pickle files (CRITICAL - always update)
          if ls /content/forex-alpha-models/merged_data_pickles/*_2244.pkl 1> /dev/null 2>&1; then
            cp -v /content/forex-alpha-models/merged_data_pickles/*_2244.pkl "$REPO_DIR/" 2>/dev/null || true
            echo "‚úÖ Updated merged pickle files"
          fi
          
          # Copy indicator pickle files
          if ls /content/forex-alpha-models/pickles/*_indicators.pkl 1> /dev/null 2>&1; then
            for file in /content/forex-alpha-models/pickles/*_indicators.pkl; do
              filename=$(basename "$file")
              if [ ! -f "$REPO_DIR/$filename" ] || ! cmp -s "$file" "$REPO_DIR/$filename"; then
                cp -v "$file" "$REPO_DIR/"
              fi
            done
          fi
          
          # Copy ML model files (v8.5 outputs)
          for pattern in "*_sgd.pkl" "*_rf.pkl" "learning_v85.pkl" "iteration_v85.pkl" "weights_v85.pkl" "memory_v85.db" "monday_runs.pkl"; do
            if ls /content/forex-alpha-models/pickles/$pattern 1> /dev/null 2>&1 || ls "$REPO_DIR"/$pattern 1> /dev/null 2>&1; then
              cp -v /content/forex-alpha-models/pickles/$pattern "$REPO_DIR/" 2>/dev/null || true
              cp -v "$REPO_DIR"/$pattern "$REPO_DIR/" 2>/dev/null || true
            fi
          done
          
          # Copy JSON signal files (v8.5 outputs)
          if ls "$REPO_DIR"/*.json 1> /dev/null 2>&1; then
            echo "‚úÖ JSON signal files already in repo"
          fi
          
          echo ""
          echo "=========================================="
          echo "üìä Repository contents:"
          echo "=========================================="
          echo "CSV files: $(ls -1 "$REPO_DIR"/*.csv 2>/dev/null | wc -l)"
          echo "Merged pickles (2244): $(ls -1 "$REPO_DIR"/*_2244.pkl 2>/dev/null | wc -l)"
          echo "Databases: $(ls -1 "$REPO_DIR"/*.db 2>/dev/null | wc -l)"
          echo "JSON signals: $(ls -1 "$REPO_DIR"/*.json 2>/dev/null | wc -l)"
          echo "Learning files: $(ls -1 "$REPO_DIR"/*_v85.pkl 2>/dev/null | wc -l)"
          echo "=========================================="
          
          echo "‚úÖ All outputs synchronized"

      - name: Commit and push changes
        if: always()
        run: |
          cd /content/forex-alpha-models/forex-ai-models
          
          git add .
          
          if git diff --cached --quiet; then
            echo "‚ÑπÔ∏è  No changes to commit"
          else
            MODE="${{ steps.detect_mode.outputs.execution_mode }}"
            git commit -m "ü§ñ Auto-update [$MODE]: $(date +'%Y-%m-%d %H:%M:%S UTC')"
            git push origin main || {
              echo "‚ö†Ô∏è  Push failed, trying to pull and merge..."
              git pull --rebase origin main
              git push origin main
            }
            echo "‚úÖ Changes pushed successfully"
          fi

      - name: Upload logs as artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: pipeline-logs-${{ github.run_number }}-${{ steps.detect_mode.outputs.execution_mode }}
          path: |
            pipeline_output.log
            /content/forex-alpha-models/logs/*.log
          retention-days: 7

      - name: Execution Summary
        if: always()
        run: |
          echo ""
          echo "=========================================="
          echo "üìä EXECUTION SUMMARY"
          echo "=========================================="
          echo "Mode: ${{ steps.detect_mode.outputs.execution_mode }}"
          echo "Weekend: ${{ steps.detect_mode.outputs.is_weekend }}"
          echo "Date: $(date +'%A, %B %d, %Y %H:%M UTC')"
          echo ""
          
          if [ "${{ steps.detect_mode.outputs.is_weekend }}" == "true" ]; then
            echo "‚úÖ Weekend mode: Executed v8.5 pipeline only"
            echo "   - Used existing merged pickle data"
            echo "   - No data fetching performed"
            echo "   - Trade evaluation with historical prices"
          elif [ "${{ steps.detect_mode.outputs.execution_mode }}" == "monday_full" ]; then
            echo "‚úÖ Monday mode: Executed full pipeline"
            echo "   - Fresh data fetched from APIs"
            echo "   - Indicators recalculated"
            echo "   - v8.5 pipeline executed with new data"
          else
            if [ "${{ steps.check_data.outputs.decision }}" == "v85_only" ]; then
              echo "‚úÖ Weekday smart mode: v8.5 only"
              echo "   - Sufficient data already exists"
              echo "   - Skipped data fetching"
            else
              echo "‚úÖ Weekday smart mode: Full pipeline"
              echo "   - Missing data detected"
              echo "   - Full refresh performed"
            fi
          fi
          
          echo ""
          echo "üìà Pipeline outputs should be available in repository"
          echo "=========================================="
