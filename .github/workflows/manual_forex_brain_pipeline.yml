name: Smart Forex Brain Pipeline (Auto-Detect Mode)

on:
  workflow_dispatch:
  push:
    paths:
      - 'colab_trigger.txt'
    branches:
      - main

jobs:
  run-forex-brain:
    runs-on: ubuntu-latest
    timeout-minutes: 55

    env:
      FOREX_PAT: ${{ secrets.FOREX_PAT }}
      BROWSERLESS_TOKEN: ${{ secrets.BROWSERLESS_TOKEN }}
      ALPHA_VANTAGE_KEY: ${{ secrets.ALPHA_VANTAGE_KEY }}
      GIT_USER_NAME: "Forex AI Bot"
      GIT_USER_EMAIL: "nakatonabira3@gmail.com"
      GITHUB_USERNAME: "rahim-dotAI"
      GITHUB_REPO: "forex-ai-models"
      PYTHONIOENCODING: utf-8
      PYTHONUNBUFFERED: 1
      GITHUB_ACTIONS: "true"
      SINGLE_RUN_MODE: "true"

    steps:
      - name: Pre-cleanup
        run: |
          sudo rm -rf /content 2>/dev/null || true
          rm -f .gitmodules 2>/dev/null || true

      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          persist-credentials: false
          fetch-depth: 0
          lfs: false
          submodules: false
          clean: true

      - name: Verify secrets
        run: |
          MISSING_SECRETS=()
          [ -z "${FOREX_PAT}" ] && MISSING_SECRETS+=("FOREX_PAT")
          [ -z "${BROWSERLESS_TOKEN}" ] && MISSING_SECRETS+=("BROWSERLESS_TOKEN")
          [ -z "${ALPHA_VANTAGE_KEY}" ] && MISSING_SECRETS+=("ALPHA_VANTAGE_KEY")
          if [ ${#MISSING_SECRETS[@]} -gt 0 ]; then
            echo "Missing secrets: ${MISSING_SECRETS[*]}"
          else
            echo "All secrets configured"
          fi

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: pip

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip wheel setuptools
          pip install --no-cache-dir \
            mplfinance firebase-admin dropbox requests beautifulsoup4 \
            pandas numpy ta yfinance pyppeteer nest_asyncio lightgbm \
            joblib matplotlib alpha_vantage tqdm scikit-learn river \
            jupyter nbconvert

      - name: Create directory structure
        run: |
          sudo mkdir -p /content/forex-alpha-models/{csvs,pickles,logs,merged_data_pickles,temp_pickles,forex-ai-models}
          sudo chown -R $USER:$USER /content
          sudo chmod -R 755 /content
          mkdir -p $GITHUB_WORKSPACE/outputs/{csvs,pickles,logs,merged_data_pickles,temp_pickles}

      - name: Configure Git
        run: |
          git config --global user.name "${GIT_USER_NAME}"
          git config --global user.email "${GIT_USER_EMAIL}"
          git config --global advice.detachedHead false
          git config --global credential.helper store
          echo "https://${GITHUB_USERNAME}:${FOREX_PAT}@github.com" > ~/.git-credentials

      - name: Clone forex-ai-models repository
        run: |
          cd /content/forex-alpha-models
          if [ ! -d "forex-ai-models/.git" ]; then
            git clone -b main https://${GITHUB_USERNAME}:${FOREX_PAT}@github.com/${GITHUB_USERNAME}/${GITHUB_REPO}.git forex-ai-models
          else
            cd forex-ai-models
            git pull origin main
          fi
          cd forex-ai-models
          git config user.name "${GIT_USER_NAME}"
          git config user.email "${GIT_USER_EMAIL}"

      - name: Check dependencies and decide execution mode
        id: check_deps
        run: |
          echo "Checking if required files exist for Ultra-Persistent mode..."
          
          REQUIRED_FILES_MISSING=0
          
          # Check for CSV data files
          if [ ! -d "/content/forex-alpha-models/csvs" ] || [ -z "$(ls -A /content/forex-alpha-models/csvs/*.csv 2>/dev/null)" ]; then
            echo "Missing: CSV data files"
            REQUIRED_FILES_MISSING=1
          fi
          
          # Check for merged pickle files
          if [ ! -d "/content/forex-alpha-models/merged_data_pickles" ] || [ -z "$(ls -A /content/forex-alpha-models/merged_data_pickles/*.pkl 2>/dev/null)" ]; then
            echo "Missing: Merged pickle files"
            REQUIRED_FILES_MISSING=1
          fi
          
          # Check forex-ai-models repo
          if [ ! -d "/content/forex-alpha-models/forex-ai-models/.git" ]; then
            echo "Missing: forex-ai-models repository"
            REQUIRED_FILES_MISSING=1
          fi
          
          if [ $REQUIRED_FILES_MISSING -eq 1 ]; then
            echo "mode=full" >> $GITHUB_OUTPUT
            echo "DECISION: Running FULL pipeline (data files missing)"
          else
            echo "mode=ultra" >> $GITHUB_OUTPUT
            echo "DECISION: Running ULTRA-PERSISTENT mode (all dependencies present)"
          fi

      - name: Convert notebook to Python
        run: |
          jupyter nbconvert --to python "AI_Forex_Brain_2.ipynb" --output ai_forex_brain_2
          sed -i '/get_ipython()/d' ai_forex_brain_2.py
          sed -i '/^get_ipython/d' ai_forex_brain_2.py
          sed -i 's/\.mkdir(exist_ok=True)/.mkdir(parents=True, exist_ok=True)/g' ai_forex_brain_2.py

      - name: Apply path fixes
        run: |
          cat > path_fixes.sed << 'EOF'
          s|ROOT_DIR = Path("/content")|ROOT_DIR = Path("/content/forex-alpha-models")|g
          s|ROOT_PATH = ROOT_DIR / "forex-alpha-models"|ROOT_PATH = Path("/content/forex-alpha-models")|g
          s|BASE_DIR = Path(".")|BASE_DIR = Path("/content/forex-alpha-models")|g
          s|REPO_FOLDER = .* / "forex-ai-models"|REPO_FOLDER = Path("/content/forex-alpha-models/forex-ai-models")|g
          s|PICKLE_FOLDER = .* / "pickles"|PICKLE_FOLDER = Path("/content/forex-alpha-models/pickles")|g
          s|FINAL_PICKLE_FOLDER = .* / "merged_data_pickles"|FINAL_PICKLE_FOLDER = Path("/content/forex-alpha-models/merged_data_pickles")|g
          s|CSV_FOLDER = .* / "csvs"|CSV_FOLDER = Path("/content/forex-alpha-models/csvs")|g
          s|LOG_FOLDER = .* / "logs"|LOG_FOLDER = Path("/content/forex-alpha-models/logs")|g
          EOF
          sed -i -f path_fixes.sed ai_forex_brain_2.py

      - name: Extract Ultra-Persistent section (if needed)
        if: steps.check_deps.outputs.mode == 'ultra'
        run: |
          cat > extract_ultra.py << 'PYTHON_EOF'
          with open("ai_forex_brain_2.py", "r", encoding="utf-8") as f:
              content = f.read()
          
          marker = '#!/usr/bin/env python3\n"""\nVERSION 3.6'
          
          if marker in content:
              idx = content.find(marker)
              filtered = content[idx:]
              print(f"Found Ultra-Persistent v3.6 at position {idx}")
          else:
              # Try alternate markers
              for alt_marker in ['VERSION 3.5', 'ULTRA-PERSISTENT']:
                  if alt_marker in content:
                      sections = content.split('#!/usr/bin/env python3')
                      for i, section in enumerate(sections):
                          if alt_marker in section:
                              filtered = '#!/usr/bin/env python3' + section
                              print(f"Found using alt method (section {i})")
                              break
                      break
              else:
                  print("Warning: Could not find section, using full file")
                  filtered = content
          
          with open("ai_forex_brain_2_ultra.py", "w", encoding="utf-8") as f:
              f.write(filtered)
          
          print(f"Extracted {len(filtered)} characters")
          PYTHON_EOF
          
          python extract_ultra.py

      - name: Run Pipeline (Full Mode)
        if: steps.check_deps.outputs.mode == 'full'
        run: |
          echo "=========================================="
          echo "RUNNING FULL PIPELINE MODE"
          echo "Reason: Required data files not present"
          echo "This will run the complete notebook"
          echo "=========================================="
          python ai_forex_brain_2.py 2>&1 | tee pipeline_output.log
          EXIT_CODE=${PIPESTATUS[0]}
          if [ $EXIT_CODE -ne 0 ]; then
            echo "Pipeline failed with exit code $EXIT_CODE"
            tail -n 50 pipeline_output.log
            exit $EXIT_CODE
          fi
        timeout-minutes: 50

      - name: Run Pipeline (Ultra-Persistent Mode)
        if: steps.check_deps.outputs.mode == 'ultra'
        run: |
          echo "=========================================="
          echo "RUNNING ULTRA-PERSISTENT MODE v3.6"
          echo "Reason: All required files present"
          echo "Starting from VERSION 3.6 section"
          echo "=========================================="
          python ai_forex_brain_2_ultra.py 2>&1 | tee pipeline_output.log
          EXIT_CODE=${PIPESTATUS[0]}
          if [ $EXIT_CODE -ne 0 ]; then
            echo "Pipeline failed with exit code $EXIT_CODE"
            tail -n 50 pipeline_output.log
            exit $EXIT_CODE
          fi
        timeout-minutes: 50

      - name: Verify persistence after run
        if: always()
        run: |
          echo "=========================================="
          echo "VERIFYING DATA PERSISTENCE"
          echo "=========================================="
          
          cd /content/forex-alpha-models/forex-ai-models
          
          echo ""
          echo "ðŸ“Š Checking critical persistence files..."
          
          # Check database
          if [ -f "ml_persistent_memory.db" ]; then
            DB_SIZE=$(du -h ml_persistent_memory.db | cut -f1)
            echo "âœ… Database exists: ml_persistent_memory.db ($DB_SIZE)"
            
            # Check if database has data
            if command -v sqlite3 &> /dev/null; then
              PENDING_COUNT=$(sqlite3 ml_persistent_memory.db "SELECT COUNT(*) FROM pending_trades;" 2>/dev/null || echo "0")
              COMPLETED_COUNT=$(sqlite3 ml_persistent_memory.db "SELECT COUNT(*) FROM completed_trades;" 2>/dev/null || echo "0")
              echo "   ðŸ“ˆ Pending trades: $PENDING_COUNT"
              echo "   ðŸ“Š Completed trades: $COMPLETED_COUNT"
            fi
          else
            echo "âŒ Database NOT found - first run or creation failed"
          fi
          
          # Check iteration counter
          if [ -f "ml_iteration_counter.pkl" ]; then
            echo "âœ… Iteration counter exists"
          else
            echo "âš ï¸  Iteration counter missing"
          fi
          
          # Check learning progress
          if [ -f "ml_learning_progress.pkl" ]; then
            echo "âœ… Learning progress file exists"
          else
            echo "âš ï¸  Learning progress missing"
          fi
          
          # Check signals
          if [ -f "latest_signals.json" ]; then
            echo "âœ… Latest signals JSON exists"
          else
            echo "âš ï¸  Signals JSON missing"
          fi
          
          echo ""
          echo "ðŸ“ All files in repo root:"
          ls -lh *.db *.pkl *.json 2>/dev/null || echo "No persistence files found"
          
          echo ""
          echo "=========================================="

      - name: Commit and push all changes to forex-ai-models repo
        if: always()
        run: |
          cd /content/forex-alpha-models/forex-ai-models
          
          echo "=========================================="
          echo "COMMITTING CHANGES TO GIT"
          echo "=========================================="
          
          # Stage all changes
          git add -A
          
          # Check if there are changes
          if git diff --staged --quiet; then
            echo "â„¹ï¸  No changes to commit"
          else
            echo "ðŸ“ Changes detected, committing..."
            
            # Show what's being committed
            echo ""
            echo "Files to be committed:"
            git diff --staged --name-only
            
            # Commit with detailed message
            TIMESTAMP=$(date -u +"%Y-%m-%d %H:%M:%S UTC")
            git commit -m "ðŸ¤– Auto update - $TIMESTAMP

            - Trade evaluation system: FIXED
            - Data persistence: ACTIVE
            - Learning system: OPERATIONAL
            
            This commit contains:
            - Updated database with trade results
            - Model performance cache
            - Iteration counter
            - Learning progress data
            - Latest trading signals"
            
            # Push with retry logic
            echo ""
            echo "ðŸš€ Pushing to GitHub..."
            for i in {1..3}; do
              if git push origin main; then
                echo "âœ… Changes pushed successfully on attempt $i"
                break
              else
                echo "âš ï¸  Push attempt $i failed, retrying in 5 seconds..."
                sleep 5
                
                if [ $i -eq 3 ]; then
                  echo "âŒ Failed to push after 3 attempts"
                  exit 1
                fi
              fi
            done
          fi
          
          echo "=========================================="

      - name: Collect outputs
        if: always()
        run: |
          mkdir -p $GITHUB_WORKSPACE/outputs/signals
          cp -r /content/forex-alpha-models/logs $GITHUB_WORKSPACE/outputs/ 2>/dev/null || true
          cp -r /content/forex-alpha-models/merged_data_pickles $GITHUB_WORKSPACE/outputs/ 2>/dev/null || true
          cp -r /content/forex-alpha-models/pickles $GITHUB_WORKSPACE/outputs/ 2>/dev/null || true
          cp /content/forex-alpha-models/forex-ai-models/*.json $GITHUB_WORKSPACE/outputs/signals/ 2>/dev/null || true
          cp pipeline_output.log $GITHUB_WORKSPACE/outputs/logs/ 2>/dev/null || true
          cp /content/forex-alpha-models/forex-ai-models/*.pkl $GITHUB_WORKSPACE/outputs/ 2>/dev/null || true
          cp /content/forex-alpha-models/forex-ai-models/*.db $GITHUB_WORKSPACE/outputs/ 2>/dev/null || true

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: forex-pipeline-logs-${{ github.run_number }}
          path: |
            outputs/logs/*.log
            pipeline_output.log
          retention-days: 7

      - name: Upload pickles
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: forex-pickles-${{ github.run_number }}
          path: |
            outputs/merged_data_pickles/*.pkl
            outputs/pickles/*.pkl
            outputs/*.pkl
          retention-days: 3

      - name: Upload signals
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: forex-signals-${{ github.run_number }}
          path: outputs/signals/*.json
          retention-days: 7

      - name: Upload database (for inspection)
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: forex-database-${{ github.run_number }}
          path: outputs/*.db
          retention-days: 7

      - name: Cleanup sensitive data
        if: always()
        run: |
          rm -f ~/.git-credentials
          rm -f /content/forex-alpha-models/forex-ai-models/.git/credentials 2>/dev/null || true

      - name: Pipeline summary
        if: always()
        run: |
          echo "=========================================="
          echo "PIPELINE EXECUTION SUMMARY"
          echo "=========================================="
          echo "Run Number: ${{ github.run_number }}"
          echo "Execution Mode: ${{ steps.check_deps.outputs.mode }}"
          echo "Status: ${{ job.status }}"
          echo ""
          echo "ðŸ“Š Persistence Check:"
          if [ -f "/content/forex-alpha-models/forex-ai-models/ml_persistent_memory.db" ]; then
            echo "âœ… Database persisted to Git"
          else
            echo "âš ï¸  Database not found"
          fi
          echo ""
          echo "ðŸ“ Last 30 lines of log:"
          tail -n 30 pipeline_output.log 2>/dev/null || echo "No log file found"
          echo "=========================================="
