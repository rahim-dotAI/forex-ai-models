üìñ Reading notebook: AI_Forex_Brain_2.ipynb
‚úÖ Loaded 10 cells
   - Code cells: 10
   - Markdown cells: 0

üöÄ Executing notebook...
============================================================

============================================================
‚ùå ERROR: Cell execution failed!
Cell index: unknown
Error: An error occurred while executing the following cell:
------------------
#!/usr/bin/env python3
"""
VERSION 3.6 ‚Äì ULTRA-PERSISTENT SELF-LEARNING HYBRID FX PIPELINE (FIXED)
========================================================================
üöÄ CRITICAL FIXES:
- ‚úÖ Environment detection (Colab vs GitHub Actions vs Local)
- ‚úÖ Proper path handling for each environment
- ‚úÖ SQLite INDEX syntax fixed (was causing crash)
- ‚úÖ Trades evaluated in NEXT iteration (after price has moved)
- ‚úÖ All data persists in Git repo (survives GitHub Actions)
- ‚úÖ Real accuracy tracking (not artificial 100%)
- ‚úÖ Proper minimum trade age before evaluation (1+ hours)
- ‚úÖ Learning system gets real performance data
- ‚úÖ Database auto-commits to Git after each run

NEW IMPROVEMENTS:
- ‚úÖ Separate pending_trades and completed_trades tables
- ‚úÖ Minimum age requirement for trade evaluation
- ‚úÖ Better model performance comparison
- ‚úÖ CSV and pickle files persist properly
- ‚úÖ Proper SQLite index creation (separate statements)
- ‚úÖ Enhanced error handling and validation
"""

import os, time, json, re, shutil, subprocess, pickle, filecmp, sqlite3
from pathlib import Path
from datetime import datetime, timezone, timedelta
import pandas as pd
import numpy as np
import requests
import ta
import logging
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import SGDClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.exceptions import NotFittedError
from collections import defaultdict

# ======================================================
# 0Ô∏è‚É£ FIXED: Environment Detection & Path Setup
# ======================================================

# Detect environment
try:
    import google.colab
    IN_COLAB = True
    ENV_NAME = "Google Colab"
except ImportError:
    IN_COLAB = False
    ENV_NAME = "Local/GitHub Actions"

IN_GHA = "GITHUB_ACTIONS" in os.environ

if IN_GHA:
    ENV_NAME = "GitHub Actions"

print(f"üåç Detected Environment: {ENV_NAME}")

# CRITICAL FIX: Set paths based on environment
if IN_COLAB:
    # Colab: Use /content (has permissions)
    ROOT_DIR = Path("/content/forex-alpha-models")
    ROOT_DIR.mkdir(parents=True, exist_ok=True)
elif IN_GHA:
    # GitHub Actions: Use current working directory (repo root)
    ROOT_DIR = Path.cwd()
    print(f"üìÇ GitHub Actions: Using repo root: {ROOT_DIR}")
else:
    # Local: Use current directory or subdirectory
    ROOT_DIR = Path("./forex-alpha-models")
    ROOT_DIR.mkdir(parents=True, exist_ok=True)

# Setup subdirectories
REPO_FOLDER = ROOT_DIR / "forex-ai-models"
CSV_FOLDER = ROOT_DIR / "csvs"
PICKLE_FOLDER = ROOT_DIR / "pickles"
LOGS_FOLDER = ROOT_DIR / "logs"

for folder in [CSV_FOLDER, PICKLE_FOLDER, LOGS_FOLDER]:
    folder.mkdir(parents=True, exist_ok=True)

print(f"‚úÖ Root Directory: {ROOT_DIR}")
print(f"‚úÖ Repo Folder: {REPO_FOLDER}")
print(f"‚úÖ CSV Folder: {CSV_FOLDER}")
print(f"‚úÖ Pickle Folder: {PICKLE_FOLDER}")
print(f"‚úÖ Logs Folder: {LOGS_FOLDER}")

# Logging setup
logging.basicConfig(
    filename=LOGS_FOLDER / "pipeline.log",
    level=logging.INFO,
    format="%(asctime)s | %(levelname)s | %(message)s"
)

def print_status(msg, level="info"):
    icons = {"info":"‚ÑπÔ∏è","success":"‚úÖ","warn":"‚ö†Ô∏è","debug":"üêû","error":"‚ùå"}
    getattr(logging, level if level != "warn" else "warning", logging.info)(msg)
    print(f"{icons.get(level,'‚ÑπÔ∏è')} {msg}")

print_status(f"Environment: {ENV_NAME}", "success")
print_status(f"Working Directory: {os.getcwd()}", "info")

# ======================================================
# üÜï FIXED DATABASE - Stores in Git Repo
# ======================================================
PERSISTENT_DB = REPO_FOLDER / "ml_persistent_memory.db"

class FixedTradeMemoryDatabase:
    """
    FIXED VERSION - SQLite compatible database
    Now with proper environment handling

    IMPROVEMENTS:
    - ‚úÖ Proper SQLite INDEX syntax (created separately)
    - ‚úÖ Enhanced error handling
    - ‚úÖ Transaction management
    - ‚úÖ Data validation
    - ‚úÖ Backup and recovery
    - ‚úÖ Environment-aware paths

    EVALUATION FLOW:
    - Stores trades at end of iteration N
    - Evaluates them at start of iteration N+1 (after 1+ hours)
    - All data stored in Git repo for persistence
    """

    def __init__(self, db_path=PERSISTENT_DB):
        self.db_path = db_path
        # Ensure parent directory exists
        self.db_path.parent.mkdir(parents=True, exist_ok=True)
        self.conn = None
        self.min_age_hours = 1  # Minimum hours before evaluation
        self.initialize_database()

    def initialize_database(self):
        """
        Create database in Git repo (persists across runs)
        FIXED: Proper SQLite syntax for indexes
        """
        try:
            self.conn = sqlite3.connect(str(self.db_path), timeout=30)
            self.conn.execute("PRAGMA journal_mode=WAL")  # Better concurrency
            self.conn.execute("PRAGMA synchronous=NORMAL")  # Faster writes
            cursor = self.conn.cursor()

            # ===== TABLE 1: Pending trades (waiting to be evaluated) =====
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS pending_trades (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    created_at TEXT NOT NULL,
                    iteration INTEGER NOT NULL,
                    pair TEXT NOT NULL,
                    timeframe TEXT NOT NULL,
                    sgd_prediction INTEGER,
                    rf_prediction INTEGER,
                    ensemble_prediction INTEGER,
                    entry_price REAL NOT NULL,
                    sl_price REAL NOT NULL,
                    tp_price REAL NOT NULL,
                    confidence REAL,
                    evaluated BOOLEAN DEFAULT 0
                )
            ''')

            # Create indexes separately (SQLite proper syntax)
            cursor.execute('''
                CREATE INDEX IF NOT EXISTS idx_pending_eval
                ON pending_trades(evaluated, created_at)
            ''')

            cursor.execute('''
                CREATE INDEX IF NOT EXISTS idx_pending_pair
                ON pending_trades(pair, evaluated)
            ''')

            # ===== TABLE 2: Completed trades (historical results) =====
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS completed_trades (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    pending_trade_id INTEGER,
                    created_at TEXT NOT NULL,
                    evaluated_at TEXT NOT NULL,
                    iteration_created INTEGER,
                    iteration_evaluated INTEGER,
                    pair TEXT NOT NULL,
                    timeframe TEXT NOT NULL,
                    model_used TEXT NOT NULL,
                    entry_price REAL NOT NULL,
                    exit_price REAL NOT NULL,
                    sl_price REAL NOT NULL,
                    tp_price REAL NOT NULL,
                    prediction INTEGER,
                    hit_tp BOOLEAN NOT NULL,
                    pnl REAL NOT NULL,
                    duration_hours REAL,
                    FOREIGN KEY (pending_trade_id) REFERENCES pending_trades(id)
                )
            ''')

            # Create indexes separately
            cursor.execute('''
                CREATE INDEX IF NOT EXISTS idx_completed_model
                ON completed_trades(model_used, evaluated_at)
            ''')

            cursor.execute('''
                CREATE INDEX IF NOT EXISTS idx_completed_pair
                ON completed_trades(pair, model_used, evaluated_at)
            ''')

            cursor.execute('''
                CREATE INDEX IF NOT EXISTS idx_completed_timestamp
                ON completed_trades(evaluated_at)
            ''')

            # ===== TABLE 3: Model performance cache =====
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS model_stats_cache (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    updated_at TEXT NOT NULL,
                    pair TEXT NOT NULL,
                    model_name TEXT NOT NULL,
                    days INTEGER NOT NULL,
                    total_trades INTEGER DEFAULT 0,
                    winning_trades INTEGER DEFAULT 0,
                    accuracy_pct REAL DEFAULT 0.0,
                    total_pnl REAL DEFAULT 0.0,
                    avg_pnl REAL DEFAULT 0.0,
                    UNIQUE(pair, model_name, days) ON CONFLICT REPLACE
                )
            ''')

            cursor.execute('''
                CREATE INDEX IF NOT EXISTS idx_stats_lookup
                ON model_stats_cache(pair, model_name, days)
            ''')

            # ===== TABLE 4: Pipeline execution log =====
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS execution_log (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    timestamp TEXT NOT NULL,
                    iteration INTEGER NOT NULL,
                    status TEXT NOT NULL,
                    trades_stored INTEGER DEFAULT 0,
                    trades_evaluated INTEGER DEFAULT 0,
                    duration_seconds REAL,
                    error_message TEXT
                )
            ''')

            self.conn.commit()
            print_status("‚úÖ Fixed ML Database initialized (persists in Git)", "success")

            # Verify database integrity
            self._verify_database_integrity()

        except sqlite3.Error as e:
            print_status(f"‚ùå Database initialization failed: {e}", "error")
            raise

    def _verify_database_integrity(self):
        """Verify database structure is correct"""
        try:
            cursor = self.conn.cursor()

            # Check if tables exist
            cursor.execute("""
                SELECT name FROM sqlite_master
                WHERE type='table' AND name IN (
                    'pending_trades', 'completed_trades',
                    'model_stats_cache', 'execution_log'
                )
            """)

            tables = [row[0] for row in cursor.fetchall()]
            expected_tables = ['pending_trades', 'completed_trades',
                             'model_stats_cache', 'execution_log']

            for table in expected_tables:
                if table in tables:
                    print_status(f"  ‚úì Table '{table}' exists", "debug")
                else:
                    print_status(f"  ‚úó Table '{table}' missing!", "error")

            # Check indexes
            cursor.execute("""
                SELECT name FROM sqlite_master
                WHERE type='index' AND name LIKE 'idx_%'
            """)

            indexes = [row[0] for row in cursor.fetchall()]
            print_status(f"  üìä Found {len(indexes)} indexes", "debug")

        except Exception as e:
            print_status(f"‚ö†Ô∏è Database verification warning: {e}", "warn")

    def store_new_signals(self, aggregated_signals, current_iteration):
        """
        Store signals at END of current iteration.
        They will be evaluated in NEXT iteration.

        Args:
            aggregated_signals: Dict of signals by pair
            current_iteration: Current iteration number

        Returns:
            int: Number of signals stored
        """
        if not aggregated_signals:
            print_status("‚ö†Ô∏è No signals to store", "warn")
            return 0

        cursor = self.conn.cursor()
        stored_count = 0
        failed_count = 0

        try:
            # Start transaction
            cursor.execute("BEGIN TRANSACTION")

            for pair, pair_data in aggregated_signals.items():
                signals = pair_data.get('signals', {})

                for tf_name, signal_data in signals.items():
                    if not signal_data:
                        continue

                    # Validate required fields
                    required_fields = ['live', 'SL', 'TP']
                    if not all(signal_data.get(f, 0) > 0 for f in required_fields):
                        print_status(
                            f"‚ö†Ô∏è Skipping invalid signal for {pair} {tf_name}",
                            "warn"
                        )
                        failed_count += 1
                        continue

                    try:
                        cursor.execute('''
                            INSERT INTO pending_trades
                            (created_at, iteration, pair, timeframe,
                             sgd_prediction, rf_prediction, ensemble_prediction,
                             entry_price, sl_price, tp_price, confidence)
                            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                        ''', (
                            datetime.now(timezone.utc).isoformat(),
                            current_iteration,
                            pair,
                            tf_name,
                            signal_data.get('sgd_pred', 0),
                            signal_data.get('rf_pred', 0),
                            signal_data.get('signal', 0),
                            signal_data.get('live', 0),
                            signal_data.get('SL', 0),
                            signal_data.get('TP', 0),
                            signal_data.get('confidence', 0.5)
                        ))
                        stored_count += 1
                    except sqlite3.Error as e:
                        print_status(f"‚ö†Ô∏è Failed to store {pair} {tf_name}: {e}", "warn")
                        failed_count += 1

            # Commit transaction
            self.conn.commit()

            # Log execution
            cursor.execute('''
                INSERT INTO execution_log
                (timestamp, iteration, status, trades_stored)
                VALUES (?, ?, 'signals_stored', ?)
            ''', (
                datetime.now(timezone.utc).isoformat(),
                current_iteration,
                stored_count
            ))
            self.conn.commit()

            print_status(
                f"üíæ Stored {stored_count} trades for next iteration "
                f"({failed_count} failed)",
                "success"
            )
            return stored_count

        except sqlite3.Error as e:
            self.conn.rollback()
            print_status(f"‚ùå Transaction failed: {e}", "error")
            return 0

    def evaluate_pending_trades(self, current_prices, current_iteration):
        """
        Evaluate trades from PREVIOUS iterations.
        Only evaluates trades older than min_age_hours.

        Args:
            current_prices: Dict of current prices by pair
            current_iteration: Current iteration number

        Returns:
            dict: Evaluation results by model
        """
        if not current_prices:
            print_status("‚ö†Ô∏è No current prices provided", "warn")
            return {}

        cursor = self.conn.cursor()

        # Get unevaluated trades that are OLD ENOUGH
        min_age = (datetime.now(timezone.utc) - timedelta(hours=self.min_age_hours)).isoformat()

        try:
            cursor.execute('''
                SELECT id, pair, timeframe, sgd_prediction, rf_prediction,
                       ensemble_prediction, entry_price, sl_price, tp_price,
                       created_at, iteration
                FROM pending_trades
                WHERE evaluated = 0 AND created_at < ?
                ORDER BY created_at ASC
            ''', (min_age,))

            pending_trades = cursor.fetchall()

        except sqlite3.Error as e:
            print_status(f"‚ùå Failed to fetch pending trades: {e}", "error")
            return {}

        if not pending_trades:
            print_status(
                f"‚ÑπÔ∏è No trades old enough to evaluate (need {self.min_age_hours}+ hours)",
                "info"
            )
            return {}

        print_status(
            f"üîç Evaluating {len(pending_trades)} trades from previous iteration(s)",
            "info"
        )

        results_by_model = defaultdict(lambda: {
            'closed_trades': 0,
            'wins': 0,
            'losses': 0,
            'total_pnl': 0.0,
            'trades': []
        })

        evaluated_count = 0
        skipped_count = 0

        try:
            # Start transaction
            cursor.execute("BEGIN TRANSACTION")

            for trade in pending_trades:
                (trade_id, pair, timeframe, sgd_pred, rf_pred, ensemble_pred,
                 entry_price, sl_price, tp_price, created_at, created_iteration) = trade

                current_price = current_prices.get(pair, 0)

                if current_price <= 0:
                    print_status(f"‚ö†Ô∏è No current price for {pair}, skipping", "warn")
                    skipped_count += 1
                    continue

                # Validate prices
                if not self._validate_trade_prices(entry_price, sl_price, tp_price, current_price):
                    print_status(
                        f"‚ö†Ô∏è Invalid prices for {pair} {timeframe}, skipping",
                        "warn"
                    )
                    skipped_count += 1
                    continue

                # Evaluate for each model that made a prediction
                for model_name, prediction in [
                    ('SGD', sgd_pred),
                    ('RandomForest', rf_pred),
                    ('Ensemble', ensemble_pred)
                ]:
                    if prediction is None:
                        continue

                    # Check if TP or SL was hit
                    hit_tp, hit_sl, exit_price = self._evaluate_trade_outcome(
                        prediction, current_price, tp_price, sl_price
                    )

                    # If trade closed, record result
                    if exit_price:
                        # Calculate P&L
                        pnl = self._calculate_pnl(
                            prediction, entry_price, exit_price
                        )

                        # Duration
                        duration_hours = self._calculate_duration_hours(created_at)

                        # Insert into completed trades
                        try:
                            cursor.execute('''
                                INSERT INTO completed_trades
                                (pending_trade_id, created_at, evaluated_at,
                                 iteration_created, iteration_evaluated,
                                 pair, timeframe, model_used, entry_price, exit_price,
                                 sl_price, tp_price, prediction, hit_tp, pnl, duration_hours)
                                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                            ''', (
                                trade_id, created_at, datetime.now(timezone.utc).isoformat(),
                                created_iteration, current_iteration,
                                pair, timeframe, model_name, entry_price, exit_price,
                                sl_price, tp_price, prediction, hit_tp, pnl, duration_hours
                            ))
                        except sqlite3.Error as e:
                            print_status(
                                f"‚ö†Ô∏è Failed to record completed trade: {e}",
                                "warn"
                            )
                            continue

                        # Accumulate results
                        results_by_model[model_name]['closed_trades'] += 1
                        results_by_model[model_name]['total_pnl'] += pnl

                        if hit_tp:
                            results_by_model[model_name]['wins'] += 1
                        else:
                            results_by_model[model_name]['losses'] += 1

                        results_by_model[model_name]['trades'].append({
                            'pair': pair,
                            'timeframe': timeframe,
                            'pnl': pnl,
                            'hit_tp': hit_tp
                        })

                        status = "WIN ‚úÖ" if hit_tp else "LOSS ‚ùå"
                        print_status(
                            f"{status} {model_name}: {pair} {timeframe} "
                            f"Entry={entry_price:.5f} Exit={exit_price:.5f} "
                            f"P&L=${pnl:.5f} ({duration_hours:.1f}h)",
                            "success" if hit_tp else "warn"
                        )

                # Mark pending trade as evaluated
                try:
                    cursor.execute('''
                        UPDATE pending_trades
                        SET evaluated = 1
                        WHERE id = ?
                    ''', (trade_id,))
                    evaluated_count += 1
                except sqlite3.Error as e:
                    print_status(f"‚ö†Ô∏è Failed to mark trade as evaluated: {e}", "warn")

            # Commit transaction
            self.conn.commit()

            # Log execution
            cursor.execute('''
                INSERT INTO execution_log
                (timestamp, iteration, status, trades_evaluated)
                VALUES (?, ?, 'trades_evaluated', ?)
            ''', (
                datetime.now(timezone.utc).isoformat(),
                current_iteration,
                evaluated_count
            ))
            self.conn.commit()

            print_status(
                f"‚úÖ Evaluated {evaluated_count} trades "
                f"({skipped_count} skipped)",
                "success"
            )

        except sqlite3.Error as e:
            self.conn.rollback()
            print_status(f"‚ùå Evaluation transaction failed: {e}", "error")
            return {}

        # Calculate accuracies
        for model_name, results in results_by_model.items():
            if results['closed_trades'] > 0:
                results['accuracy'] = (results['wins'] / results['closed_trades']) * 100
            else:
                results['accuracy'] = 0.0

        # Update model stats cache
        self._update_stats_cache()

        return dict(results_by_model)

    def _validate_trade_prices(self, entry, sl, tp, current):
        """Validate that trade prices are reasonable"""
        try:
            if any(p <= 0 for p in [entry, sl, tp, current]):
                return False

            # Prices shouldn't be wildly different (max 50% deviation)
            prices = [entry, sl, tp, current]
            avg_price = sum(prices) / len(prices)

            for price in prices:
                if abs(price - avg_price) / avg_price > 0.5:
                    return False

            return True
        except:
            return False

    def _evaluate_trade_outcome(self, prediction, current_price, tp_price, sl_price):
        """Determine if trade hit TP or SL"""
        hit_tp = False
        hit_sl = False
        exit_price = None

        try:
            if prediction == 1:  # Long
                if current_price >= tp_price:
                    hit_tp = True
                    exit_price = tp_price
                elif current_price <= sl_price:
                    hit_sl = True
                    exit_price = sl_price
            elif prediction == 0:  # Short
                if current_price <= tp_price:
                    hit_tp = True
                    exit_price = tp_price
                elif current_price >= sl_price:
                    hit_sl = True
                    exit_price = sl_price

        except Exception as e:
            print_status(f"‚ö†Ô∏è Trade evaluation error: {e}", "warn")

        return hit_tp, hit_sl, exit_price

    def _calculate_pnl(self, prediction, entry_price, exit_price):
        """Calculate profit/loss"""
        try:
            if prediction == 1:  # Long
                return exit_price - entry_price
            else:  # Short
                return entry_price - exit_price
        except:
            return 0.0

    def _calculate_duration_hours(self, created_at):
        """Calculate trade duration in hours"""
        try:
            created_dt = datetime.fromisoformat(created_at.replace('Z', '+00:00'))
            duration = (datetime.now(timezone.utc) - created_dt).total_seconds() / 3600
            return max(0, duration)
        except:
            return 0.0

    def _update_stats_cache(self):
        """Update cached model performance statistics"""
        cursor = self.conn.cursor()

        try:
            # Get unique pairs and models
            cursor.execute('SELECT DISTINCT pair FROM completed_trades')
            pairs = [row[0] for row in cursor.fetchall()]

            cursor.execute('SELECT DISTINCT model_used FROM completed_trades')
            models = [row[0] for row in cursor.fetchall()]

            for pair in pairs:
                for model in models:
                    for days in [7, 30, 90]:
                        since = (datetime.now(timezone.utc) - timedelta(days=days)).isoformat()

                        cursor.execute('''
                            SELECT
                                COUNT(*) as total,
                                SUM(CASE WHEN hit_tp THEN 1 ELSE 0 END) as wins,
                                SUM(pnl) as total_pnl,
                                AVG(pnl) as avg_pnl
                            FROM completed_trades
                            WHERE pair = ? AND model_used = ? AND evaluated_at > ?
                        ''', (pair, model, since))

                        result = cursor.fetchone()
                        total, wins, total_pnl, avg_pnl = result

                        if total and total > 0:
                            accuracy = (wins / total * 100) if total > 0 else 0.0

                            cursor.execute('''
                                INSERT OR REPLACE INTO model_stats_cache
                                (updated_at, pair, model_name, days, total_trades,
                                 winning_trades, accuracy_pct, total_pnl, avg_pnl)
                                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                            ''', (
                                datetime.now(timezone.utc).isoformat(),
                                pair, model, days, total, wins or 0,
                                accuracy, total_pnl or 0.0, avg_pnl or 0.0
                            ))

            self.conn.commit()
            print_status("‚úÖ Stats cache updated", "debug")

        except sqlite3.Error as e:
            print_status(f"‚ö†Ô∏è Stats cache update failed: {e}", "warn")

    def get_model_performance(self, pair, model_name, days=7):
        """
        Get model performance from cache (fast)

        Args:
            pair: Currency pair (e.g., 'EUR/USD')
            model_name: Model name ('SGD', 'RandomForest', 'Ensemble')
            days: Number of days to look back

        Returns:
            dict: Performance metrics
        """
        cursor = self.conn.cursor()

        try:
            cursor.execute('''
                SELECT total_trades, winning_trades, accuracy_pct,
                       total_pnl, avg_pnl, updated_at
                FROM model_stats_cache
                WHERE pair = ? AND model_name = ? AND days = ?
            ''', (pair, model_name, days))

            result = cursor.fetchone()

            if not result:
                return {
                    'total_trades': 0,
                    'winning_trades': 0,
                    'accuracy': 0.0,
                    'total_pnl': 0.0,
                    'avg_pnl': 0.0
                }

            total, wins, accuracy, total_pnl, avg_pnl, updated_at = result

            return {
                'total_trades': total,
                'winning_trades': wins,
                'accuracy': accuracy,
                'total_pnl': total_pnl,
                'avg_pnl': avg_pnl,
                'updated_at': updated_at
            }

        except sqlite3.Error as e:
            print_status(f"‚ö†Ô∏è Failed to get model performance: {e}", "warn")
            return {
                'total_trades': 0,
                'winning_trades': 0,
                'accuracy': 0.0,
                'total_pnl': 0.0,
                'avg_pnl': 0.0
            }

    def get_best_model(self, pair, days=7, min_trades=3):
        """
        Determine which model performs best based on ACTUAL results

        Args:
            pair: Currency pair
            days: Number of days to look back
            min_trades: Minimum number of trades required

        Returns:
            str: Best model name or 'Ensemble' as default
        """
        cursor = self.conn.cursor()

        try:
            cursor.execute('''
                SELECT model_name, accuracy_pct, total_trades, total_pnl
                FROM model_stats_cache
                WHERE pair = ? AND days = ? AND total_trades >= ?
                ORDER BY accuracy_pct DESC, total_pnl DESC
                LIMIT 1
            ''', (pair, days, min_trades))

            result = cursor.fetchone()

            if result:
                return result[0]

        except sqlite3.Error as e:
            print_status(f"‚ö†Ô∏è Failed to get best model: {e}", "warn")

        return 'Ensemble'  # Default fallback

    def get_database_stats(self):
        """Get database statistics with error handling"""
        cursor = self.conn.cursor()
        stats = {}

        try:
            # Pending trades count
            cursor.execute('SELECT COUNT(*) FROM pending_trades WHERE evaluated = 0')
            stats['pending_trades'] = cursor.fetchone()[0]

            # Completed trades count
            cursor.execute('SELECT COUNT(*) FROM completed_trades')
            stats['completed_trades'] = cursor.fetchone()[0]

            # Total P&L
            cursor.execute('SELECT SUM(pnl) FROM completed_trades')
            result = cursor.fetchone()
            stats['total_pnl'] = result[0] if result[0] else 0.0

            # Overall accuracy
            cursor.execute('''
                SELECT
                    COUNT(*) as total,
                    SUM(CASE WHEN hit_tp THEN 1 ELSE 0 END) as wins
                FROM completed_trades
            ''')
            result = cursor.fetchone()
            if result and result[0] > 0:
                stats['overall_accuracy'] = (result[1] / result[0]) * 100
            else:
                stats['overall_accuracy'] = 0.0

            # Database size
            if self.db_path.exists():
                stats['db_size_mb'] = self.db_path.stat().st_size / (1024 * 1024)
            else:
                stats['db_size_mb'] = 0.0

        except Exception as e:
            print_status(f"‚ö†Ô∏è Failed to get database stats: {e}", "warn")

        return stats

    def cleanup_old_data(self, days_to_keep=90):
        """
        Clean up old data to prevent database bloat

        Args:
            days_to_keep: Number of days of data to keep
        """
        cursor = self.conn.cursor()
        cutoff_date = (datetime.now(timezone.utc) - timedelta(days=days_to_keep)).isoformat()

        try:
            # Delete old evaluated pending trades
            cursor.execute('''
                DELETE FROM pending_trades
                WHERE evaluated = 1 AND created_at < ?
            ''', (cutoff_date,))
            deleted_pending = cursor.rowcount

            # Delete old execution logs
            cursor.execute('''
                DELETE FROM execution_log
                WHERE timestamp < ?
------------------


  [36mCell[39m[36m [39m[32mIn[8][39m[32m, line 857[39m
[31m    [39m[31mcursor.execute('''[39m
                   ^
[31mSyntaxError[39m[31m:[39m incomplete input


============================================================
